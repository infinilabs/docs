[{"category":null,"content":"Getting Started with the TopN Metrics Feature in INFINI Console #  Background #  In distributed search engine systems (such as Easysearch, Elasticsearch, and OpenSearch), performance monitoring is crucial. To ensure efficient system operation and reasonable resource allocation, it is important to observe the usage of key resources—especially memory and CPU usage of indices, nodes, and shards—over a period of time.\nBy performing TopN queries on these key metrics, we can identify the nodes, indices, or shards that consume the most resources, helping us quickly locate potential performance bottlenecks or overloaded components. This real-time monitoring not only improves overall cluster resource allocation but also enables timely adjustments when performance issues arise, minimizing service impact.\nWhat is Console’s TopN? #  TopN is a major new feature introduced in Console v1.28.0, designed to quickly identify the top N key metric data points. With powerful multidimensional metric analysis capabilities, it helps users optimize performance and make informed decisions more efficiently.\nAs the number of cluster nodes and indices continues to grow, traditional monitoring methods have struggled to meet the need for efficient problem localization. Previously, Console’s monitoring tools focused more on multi-dimensional metrics for a single node or index. However, when users needed to quickly find the busiest, slowest, or largest key data points across all nodes or indices, it often proved inconvenient.\nAlthough Console provides powerful advanced analytics, navigating a large number of metrics could result in slower loading speeds and overly dense data, making it difficult to identify issues at a glance. TopN was introduced to address these pain points by offering more precise and efficient monitoring and analytical capabilities.\nThe TopN metrics feature provided by INFINI Console enables users to gain a comprehensive view of cluster performance based on key indicators such as memory usage and CPU utilization. With just a few simple steps, users can quickly identify the TopN indices, nodes, or shards, and further optimize resource allocation and system performance.\nFeature Overview #  Click the left-hand menu Platform Management \u0026gt; Monitoring Reports, and select the TopN Tab page. You will then see the following interface:\n If the selected cluster uses metrics collected by INFINI Agent, you will see Nodes and Shards tabs here.\nThe current Agent collection mode does not yet support viewing TopN indices; this will be added in the future.\n Follow these steps in order:\n Go to the Index tab Set the top value (default is 15) Select the area metric, e.g., Segment Memory Select a color metric (optional), e.g., Index Storage Click the search button  You will then see the top 15 indices with the highest memory usage, as shown below:\n By default, TopN sorting uses the area metric. If you want to sort by the selected color metric instead, click the Swap button shown above.\n If you prefer a simplified view, you can switch to the table view, as shown below:\nSummary #  The TopN metrics feature in INFINI Console enables users to perform performance monitoring and analysis more efficiently, especially when dealing with large numbers of nodes, indices, and shards. Through intuitive TopN sorting, users can quickly identify the most resource-consuming nodes, indices, or shards, helping detect bottlenecks early and apply timely optimizations. Whether for memory usage, CPU utilization, or index storage, the TopN feature provides a clear view to support intelligent resource allocation and continuous performance improvement.\nAs clusters scale, traditional monitoring methods may become cumbersome and inefficient. This new feature in INFINI Console enhances performance tuning and decision-making efficiency with a user-friendly interface and powerful multi-dimensional data analysis. In practice, users can configure it flexibly to focus on the most critical resource usage points in real time, enabling proactive measures to ensure system stability and performance.\n","subcategory":null,"summary":"","tags":null,"title":"Getting Started with the TopN Metrics Feature in INFINI Console","url":"/console/main/docs/tutorials/getting_started_with_the_TopN_metrics_feature/"},{"category":null,"content":"How to monitor JVM usage of Elasticsearch cluster nodes #  Introduction #  This article will introduce how to use the INFINI Console to monitor the JVM usage of Elasticsearch cluster nodes and generate alerts.\nPrepare #   Download and install the latest version of INFINI Console Register Elasticsearch cluster using INFINI Console  Create alerting rule #  Open INFINI Console in the browser, click on the left menu \u0026ldquo;Alerting\u0026rdquo; \u0026gt; Rules to enter the alerting management page, and then click New button to enter the Create Alerting Rule page. Follow these steps to create an alerting rule:\n Select the cluster (here you need to select the Elasticsearch cluster where the INFINI Console stores data, that is, the Elasticsearch cluster configured in the configuration file console.yml, if it is not registered to the INFINI Console, please register first) Input the alerting object .infini_metrics* (select the index under the Elasticsearch cluster, or enter the index pattern, because the monitoring data collected by the INFINI Console is stored in the index .infini_metrics) Input filter criteria (Elasticsearch query DSL) Here we need to filter the monitoring metrics category to node_stats and the metadata category to elasticsearch. The DSL is as follows:  { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;metadata.name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;node_stats\u0026quot; } } }, { \u0026quot;term\u0026quot;: { \u0026quot;metadata.category\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;elasticsearch\u0026quot; } } } ] } }  Select time field timestamp and statistical period for date histogram aggregation   Input the rule name Group settings (optional, multiple can be configured), set when statistical metrics need to be grouped, because all registered to INFINI Console The Elasticsearch cluster monitoring metrics are stored in the index .infini_metrics, so you need to group according to the cluster ID first, and then group according to the node ID, Here we choose metadata.labels.cluster_id and metadata.labels.node_id. Configure the alerting metrics, select the aggregation field payload.elasticsearch.node_stats.jvm.mem.heap_used_percent, and the statistics method p90. Configure the metrics formula (when more than one alerting metrics is configured, you need to set a formula to calculate the target metrics), where the formula fx is configured as a. Then set the value type of the variable a to the ratio Ratio. Configure the alerting conditions, configure three alerting conditions here, configure the P2(Medium) alerting when the JVM usage rate is greater than 50 for continuous one cycle; Configure continues one cycle when the JVM usage rate is greater than 90, trigger the P1(High) alerting; Configure the P0(Critical) alerting to be triggered when the JVM usage rate is greater than 95 for one cycle; Set the execution period, here is configured to execute a check every minute Set the event title, the event title is a template, you can use template variables, template syntax and template variable usage reference here Set the event content, the event content is a template, you can use template variables, template syntax and template variable usage reference here  Priority:{{.priority}} Timestamp:{{.timestamp | datetime_in_zone \u0026quot;Asia/Shanghai\u0026quot;}} RuleID:{{.rule_id}} EventID:{{.event_id}} {{range.results}} ClusterID:{{index.group_values ​​0}}; NodeID:{{index.group_values ​​1}}; JVM used percent: {{.result_value | to_fixed 2}}%; {{end}}  Turn on the configure alerting channel switch, and select add in the upper right corner to quickly select an alerting channel template to fill. For how to create an alerting channel template, please refer to here Set the silence period to 1 hour, that is, after the alerting rule is triggered, the notification message will only be sent once within an hour Set the receiving period, the default is 00:00-23:59, that is, you can receive notification messages throughout the day  After the settings are complete, click the Save button to submit.\nReceive alert notification message #  Wait for a while, and receive the DingTalk alerting message notification as follows:\nYou can see that the alert notification message displays the Elasticsearch cluster ID, node ID, and current JVM usage rate triggered by the current rule.\nView the alerting message center #  In addition to receiving external notification messages, the INFINI Console Alert Message Center also generates an alert message. Click menu Alerting \u0026gt; Alerting Center to enter\nSummary #  By using the INFINI Console alert function, you can easily monitor the JVM usage of Elasticsearch cluster nodes. After configuring alerting rule, Once any Elasticsearch node JVM usage exceeds a set threshold, an alert will be triggered and an alert message will be sent.\n","subcategory":null,"summary":"","tags":null,"title":"How to monitor JVM usage of Elasticsearch cluster nodes","url":"/console/main/docs/tutorials/cluster_node_jvm_usage/"},{"category":null,"content":"How to monitor the CPU usage of Elasticsearch cluster nodes #  Introduction #  This article will introduce how to use the INFINI Console to monitor the disk usage of Elasticsearch cluster nodes and alert them.\nPrepare #   Download and install the latest version of INFINI Console Register Elasticsearch cluster using INFINI Console  Create alerting rule #  Open INFINI Console in the browser, click Alerting \u0026gt; Rules on the left menu to enter the alerting management page, and then click the New button to enter the alerting rule creation page. Follow these steps to create an alerting rule:\n Select the cluster (here you need to select the Elasticsearch cluster where the INFINI Console stores data, that is, the Elasticsearch cluster configured in the configuration file console.yml, if it is not registered to the INFINI Console, please register first) Input the alerting object .infini_metrics* (select the index under the Elasticsearch cluster, or enter the index pattern, because the monitoring data collected by the INFINI Console is stored in the index .infini_metrics) Input filter condition (Elasticsearch query DSL) Here we need to filter the monitoring metrics category to node_stats and the metadata category to elasticsearch. The DSL is as follows:  { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;metadata.name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;node_stats\u0026quot; } } }, { \u0026quot;term\u0026quot;: { \u0026quot;metadata.category\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;elasticsearch\u0026quot; } } } ] } }  Select time field timestamp and statistical period for date histogram aggregation   Input the rule name Group settings (optional, multiple can be configured), set when statistical metrics need to be grouped, because all registered to INFINI Console The Elasticsearch cluster monitoring metrics are stored in the index .infini_metrics, so you need to group according to the cluster ID first, and then group according to the node ID, Here we choose metadata.labels.cluster_id and metadata.labels.node_id. Configure the alerting metrics, select the aggregation field payload.elasticsearch.node_stats.process.cpu.percent, and the statistics method avg. Configure the metrics formula (when more than one alerting metrics is configured, you need to set a formula to calculate the target metrics), where the formula fx is configured as a. Then set the value type of the variable a to the ratio Ratio. Configure the alerting conditions, configure three alerting conditions here, and configure the P2(Medium) alerting when the CPU usage is greater than 80 for continuous one cycle; Configure the continue for one cycle when the CPU usage is greater than 90, trigger the P1(High) alerting; Configure the continuous period to trigger the P0(Critical) alerting when the CPU usage is greater than 95; Set the execution period, here is configured to execute a check every minute Set the event title, the event title is a template, you can use template variables, template syntax and template variable usage reference here Set the event content, the event content is a template, you can use template variables, template syntax and template variable usage reference here  Priority:{{.priority}} Timestamp:{{.timestamp | datetime_in_zone \u0026quot;Asia/Shanghai\u0026quot;}} RuleID:{{.rule_id}} EventID:{{.event_id}} {{range.results}} ClusterID:{{index.group_values ​​0}}; NodeID:{{index.group_values ​​1}}; CPU:{{.result_value | to_fixed 2}}%; {{end}}  Turn on the configure alerting channel switch, and select add in the upper right corner to quickly select an alerting channel template to fill. For how to create an alerting channel template, please refer to here Set the silence period to 1 hour, that is, after the alerting rule is triggered, the notification message will only be sent once within an hour Set the receiving period, the default is 00:00-23:59, that is, you can receive notification messages throughout the day  After the settings are complete, click the Save button to submit.\nReceive alert notification message #  Wait for a while, and receive the DingTalk alerting message notification as follows:\nYou can see that the alert notification message displays the Elasticsearch cluster ID, node ID, and current CPU usage triggered by the current rule.\nView the alerting message center #  In addition to receiving external notification messages, the INFINI Console Alert Message Center also generates an alert message. Click menu Alerting \u0026gt; Alerting Center to enter\nSummary #  By using the INFINI Console alerting function, you can easily monitor the CPU usage of Elasticsearch cluster nodes. After configuring the alerting rule, once the CPU usage of any Elasticsearch node exceeds the set threshold, an alert will be triggered and an alert message will be sent.\n","subcategory":null,"summary":"","tags":null,"title":"How to monitor the CPU usage of Elasticsearch cluster nodes","url":"/console/main/docs/tutorials/cluster_node_cpu_usage/"},{"category":null,"content":"How to monitor slow query requests in Elasticsearch #  Introduction #  Many times, the Elasticsearch cluster will experience peak data writing or query traffic. At this time, the Elasticsearch cluster will be under a lot of pressure. Through the monitoring and alertinging of the delay of the Elasticsearch index query. This allows us to locate which indexes are the most stressed on the Elasticsearch cluster. This article will introduce how to use the INFINI Console alerting function to monitor the slow query request index in Elasticsearch.\nPrepare #   Download and install the latest version of INFINI Console Register Elasticsearch cluster using INFINI Console  Create alerting rule #  Open INFINI Console in the browser, click on the left menu \u0026ldquo;Alerting\u0026rdquo; \u0026gt; Rules to enter the alerting management page, and then click New button to enter the Create Alerting Rule page. Follow these steps to create an alerting rule:\n Select the cluster (here you need to select the Elasticsearch cluster where the INFINI Console stores data, that is, the Elasticsearch cluster configured in the configuration file console.yml, if it is not registered to the INFINI Console, please register first) Input the alerting object .infini_metrics* (select the index under the Elasticsearch cluster, or enter the index pattern, because the monitoring data collected by the INFINI Console is stored in the index .infini_metrics) Input filter criteria (Elasticsearch query DSL) Here we need to filter the monitoring metrics category to index_stats, and the index name cannot be _all, the DSL is as follows:  { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;metadata.name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;index_stats\u0026quot; } } }, { \u0026quot;term\u0026quot;: { \u0026quot;metadata.category\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;elasticsearch\u0026quot; } } } ], \u0026quot;must_not\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;metadata.labels.index_name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;_all\u0026quot; } } } ] } }  Select time field timestamp and statistical period for date histogram aggregation   Input the rule name Group settings (optional, multiple can be configured), set when statistical metrics need to be grouped, because all registered to INFINI Console The Elasticsearch cluster monitoring metrics are stored in the index .infini_metrics, so you need to group according to the cluster ID first, and then group according to the index name, Here we choose metadata.labels.cluster_id and metadata.labels.index_name Configure the alerting metrics, select the aggregation field payload.elasticsearch.index_stats.total.search.query_time_in_millis, and use the statistical method to derive derivative. Then add another alerting metrics, select the aggregation field payload.elasticsearch.index_stats.total.search.query_total, and the statistical method derivative. Configure the metrics formula (when more than one alerting metrics is configured, you need to set a formula to calculate the target metrics), where the formula fx is configured as a/b to calculate the delay, Configure the alerting conditions, three alerting conditions are configured here, and when the continue for one cycle delay is greater than 100, the P3(Low) alerting is triggered; Configure the Continue for one cycle delay when the delay is greater than 500, trigger the P1(High) alerting; Configure continue for one cycle when the delay is greater than 1000, trigger the P0(Critical) alerting; Set the execution period, here is configured to execute a check every minute Set the event title, the event title is a template, you can use template variables, template syntax and template variable usage reference here Set the event content, the event content is a template, you can use template variables, template syntax and template variable usage reference here  Priority:{{.priority}} Timestamp:{{.timestamp | datetime_in_zone \u0026quot;Asia/Shanghai\u0026quot;}} RuleID:{{.rule_id}} EventID:{{.event_id}} {{range.results}} ClusterID:{{index.group_values ​​0}}; Index name:{{index.group_values ​​1}}; Current value:{{.result_value | to_fixed 2}}ms; {{end}}  Turn on the configure alerting channel switch, and select add in the upper right corner to quickly select an alerting channel template to fill. For how to create an alerting channel template, please refer to here Set the silence period to 1 hour, that is, after the alerting rule is triggered, the notification message will only be sent once within an hour Set the receiving period, the default is 00:00-23:59, that is, you can receive notification messages throughout the day  After the settings are complete, click the Save button to submit.\nReceive alert notification message #  Wait for a while, and receive the DingTalk alerting message notification as follows:\nYou can see that the alerting notification message shows the Elasticsearch cluster ID, index name, and delay size of which query delay is too high.\nView the alerting message center #  In addition to receiving external notification messages, the INFINI Console Alert Message Center also generates an alert message. Click menu Alerting \u0026gt; Alerting Center to enter\nSummary #  By using the INFINI Console alerting function, you can easily monitor the slow index of the Elasticsearch cluster. After configuring alerting rule, Once any Elasticsearch index query latency is too high, an alert will be triggered and an alert message will be sent.\n","subcategory":null,"summary":"","tags":null,"title":"How to monitor slow query requests in Elasticsearch","url":"/console/main/docs/tutorials/cluster_slow_request/"},{"category":null,"content":"How to monitor Elasticsearch cluster node disk usage #  Introduction #  When the system disk usage is too high, data cannot be written into the Elasticsearch cluster, which is likely to result in data loss. Therefore, monitor the Elasticsearch cluster. Node disk usage is necessary. This article will show you how to monitor your Elasticsearch cluster using INFINI Console alerts Node disk usage.\nPrepare #   Download and install the latest version of INFINI Console Register Elasticsearch cluster using INFINI Console  Create alerting rule #  Open INFINI Console in the browser, click on the left menu \u0026ldquo;Alerting\u0026rdquo; \u0026gt; Rules to enter the alerting management page, and then click New button to enter the Create Alerting Rule page. Follow these steps to create an alerting rule:\n Select the cluster (here you need to select the Elasticsearch cluster where the INFINI Console stores data, that is, the Elasticsearch cluster configured in the configuration file console.yml, if it is not registered to the INFINI Console, please register first) Input the alerting object .infini_metrics* (select the index under the Elasticsearch cluster, or enter the index pattern, because the monitoring data collected by the INFINI Console is stored in the index .infini_metrics) Input filter criteria (Elasticsearch query DSL) Here we need to filter the monitoring metrics category to node_stats, the DSL is as follows:  { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;metadata.name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;node_stats\u0026quot; } } } ] } }  Select time field timestamp and statistical period for date histogram aggregation   Input the rule name Group settings (optional, multiple can be configured), set when statistical metrics need to be grouped, because all registered to INFINI Console The Elasticsearch cluster monitoring metrics are stored in the index .infini_metrics, so you need to group according to the cluster ID first, and then group according to the node ID, Here we choose metadata.labels.cluster_id and metadata.labels.node_id Configure the alerting metrics, select the aggregation field payload.elasticsearch.node_stats.fs.total.free_in_bytes, and the statistics method avg. Then add another alerting metrics, select the aggregation field payload.elasticsearch.node_stats.fs.total.total_in_bytes, and the statistical method avg. Configure the metrics formula (when more than one alerting metrics is configured, you need to set a formula to calculate the target metrics), where the formula fx is configured as ((b-a)/b)*100, which means to use the total Disk space subtract remaining disk space to get disk used space, Then divide disk used space by total disk space and multiply by 100 to get disk usage Configure the alerting conditions, here configure three alerting conditions, configure the P2(Medium) alerting when the disk usage is greater than 80 for persisting for one period; Configure the continue for one period when the disk usage is greater than 90, trigger the P1(High) alerting; Configure persisting for a period when the disk usage rate is greater than 95, trigger the P0(Critical) alerting; Set the execution period, here is configured to execute a check every minute Set the event title, the event title is a template, you can use template variables, template syntax and template variable usage reference here Set the event content, the event content is a template, you can use template variables, template syntax and template variable usage reference here  Priority:{{.priority}} Timestamp:{{.timestamp | datetime}} RuleID:{{.rule_id}} EventID:{{.event_id}} {{range.results}} ClusterID: {{index.group_values ​​0}}; NodeID: {{index.group_values ​​1}}; Disk Usage:{{.result_value | to_fixed 2}}%; Free Storage: {{.relation_values.a | format_bytes 2}}; {{end}}  Turn on the configure alerting channel switch, and select add in the upper right corner to quickly select an alerting channel template to fill. For how to create an alerting channel template, please refer to here Set the silence period to 1 hour, that is, after the alerting rule is triggered, the notification message will only be sent once within an hour Set the receiving period, the default is 00:00-23:59, that is, you can receive notification messages throughout the day  After the settings are complete, click the Save button to submit.\nReceive alert notification message #  Wait for a while, and receive the DingTalk alerting message notification as follows:\nYou can see that the alert notification message displays the Elasticsearch cluster ID, node ID, and remaining disk space with high disk usage.\nView the alerting message center #  In addition to receiving external notification messages, the INFINI Console Alert Message Center also generates an alert message. Click menu Alerting \u0026gt; Alerting Center to enter\nSummary #  By using the INFINI Console alerting function, you can easily monitor the disk usage of Elasticsearch cluster nodes. After configuring alerting rule, Once the disk usage of any Elasticsearch node exceeds the set threshold, an alert will be triggered and an alert message will be sent.\n","subcategory":null,"summary":"","tags":null,"title":"How to monitor Elasticsearch cluster node disk usage","url":"/console/main/docs/tutorials/cluster_node_disk_usage/"},{"category":null,"content":"How to Monitor Elasticsearch Cluster Health #  Introduction #  In many cases, the cluster health status of the Elasticsearch cluster will turn red for some reason. At this time, at least one primary shard in the Elasticsearch cluster is unallocated or lost. So it is necessary to monitor the health status of the Elasticsearch cluster. This article will introduce how to use the INFINI Console alerting feature to monitor the health of an Elasticsearch cluster.\nPrepare #   Download and install the latest version of INFINI Console Register Elasticsearch cluster using INFINI Console  Create alerting rule #  Open INFINI Console in the browser, click on the left menu \u0026ldquo;Alerting\u0026rdquo; \u0026gt; Rules to enter the alerting management page, and then click New button to enter the Create Alerting Rule page. Follow these steps to create an alerting rule:\n Select the cluster (here you need to select the Elasticsearch cluster where the INFINI Console stores data, that is, the Elasticsearch cluster configured in the configuration file console.yml, if it is not registered to the INFINI Console, please register first) Select the alerting object .infini_metrics (select the index under the Elasticsearch cluster, or enter the index pattern, because the monitoring data collected by the INFINI Console is stored in the index .infini_metrics) Input filter condition (Elasticsearch query DSL) Here we need to filter the data whose monitoring metrics category is cluster_health and the health status is red. The DSL is as follows:  { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;match\u0026quot;: { \u0026quot;payload.elasticsearch.cluster_health.status\u0026quot;: \u0026quot;red\u0026quot; } }, { \u0026quot;term\u0026quot;: { \u0026quot;metadata.name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;cluster_health\u0026quot; } } } ] } }  Select time field and stat period for date histogram aggregation   Input the rule name Group settings (optional, multiple can be configured), set when statistical metrics need to be grouped, because all registered to INFINI Console The Elasticsearch cluster monitoring metrics are stored in the index .infini_metrics, so they need to be grouped according to the cluster ID, Here we choose metadata.labels.cluster_id Configure the alerting metrics, select the aggregation field payload.elasticsearch.cluster_health.status, and the statistical method count Configure the alerting condition, configure the continue for one period and the aggregation result is greater than or equal to 1, that is, the Critical alerting is triggered Set the execution period, here is configured to execute a check every minute Set the event title, the event title is a template, you can use template variables, template syntax and template variable usage reference here Set the event content, the event content is a template, you can use template variables, template syntax and template variable usage reference here   Turn on the configure alerting channel switch, and select add in the upper right corner to quickly select an alerting channel template to fill. For how to create an alerting channel template, please refer to here Set the silence period to 1 hour, that is, after the alerting rule is triggered, the notification message will only be sent once within an hour Set the receiving period, the default is 00:00-23:59, that is, you can receive notification messages throughout the day  After the settings are complete, click the Save button to submit.\nSimulate trigger alerting rule #  Open the INFINI Console Dev tools (Ctrl+Shift+O) and enter the command as shown below:\nReceive alert notification message #  After waiting for about a minute, you will receive a DingTalk alerting notification as follows:\nYou can see that the alerting notification message shows the ID of the Elasticsearch cluster whose health status has turned red. Click the link below the message to view the alerting details as follows:\nView the alerting message center #  In addition to receiving external notification messages, the INFINI Console Alert Message Center also generates an alert message. Click menu Alerting \u0026gt; Alerting Center to enter\nSummary #  By using the INFINI Console alerting function, you can easily monitor the health status of the Elasticsearch cluster. After configuring alerting rule,As soon as any Elasticsearch cluster status turns red, an alert is triggered and an alert message is sent.\n","subcategory":null,"summary":"","tags":null,"title":"How to Monitor Elasticsearch Cluster Health","url":"/console/main/docs/tutorials/cluster_health_change/"},{"category":null,"content":"Kubernetes Deployment #  INFINI Console supports deployment on Kubernetes using Helm charts.\nThe Chart Repository #  Chart repository: https://helm.infinilabs.com.\nUse the follow command add the repository:\nhelm repo add infinilabs https://helm.infinilabs.com Prerequisites #   K8S StorageClass  The default StorageClass of the Chart package is local-path, you can install it through here.\nIf you want use other StorageClass(installed), you can create a YAML file (eg. vaules.yaml) file that it contains the follow contents:\nstorageClassName: \\\u0026lt;storageClassName\\\u0026gt; and use it through -f.\nInstall #  helm install console infinilabs/console -n \u0026lt;namespace\u0026gt; Uninstall #  helm uninstall console -n \u0026lt;namespace\u0026gt; kubectl delete pvc console-data-console-0 console-config-console-0 -n \u0026lt;namespace\u0026gt; ","subcategory":null,"summary":"","tags":null,"title":"Kubernetes","url":"/console/main/docs/getting-started/helm/"},{"category":null,"content":"User Management #  Introduction #  User Management includes CURD operations and reset password for user.\nCreate User #   User name is required, and it should be unique. Nick name, phone, email, is optional. Select one or more role. Tags is optional, it helps you group users.  Search User #  Input keywords and click the search button to query users.\nUpdate User #  Modify as needed, and then click the Save button to submit.\nReset User password #  Input the new password and then click the save button to reset the password.\n","subcategory":null,"summary":"","tags":null,"title":"User","url":"/console/main/docs/reference/system/security/user/"},{"category":null,"content":"Role Management #  Introduction #  Role Management includes CURD operations for role. And INFINI Console has a builtin role named Administrator, it has all privileges , includes Platform and Data. The data role can help us control privileges of elasticsearch, includes elasticsearch api privileges which can be configured in the file config/permission.json of your setup path.\nCreate Platform Role #   Input role name, role name should be unique. Select feature privileges, can not be empty. Input a description if needed  All privilege represents both read and write permission, Read privilege represents only read permission, and None privilege represents no permission\nCreate Data Role #   Input role name, role name should be unique. Select one or more cluster, * represents all clusters. Config cluster api privileges, * represents all privileges. Config index api privileges, * represents all privileges. Input a description if needed  Search Role #  Input a keyword and click the search button to query roles.\nUpdate Platform Role #  Modify the role as needed, and then click the Save button to submit.\nUpdate Data Role #  Modify the role as needed, and then click the Save button to submit.\n","subcategory":null,"summary":"","tags":null,"title":"Role","url":"/console/main/docs/reference/system/security/role/"},{"category":null,"content":"Container Deployment #  INFINI Console supports container deployment.\nDownloading an Image #  The images of INFINI Console are published at the official repository of Docker. The URL is as follows:\n https://hub.docker.com/r/infinilabs/console\nUse the following command to obtain the latest container image:\ndocker pull infinilabs/console:1.29.3-2018 Verifying the Image #  After downloading the image locally, you will notice that the container image of INFINI Console is very small, with a size less than 30 MB. So, the downloading is very fast.\n✗ docker images |grep \u0026quot;console\u0026quot; |grep \u0026quot;1.29.3-2018\u0026quot; REPOSITORY TAG IMAGE ID CREATED SIZE infinilabs/console 1.29.3-2018 8c27cd334e4c 47 minutes ago 26.4MB Starting the Console #  Use the following command to start the INFINI Console container:\ndocker run -p 9000:9000 infinilabs/console:1.29.3-2018 Docker Compose #  You can also use docker compose to manage container instances. Create one docker-compose.yml file as follows:\nversion: \u0026quot;3.5\u0026quot; services: infini-console: image: infinilabs/console:1.29.3-2018 ports: - 9000:9000 container_name: \u0026quot;infini-console\u0026quot; In the directory where the configuration file resides, run the following command to start INFINI Console.\n➜ docker-compose up   ","subcategory":null,"summary":"","tags":null,"title":"Docker","url":"/console/main/docs/getting-started/docker/"},{"category":null,"content":"Container Deployment #  INFINI Agent supports container deployment.\nDownload Image #  The images of INFINI Agent are published at the official repository of Docker. The URL is as follows: https://hub.docker.com/r/infinilabs/agent\nRun the following command:\ndocker pull infinilabs/agent:1.29.3-2018 Verifying the Image #  After downloading the image locally, you will notice that the container image of INFINI Agent is very small, with a size less than 25 MB. So, the downloading is very fast.\n✗ docker images |grep \u0026quot;agent\u0026quot; |grep \u0026quot;1.29.3-2018\u0026quot; REPOSITORY TAG IMAGE ID CREATED SIZE infinilabs/agent 1.29.3-2018 c7bd9ad063d9 4 days ago 13.8MB Configuration #  Create a configuration file agent.yml to perform basic configuration as follows:\napi: enabled: true network: binding: 0.0.0.0:8080 metrics: enabled: true queue: metrics network: enabled: true summary: true details: true memory: metrics: - swap - memory disk: metrics: - ioqs - usage cpu: metrics: - idle - system - user - iowait - load elasticsearch: enabled: true agent_mode: true node_stats: true index_stats: true cluster_stats: true\nelasticsearch:\n name: default enabled: true endpoint: http://192.168.3.4:9200 monitored: false discovery: enabled: true  pipeline:\n name: metrics_ingest auto_start: true keep_running: true processor:  json_indexing: index_name: \u0026quot;.infini_metrics\u0026quot; elasticsearch: \u0026quot;default\u0026quot; input_queue: \u0026quot;metrics\u0026quot; output_queue: name: \u0026quot;metrics_requests\u0026quot; label: tag: \u0026quot;metrics\u0026quot; worker_size: 1 bulk_size_in_mb: 10   name: consume-metrics_requests auto_start: true keep_running: true processor:  bulk_indexing: bulk: compress: true batch_size_in_mb: 10 batch_size_in_docs: 5000 consumer: fetch_max_messages: 100 queues: type: indexing_merge when: cluster_available: [ \u0026quot;default\u0026quot; ]    agent: major_ip_pattern: \u0026quot;192.*\u0026quot; labels: env: dev tags: - linux - x86 - es7 - v7.5\npath.data: data path.logs: log\nagent.manager.endpoint: http://192.168.3.4:9000 Note: In the above configuration, replace the Elasticsearch configuration with the actual server connection address and authentication information.\nStarting #  Run the following command:\ndocker run -p 8080:8080 -v=`pwd`/agent.yml:/agent.yml infinilabs/agent:1.29.3-2018 Docker Compose #  You can also use docker compose to manage container instances. Create one docker-compose.yml file as follows:\nversion: \u0026quot;3.5\u0026quot; services: infini-agent: image: infinilabs/agent:1.29.3-2018 ports: - 8080:8080 container_name: \u0026quot;infini-agent\u0026quot; volumes: - ./agent.yml:/agent.yml\nvolumes: dist: Run the following command to start INFINI Agent.\n➜ docker-compose up Recreating infini-agent ... done Attaching to infini-agent infini-agent | _ ___ __ __ _____ infini-agent | /_\\ / _ \\ /__\\/\\ \\ \\/__ \\ infini-agent | //_\\\\ / /_\\//_\\ / \\/ / / /\\/ infini-agent | / _ \\/ /_\\\\//__/ /\\ / / / infini-agent | \\_/ \\_/\\____/\\__/\\_\\ \\/ \\/ infini-agent | infini-agent | [AGENT] A light-weight, powerful and high-performance elasticsearch agent. infini-agent | [AGENT] 0.1.0_SNAPSHOT#15, 2022-08-26 15:05:43, 2025-12-31 10:10:10, 164bd8a0d74cfd0ba5607352e125d72b46a1079e infini-agent | [08-31 09:11:45] [INF] [app.go:164] initializing agent. infini-agent | [08-31 09:11:45] [INF] [app.go:165] using config: /agent.yml. infini-agent | [08-31 09:11:45] [INF] [instance.go:72] workspace: /data/agent/nodes/cc7ibke5epac7314bf9g infini-agent | [08-31 09:11:45] [INF] [metrics.go:63] ip:172.18.0.2, host:bd9f43490911, labels:, tags: infini-agent | [08-31 09:11:45] [INF] [api.go:261] api listen at: http://0.0.0.0:8080 infini-agent | [08-31 09:11:45] [INF] [actions.go:367] elasticsearch [default] is available infini-agent | [08-31 09:11:45] [INF] [module.go:116] all modules are started infini-agent | [08-31 09:11:45] [INF] [manage.go:180] register agent to console infini-agent | [08-31 09:11:45] [INF] [app.go:334] agent is up and running now.   ","subcategory":null,"summary":"","tags":null,"title":"Container Deployment","url":"/console/main/docs/reference/agent/docker/"},{"category":null,"content":"How to assign Elasticsearch index-level permissions to INFINI Console accounts #  Introduction #  This article will introduce the use of INFINI Console to limit an account to only have the management permissions of certain indexes in the Elasticsearch cluster\nPrepare #   Download and install the latest version of INFINI Console Enable INFINI Console Security Features Register at least two Elasticsearch clusters to the INFINI Console  Creating a Role #  Click System \u0026gt; Security Settings on the left menu of INFINI Console, and select the Role Tab page to enter the role management page.\nNew platform role platform_role #  Click the New button, select the platform role, and create a new platform role platform_role\nNew data role test_index_only #  Click the New button, select the data role, create a new data role test_index_only, and then configure the following:\n Select only es-v7140 for the cluster (restrict access to this role only to the Elasticsearch cluster es-v7140) Set index permissions to index only enter the index pattern test* (restrict the role to only index access permissions whose index name matches test*)  After the configuration is complete, click the Save button to submit.\nCreate Account #  Click the left menu of INFINI Console System \u0026gt; Security Settings, select the User Tab page to enter the Account Management page.\nNew account liming #  Click the New button to create a new account liming and assign the account roles platform_role, test_index_only\nClick the save button to submit after the creation is successful, save the account password\nLogin with administrator account #  After logging in with the administrator account, click the menu Data \u0026gt; Index Management, select the cluster es-v7140, and you can see:\nLogin with account liming #  After logging in with the account liming, click the menu Data \u0026gt; Index Management, select the cluster es-v7140, and then you can see:\nSummary #  By specifying the role\u0026rsquo;s Elasticsearch cluster permissions and indexing permissions, it is easy to precisely control user permissions down to the indexing level.\n","subcategory":null,"summary":"","tags":null,"title":"How to assign Elasticsearch index-level permissions to INFINI Console accounts","url":"/console/main/docs/tutorials/role_with_index_limit/"},{"category":null,"content":"How to assign different Elasticsearch cluster access permissions to different INFINI Console accounts #  Introduction #  This article will introduce the use of INFINI Console to assign two different Elasticsearch cluster management permissions to two different accounts\nPrepare #   Download and install the latest version of INFINI Console Enable INFINI Console Security Features Register at least two Elasticsearch clusters to the INFINI Console  Creating a Role #  Click System \u0026gt; Security Settings on the left menu of INFINI Console, and select the Role Tab page to enter the role management page.\nNew platform role platform_role #  Click the New button, select the platform role, and create a new platform role platform_role. The operation steps are as follows:\n Input role name platform_role Expand all functional permissions Except for the security functions under the system settings, select the All permission for all other functions. Security feature under System Settings is set to None permission. Click the save button to submit  Selecting the All permission of a function represents the read and write operation permission of this function, Read means only have read permission, None means no permission for this function (the function is not available in the menu after the user logs in)\n   New data role es-v7171 #  Click the New button, select the data role, and create a new data role es-v7171\nNew data role es-v630 #  Click the New button, select the data role, create a new data role es-v630, the configuration is similar to the role es-v7171\nCreate Account #  Click the left menu of INFINI Console System \u0026gt; Security Settings, select the User Tab page to enter the Account Management page.\nNew account zhangsan #  Click the New button to create a new account zhangsan and assign the account role platform_role, es-v717\nClick the save button to submit after the creation is successful, save the account password\nNew account wangwu #  Click the New button to create a new account wangwu, and assign the account roles platform_role, es-v630, the configuration is similar to the account zhangsan\nLogin with administrator account #  After logging in with the administrator account, view the platform overview, and you can see all 13 registered clusters\nLogin with account zhangsan #  After logging in with the account zhangsan and viewing the platform overview, you can only see the cluster es-v7171\nLogin with account wangwu #  After logging in with the account zhangsan and viewing the platform overview, you can only see the cluster es-v630\nSummary #  By creating different roles and granting different Elasticsearch cluster permissions, and then assigning roles to users, we can quickly implement Grant different Elasticsearch cluster permissions to different users.\n","subcategory":null,"summary":"","tags":null,"title":"How to assign different Elasticsearch cluster access permissions to different INFINI Console accounts","url":"/console/main/docs/tutorials/role_with_different_rights/"},{"category":null,"content":"How to easily create an Elasticsearch \u0026ldquo;guest\u0026rdquo; user #  Introduction #  In some cases, we want to share some functions or data with customers, but do not want the data to be modified. At this point we need to create a \u0026ldquo;guest\u0026rdquo; user. This article briefly describes how to create a \u0026ldquo;guest\u0026rdquo; user using the INFINI Console.\nPrepare #   Download and install the latest version of INFINI Console Enable INFINI Console Security Features  Creating a Role #  Click System \u0026gt; Security Settings on the left menu of INFINI Console, and select the Role Tab page to enter the role management page.\nNew platform role readonly #  Click the New button, select the platform role, and create a new platform role readonly. The operation steps are as follows:\n Input role name readonly Expand all functional permissions Read permission is selected for all other functions except the security functions under the system settings. Security feature under System Settings is set to None permission. Click the save button to submit  Selecting the All permission of a function represents the read and write operation permission of this function, Read means only have read permission, None means no permission for this function (the function is not available in the menu after the user logs in)\n   New data role es-v7171 #  Click the New button, select the data role, and create a new data role es-v7171. The operation steps are as follows:\n Input role name es-v7171 Cluster permission select cluster es-v7171 Click the save button to submit  New account guest #  Click the left menu of INFINI Console System \u0026gt; Security Settings, select the User Tab page to enter the Account Management page. Click the New button to create a new account guest and assign the account role readonly, es-v7171\nClick Save and submit. After the creation is successful, you can use the guest account to log in to the INFINI Console and only have read-only permissions.\n","subcategory":null,"summary":"","tags":null,"title":"How to easily create an Elasticsearch \"guest\" user","url":"/console/main/docs/tutorials/create_readonly_account/"},{"category":null,"content":"Installing The Agent #  Before You Begin #  Install and keep INFINI Console running.\nInstall by Console generated script #  curl -sSL http://localhost:9000/agent/install.sh?token=cjctdrms4us1c6fu04ag |sudo bash -s -- -u https://release.infinilabs.com/agent/stable -v 0.6.0-262 -t /opt/agent  The -u and -v parameters indicate that the specified version of the Agent is downloaded from the specified URL, and the -t parameter indicates the installation path. In a networked environment, the \u0026ndash; and subsequent parameters can be ignored, and by default, the latest version of the Agent will be downloaded from the official website for installation.\n Container Deployment #  INFINI Agent also supports Docker container deployment.\nLearn More  Configuration #  Most of the configuration of INFINI Agent can be completed using agent.yml. After the configuration is modified, the agent program needs to be restarted to make the configuration take effect.\nAfter unzip the file and open agent.yml, you will see this:\nenv: LOGGING_ES_ENDPOINT: http://localhost:9200 LOGGING_ES_USER: admin LOGGING_ES_PASS: admin API_BINDING: \u0026quot;0.0.0.0:2900\u0026quot; path.data: data path.logs: log\napi: enabled: true network: binding: $[[env.API_BINDING]]\nomitted \u0026hellip; agent.manager.endpoint: http://192.168.3.4:9000 In most cases, you only need to config the LOGGING_ES_ENDPOINT, but if Elasticsearch has security authentication enabled, then configure the LOGGING_ES_USER and LOGGING_ES_PASS.\nThe user must have access to the cluster metadata, index metadata, and all indexes with .infini prefix.\nStarting the Agent #  Run the agent program to start INFINI Agent, as follows:\n _ ___ __ __ _____ /_\\ / _ \\ /__\\/\\ \\ \\/__ \\ //_\\\\ / /_\\//_\\ / \\/ / / /\\/ / _ \\/ /_\\\\//__/ /\\ / / / \\_/ \\_/\\____/\\__/\\_\\ \\/ \\/ [AGENT] A light-weight, powerful and high-performance elasticsearch agent. [AGENT] 0.1.0#14, 2022-08-26 14:09:29, 2025-12-31 10:10:10, 4489a8dff2b68501a0dd9ae15276cf5751d50e19 [08-31 15:52:07] [INF] [app.go:164] initializing agent. [08-31 15:52:07] [INF] [app.go:165] using config: /Users/INFINI/agent/agent-0.1.0-14-mac-arm64/agent.yml. [08-31 15:52:07] [INF] [instance.go:72] workspace: /Users/INFINI/agent/agent-0.1.0-14-mac-arm64/data/agent/nodes/cc7h5qitoaj25p2g9t20 [08-31 15:52:07] [INF] [metrics.go:63] ip:192.168.3.22, host:INFINI-MacBook.local, labels:, tags: [08-31 15:52:07] [INF] [api.go:261] api listen at: http://0.0.0.0:8080 [08-31 15:52:07] [INF] [module.go:116] all modules are started [08-31 15:52:07] [INF] [manage.go:180] register agent to console [08-31 15:52:07] [INF] [actions.go:367] elasticsearch [default] is available [08-31 15:52:07] [INF] [manage.go:203] registering, waiting for review [08-31 15:52:07] [INF] [app.go:334] agent is up and running now. If the above startup information is displayed, the agent is running successfully and listening on the responding port.\nBut now agent can\u0026rsquo;t work normally util it\u0026rsquo;s being added to INFINI Console. See Agent Manage\nShutting Down the Agent #  To shut down INFINI Agent, hold down Ctrl+C. The following information will be displayed:\n^C [AGENT] got signal: interrupt, start shutting down [08-31 15:57:13] [INF] [module.go:145] all modules are stopped [08-31 15:57:13] [INF] [app.go:257] agent now terminated. [AGENT] 0.1.0, uptime: 5m6.240314s  / // |/ // __// // |/ // / / // || // / / // || // / ////|/// ////|//_/\n©INFINI.LTD, All Rights Reserved. System Service #\n To run the INFINI Agent as a system service, run the following commands:\n➜ ./agent -service install Success ➜ ./agent -service start Success Uninstall service:\n➜ ./agent -service stop Success ➜ ./agent -service uninstall Success Manual Configuration #  If you want to manually configure the INFINI Agent to collect Elasticsearch logs and metrics, you can refer to the agent.yml. If you want to collect metrics and logs for other Elasticsearch clusters, you need to add the corresponding configuraiton under elasticsearch and pipeline configuration.\nIf you want to toggle off some metrics/logs collecting, set the corresponding pipeline.enabled to `false.\nCollect Elasticsearch Metrics #  Collect node stats:\n - name: collect_default_node_stats enabled: false auto_start: true keep_running: true retry_delay_in_ms: 10000 processor: - es_node_stats: elasticsearch: default Collect index stats:\n - name: collect_default_index_stats enabled: false auto_start: true keep_running: true retry_delay_in_ms: 10000 processor: - es_index_stats: elasticsearch: default Collect cluster stats:\n - name: collect_default_cluster_stats enabled: false auto_start: true keep_running: true retry_delay_in_ms: 10000 processor: - es_cluster_stats: elasticsearch: default Collect cluster health info:\n - name: collect_default_cluster_health enabled: false auto_start: true keep_running: true retry_delay_in_ms: 10000 processor: - es_cluster_health: elasticsearch: default Collect Elasticsearch Logs #  Collect the logs from the specified nodes, set the endpoint to the specified node in the elasticsearch configuration:\n - name: collect_default_es_logs enabled: false auto_start: true keep_running: true retry_delay_in_ms: 3000 processor: - es_logs_processor: queue_name: \u0026quot;logs\u0026quot; elasticsearch: default If you have multiple nodes running on the local host, add more elasticsearch and pipeline configurations:\nelasticsearch: # omitted ... - name: cluster-a-node-1 enabled: true endpoint: http://localhost:9202 monitored: false discovery: enabled: true omitted \u0026hellip;  name: collect_node_1_es_logs enabled: false auto_start: true keep_running: true retry_delay_in_ms: 3000 processor:  es_logs_processor: queue_name: \u0026quot;logs\u0026quot; elasticsearch: cluster-a-node-1 Collect Other Logs #     If es_logs_processor can\u0026rsquo;t provide the flexibility you need, or you want to collect other services' logs on the local host, you can use logs_processor to collect them. There\u0026rsquo;s a sample configuration to collect Elasticsearch logs in the agent.yml, you can modify it or add new configurations, and update the metadata and labels for better investigations later.\n - name: log_collect enabled: false auto_start: true keep_running: true retry_delay_in_ms: 3000 processor: - logs_processor: queue_name: \u0026quot;logs\u0026quot; logs_path: \u0026quot;/opt/es/elasticsearch-7.7.1/logs\u0026quot; # metadata for all log items metadata: category: elasticsearch # patterns are matched in order patterns: - pattern: \u0026quot;.*_server.json$\u0026quot; # file name pattern to match # log type, json/text/multiline type: json # metadata for matched files metadata: name: server # (json) timestamp fields in json message, match the first one timestamp_fields: [\u0026quot;timestamp\u0026quot;, \u0026quot;@timestamp\u0026quot;] # (json) remove fields with specified key path remove_fields: [ \u0026quot;type\u0026quot;, \u0026quot;cluster.name\u0026quot;, \u0026quot;cluster.uuid\u0026quot;, \u0026quot;node.name\u0026quot;, \u0026quot;node.id\u0026quot;, \u0026quot;timestamp\u0026quot;, \u0026quot;@timestamp\u0026quot;, ] - pattern: \u0026quot;gc.log$\u0026quot; # file name pattern to match # log type, json/text/multiline type: json # metadata for matched files metadata: name: gc # (text) regex to match timestamp in the log entries timestamp_patterns: - \u0026quot;\\\\d{4}-\\\\d{1,2}-\\\\d{1,2}T\\\\d{1,2}:\\\\d{1,2}:\\\\d{1,2}.\\\\d{3}\\\\+\\\\d{4}\u0026quot; - \u0026quot;\\\\d{4}-\\\\d{1,2}-\\\\d{1,2} \\\\d{1,2}:\\\\d{1,2}:\\\\d{1,2},\\\\d{3}\u0026quot; - \u0026quot;\\\\d{4}-\\\\d{1,2}-\\\\d{1,2}T\\\\d{1,2}:\\\\d{1,2}:\\\\d{1,2},\\\\d{3}\u0026quot; - pattern: \u0026quot;.*.log$\u0026quot; # file name pattern to match # log type, json/text/multiline type: multiline # (multiline) the pattern to match a new line line_pattern: '^\\[' # metadata for matched files metadata: name: server # (text) regex to match timestamp in the log entries timestamp_patterns: - \u0026quot;\\\\d{4}-\\\\d{1,2}-\\\\d{1,2}T\\\\d{1,2}:\\\\d{1,2}:\\\\d{1,2}.\\\\d{3}\\\\+\\\\d{4}\u0026quot; - \u0026quot;\\\\d{4}-\\\\d{1,2}-\\\\d{1,2} \\\\d{1,2}:\\\\d{1,2}:\\\\d{1,2},\\\\d{3}\u0026quot; - \u0026quot;\\\\d{4}-\\\\d{1,2}-\\\\d{1,2}T\\\\d{1,2}:\\\\d{1,2}:\\\\d{1,2},\\\\d{3}\u0026quot; ","subcategory":null,"summary":"","tags":null,"title":"Installing Agent","url":"/console/main/docs/reference/agent/install/"},{"category":null,"content":"Agent Overview #  Overview #  INFINI Agent is a submodule of INFINI Console, charge of data scraping and Elasticsearch instance manage. it\u0026rsquo;s manage by INFINI Console. INFINI Agent supports mainstream operating systems and platforms. The program package is small, with no extra external dependency. So, the agent can be installed very rapidly.\nHighlights of Agent:\n Collect cluster health/cluster stats/node stats/index stats from Elasticsearch Collect local JSON and text logs from Elasticsearch. Collect host metrics. Upload all metrics and logs to Elasticsearch.  Quick Installation #  Go to the menu INVENTORY \u0026gt; AGENTS and click the Install Agent button. You will see that the Console automatically generates an installation script. Simply click the copy icon in the top right corner of the script to copy it.\nPaste the copied installation script into the target host to perform a one-click quick installation. The generated configuration file looks like the following:\npath.configs: config configs.auto_reload: true env: API_BINDING: 0.0.0.0:8080 path.data: data path.logs: log\napi: enabled: true tls: enabled: true cert_file: config/client.crt key_file: config/client.key ca_file: config/ca.crt skip_insecure_verify: false network: binding: $[[env.API_BINDING]]\nbadger: value_log_max_entries: 1000000 value_log_file_size: 104857600 value_threshold: 1024\nagent: major_ip_pattern: .* The certificate used here is automatically generated by the Console during installation. Once the installation is successful, the agent instance will be automatically registered to the Console. The Console will then communicate with the agent using mTLS. The token used during installation is for quick installation purposes only and cannot be used for other APIs. The token is valid for one hour.\n Make sure that the Console host and the Agent host are network-accessible to each other.\n Agent Instance Registration #  Step 1: Enter the agent address, and optionally enable TLS and authentication (if authentication is enabled, a username and password are required).\nStep 2: Confirm the information, and optionally modify the agent name, tags, and description.\nAfter completing the input, click Next to finish registration.\n Agents installed via the one-click installation script from INFINI Console are automatically registered to the Console, no manual registration is needed.\n Agent Instance List #  In the agent instance list, you can view registered agent instances as shown below:\nExpanding a table row displays all Elasticsearch, Easysearch, and Opensearch node process instances on the agent. Click the refresh icon in the upper right corner after expanding to refresh the process list.\nAssociate Node Processes with Registered Clusters in Console #  To collect cluster metrics and node logs via the Agent, associate the automatically discovered Elasticsearch, Easysearch, and Opensearch node processes with already registered clusters in the Console. Once associated, the collected metrics can be directly used in the Console monitoring features. The association process is as follows:\nClick Associate in the node process list to open the following dialog:\n If the node’s cluster has already been registered in the Console, simply click Associate in the popup window to complete the operation. Once associated, the Agent will automatically collect cluster metrics and node logs. If the node process requires authentication information, the association dialog will look like this:  You need to enter the node address and authentication details, then attempt a connection to fetch the cluster info.\n If the cluster has not yet been registered in the Console, the dialog will look like this:  Just follow the instructions and click go to register to register the cluster. Once registered, return to complete the association.\nEdit Agent Information #  Click the edit button in the agent list table to enter the update screen.\nModify the configuration as needed, then click the save button to submit.\nDelete Agent Instance #  Go to the menu INVENTORY \u0026gt; AGENTS , then click Delete in the corresponding row. After confirmation, the agent will be deleted.\n","subcategory":null,"summary":"","tags":null,"title":"Overview","url":"/console/main/docs/reference/agent/manage/manage/"},{"category":null,"content":"Installing the Console #  INFINI Console supports mainstream operating systems and platforms, the package is small, without any additional external dependencies, it should be very fast to install :)\nPreparation before Installation #  Prepare an Elasticsearch cluster that can store data. The required version is 5.3 or above, which is used for INFINI Console to store related data.\nInstallation Demo #    autoplay=\u0026quot;1\u0026quot; preload=\u0026quot;1\u0026quot; start-at=\u0026quot;0\u0026quot; speed=\u0026quot;2\u0026quot; \u0026gt;\u0026lt;/asciinema-player\u0026gt;  Downloading #  Automatic install\ncurl -sSL http://get.infini.cloud | bash -s -- -p console  The above script can automatically download the latest version of the corresponding platform\u0026rsquo;s console and extract it to /opt/console\n  The optional parameters for the script are as follows:\n   -v [version number]（Default to use the latest version number）\n   -d [installation directory] (default installation to /opt/console)\n Manual install\nSelect a package for downloading in the following URL based on your operating system and platform:\n https://release.infinilabs.com/console/\nContainer Deployment #  INFINI Console also supports Docker container deployment.\nLearn More  Starting the Console #  The Console can be started by directly running the program (the mac version is used here, and the program file names of different platforms are slightly different), as follows:\n➜ ./console-mac-amd64 ___ __ ___ ___ / __\\/ / /___\\/\\ /\\ / \\ / / / / // // / \\ \\/ /\\ / / /__/ /__/ \\_//\\ \\_/ / /_// \\____|____|___/ \\___/___,' ___ ___ __ __ ___ __ __ / __\\/___\\/\\ \\ \\/ _\\ /___\\/ / /__\\ / / // // \\/ /\\ \\ // // / /_\\ / /__/ \\_// /\\ / _\\ \\/ \\_// /__//__ \\____|___/\\_\\ \\/ \\__/\\___/\\____|__/ [CONSOLE] INFINI Cloud Console, The easiest way to operate your own elasticsearch platform. [CONSOLE] 0.3.0_SNAPSHOT, 2022-03-31 10:26:41, 2023-12-31 10:10:10, fa04f6010144b7c5267c71ccaee30230ddf2432d [03-31 20:27:40] [INF] [app.go:174] initializing console. [03-31 20:27:40] [INF] [app.go:175] using config: /console-0.3.0_SNAPSHOT-447-mac-amd64/console.yml. [03-31 20:27:40] [INF] [instance.go:72] workspace: /console-0.3.0_SNAPSHOT-447-mac-amd64/data/console/nodes/c92psf1pdamk8rdhgqpg [03-31 20:27:40] [INF] [app.go:283] console is up and running now. [03-31 20:27:40] [INF] [elastic.go:136] loading [5] remote elasticsearch configs [03-31 20:27:40] [INF] [ui.go:197] ui listen at: http://0.0.0.0:9000 [03-31 20:27:40] [INF] [module.go:116] all modules are started Seeing the above startup information, it means that the Console has successfully run and listen on port 9000.\nShutting Down the Console #  To shut down INFINI Console, hold down Ctrl+C. The following information will be displayed:\n^C [CONSOLE] got signal: interrupt, start shutting down [03-31 20:33:10] [INF] [module.go:145] all modules are stopped [03-31 20:33:10] [INF] [app.go:267] console now terminated. [CONSOLE] 0.3.0_SNAPSHOT, uptime: 5m30.307832s  / // |/ // __// // |/ // / / // || // / / // || // / ////|/// ////|//_/\n©INFINI.LTD, All Rights Reserved. System Service #\n To run the Console as a background task, run the following commands:\n➜ ./console -service install Success ➜ ./console -service start Success Unloading the service is simple. To unload the service, run the following commands:\n➜ ./console -service stop Success ➜ ./console -service uninstall Success ","subcategory":null,"summary":"","tags":null,"title":"Installation","url":"/console/main/docs/getting-started/install/"},{"category":null,"content":"Audit Logs #  Introduction #  Audit logs are primarily designed to meet compliance requirements, enhance security, support incident investigations, and assist in risk management. They record system operation activities to help detect anomalies, trace the root cause of issues, and identify potential risks. This ensures the secure and stable operation of enterprise information systems while also meeting regulatory requirements.\nLog List #  The audit log list displays information such as operation time, operator, operation type, and the type of resource being operated on.\n","subcategory":null,"summary":"","tags":null,"title":"Audit Logs","url":"/console/main/docs/reference/system/audit/"},{"category":null,"content":"Template variables #  Introduction #  When custom alerting triggers event content, in addition to the fixed copy written by yourself, the event title and event content also support template syntax. The rendering of the text can be achieved using fields in the event.\nVariables #  The syntax for rendering fields is {{ .fieldname }}, and the variable fields that can be used for template content rendering are as follows:\n   Field Name Type Descriction eg     rule_id string rule uuid c9f663tath2e5a0vksjg   rule_name string rule name High CPU usage   resource_id string resource uuid c9f663tath2e5a0vksjg   resource_name string resource name es-v716   event_id string identifier for check details c9f663tath2e5a0vksjx   timestamp number Millisecond timestamp 1654595042399   first_group_value string The first value of group_values in results c9aikmhpdamkiurn1vq0   first_threshold string The first value of threshold in results 90   priority string The highest priority in results critical   title string event title Node ({{.first_group_value}}) disk used \u0026gt;= 90%   message string event content EventID：{{.event_id}}; Cluster：{{.resource_name}}   results array result of groups    ┗ threshold array  [\u0026ldquo;90\u0026rdquo;]   ┗ priority string  high   ┗ group_values array  [\u0026ldquo;cluster-xxx\u0026rdquo;, \u0026ldquo;node-xxx\u0026rdquo;]   ┗ issue_timestamp number Millisecond timestamp 1654595042399   ┗ result_value float  91.2   ┗ relation_values map  {a:100, b:91.2}    Variable usage example #  Example 1:\n{\u0026quot;content\u0026quot;:\u0026quot;【Alerting】Event ID: {{.event_id}}, Cluster：{{.resource_name}}\u0026quot;} Example 2(array traversal):\n{{range .results}} Cluster ID: {{index .group_values 0}} {{end}} Template functions #  In addition to directly displaying the field value in the alerting event, it also supports the use of template functions to further process the field value to optimize the output.\nFunctions support extra parameters. When no parameters are required or passed, the following syntax can be used directly:\n{{ \u0026lt;field\u0026gt; | \u0026lt;function\u0026gt; }}\nSpecific examples are as follows:\nFunctions take no parameters:\nAlerting event trigger time:{{ .timestamp | datetime }} Functions take parameters:\nAlerting event trigger time:{{ .timestamp | datetime_in_zone \u0026quot;Asia/Shanghai\u0026quot; }} Use multiple functions in combination:\n{{.result_value | format_bytes 2 ｜ to_upper}} The complete list of template functions is as follows:\n   Functions params Descriction      to_fixed fixed number of decimal places The float type value retains N decimal places\nExample:{{.result_value | to_fixed 2}}\nOutput:10.35    format_bytes fixed number of decimal places Byte type numeric formatting\nExample:{{.result_value | format_bytes 2}}\nOutput:10.35gb    date  Convert timestamp to UTC date\nExample:{{.timestamp | date}}\nOutput:2022-05-01    date_in_zone Time zone Convert timestamp to current zone date\nExample:{{.timestamp | date_in_zone \u0026quot;Asia/Shanghai\u0026quot;}}\nOutput:2022-05-01    datetime  Convert timestamp to UTC time\nExample:{{.timestamp | datetime}}\nOutput:2022-05-01 10:10:10    datetime_in_zone Time zone Convert timestamp to current zone time\nExample:{{.timestamp | datetime_in_zone \u0026quot;Asia/Shanghai\u0026quot;}}\nOutput:2022-05-01 10:10:10    to_lower  Convert characters to lowercase\nExample:{{.resource_name | to_lower }}\nOutput:cluster    to_upper  Convert characters to uppercase\nExample:{{.resource_name | to_upper }}\nOutput:CLUSTER    add number Example: a+b\n{{.result_value | add 1 }}\nOutput：2    sub number Example: a - b\n{{sub .result_value 1 }}\nOutput：0    mul number Example: a _ b _ c\n{{mul .result_value 3 2 }}\nOutput：6    div number Example: a/b\n{{div .result_value 2 }}\nOutput：0.5     Common Template Syntax #  Array traversal：\n{{range .results}} priority: {{.priority}} {{end}} Get values by array subscript:\nExample: group_values = [\u0026ldquo;value1\u0026rdquo;,\u0026ldquo;value2\u0026rdquo;,\u0026ldquo;value3\u0026rdquo;]\n{{index .group_values 0}} # output: value1 {{index .group_values 2}} # output: value3 if conditional branch：\n{{if pipeline}} T1 {{else}} T0 {{end}} Example:\n{{if eq .priority \u0026quot;critical\u0026quot;}} \u0026quot;#C91010\u0026quot; {{else if eq .priority \u0026quot;high\u0026quot;}} \u0026quot;#EB4C21\u0026quot; {{else}} \u0026quot;#FFB449\u0026quot; {{end}} There is also a set of binary comparison operators defined as functions:\neq Returns the boolean truth of arg1 == arg2 ne Returns the boolean truth of arg1 != arg2 lt Returns the boolean truth of arg1 \u0026lt; arg2 le Returns the boolean truth of arg1 \u0026lt;= arg2 gt Returns the boolean truth of arg1 \u0026gt; arg2 ge Returns the boolean truth of arg1 \u0026gt;= arg2 A more complete example for Slack message { \u0026quot;blocks\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;section\u0026quot;, \u0026quot;text\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;【test201】Alerting:\\n\u0026lt;http://localhost:8000/#/alerting/alert/{{.event_id}}|{{.title}}\u0026gt; \u0026lt;@username\u0026gt;\u0026quot; } }, { \u0026quot;type\u0026quot;: \u0026quot;section\u0026quot;, \u0026quot;text\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Timestamp:* {{.issue_timestamp | datetime}}\u0026quot; } } ], \u0026quot;attachments\u0026quot;: [ {{range .results}} { \u0026quot;color\u0026quot;: {{if eq .priority \u0026quot;critical\u0026quot;}} \u0026quot;#C91010\u0026quot; {{else if eq .priority \u0026quot;high\u0026quot;}} \u0026quot;#EB4C21\u0026quot; {{else}} \u0026quot;#FFB449\u0026quot; {{end}}, \u0026quot;blocks\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;section\u0026quot;, \u0026quot;fields\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Cluster:* {{index .group_values 0}}\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Node:* {{index .group_values 1}}\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Threshold:* {{index .threshold 0}}\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Priority:* {{.priority}}\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Monitoring value:* {{.result_value}}\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Disk usage:* {{.relation_values.a | format_bytes 2 | to_upper}}\u0026quot; } ] } ] }, {{end}} ] }    More template syntax Click me\n","subcategory":null,"summary":"","tags":null,"title":"Template variables","url":"/console/main/docs/reference/alerting/variables/"},{"category":null,"content":"Data View #  View list #  Creating and managing data views can help you better get data from Elasticsearch.\nCreate data view #  Step 1 Define the data view #   Input a view name Matching rules: Match the corresponding index, you can also use (*) to match multiple indexes.  Step 2 Configuration #    Select time field as time filter for view index\n  Created\n  Edit data view #  The page lists all fields that match the index, and you can set the Format, Popularity, etc. of the fields.\n","subcategory":null,"summary":"","tags":null,"title":"Data View","url":"/console/main/docs/reference/data/view/"},{"category":null,"content":"Cluster Activities #  After registering a cluster, the activities of the cluster can be observed.\n","subcategory":null,"summary":"","tags":null,"title":"Cluster Activities","url":"/console/main/docs/reference/platform/activities/"},{"category":null,"content":"Channels #  Introduction #  The channel is used to configure the channel for sending notification messages when an alerting rule is triggered. Currently, webhook is supported.\nChanne list #  In the channel list, you can query the channels that have been added\nNew channel #  Click the New button on the channels list page to enter the new alerting channel page\n Input channel name (required) Select a channel type (supports various types such as Email, Slack, Discord,DingTalk, Feishu, WeChat, and custom webhooks) Input the webhook address Select the method of HTTP request, the default is POST Add HTTP request headers as needed Configure the webhook request body Click the save button to submit  Update channel configuration #  Select the channel to be updated in the channels list and click the Edit button to enter the update channel configuration page\nDelete channel #  Click the delete button in the channels list table to confirm the second time, and execute the delete operation after confirming the deletion.\n","subcategory":null,"summary":"","tags":null,"title":"Channels","url":"/console/main/docs/reference/alerting/channel/"},{"category":null,"content":"Rules #  Introduction #  The alerting rules include the configuration of four parts: data source, metrics definition, trigger condition, and message notification\nRule list #  In the rule list, you can query the rules that have been added\nNew rule #  Click the New button in the rule list to enter the new rule page\nConfigure data source #   Select a cluster (required) Select index, support input index pattern (required) Input elasticsearch query DSL query filter conditions (optional) Select time field (required) Select the statistical period (for time field aggregation, the default is one minute)  Configure alerting metrics and trigger conditions #   Input the rule name Add the grouped fields and group size as needed, you can add more than one for terms aggregation Select the metrics aggregation field and statistics type, you can configure more than one, when configuring more than one, you must configure a formula to calculate the final metrics Configure alerting trigger conditions  Select Metrics value Select Bucket diff - Select based on Doc diff or Content diff  Doc diff: The difference in the number of matching documents between two adjacent time buckets\nContent diff: Whether there’s a change in a group between two adjacent time buckets. A difference value of 1 indicates an increase, -1 indicates a decrease, and 0 indicates no change\n    Select execution check cycle Input the title of the alerting event (template, referenced by the title in the template variable, click here to learn about template syntax ) Input alerting event message (template, referenced by message in template variable, click here for template syntax )  Bucket Diff is a feature introduced in INFINI Console version 1.28.2. It can be used to detect differences in data across different time periods, such as checking if there’s an abnormal change in data volume during a specific time window.\n   Configure message notification #   Configure notification channels, which can be reconfigured, or you can use the add button to select an already created channel as a template to quickly fill in, and support adding multiple Choose whether to enable notification upgrades as needed Select silence period (how often notification messages are sent) Configure notification sending time period Click the save button to submit  Update rules #  Select the alerting rule to be updated in the alerting rules list and click the Edit button to enter the update alerting rules page\nDelete rules #  Click the delete button in the rule list table to confirm the second time. After confirming the deletion, execute the delete operation.\nImport of common rule templates #  Some common Alerting rules are listed below, and notification channels such as DingTalk, Enterprise WeChat, and Slack are configured. You only need to replace the custom variables specified in the template, and you can quickly import the rules through the DevTools tool of the Console.\n  Cluster Health Change to Red  Index Health Change to Red  Disk utilization is Too High  CPU utilization is Too High  JVM utilization is Too High  Shard Storage \u0026gt;= 55G  Elasticsearch node left cluster  Search latency is great than 500ms  Too Many Deleted Documents  ","subcategory":null,"summary":"","tags":null,"title":"Rules","url":"/console/main/docs/reference/alerting/rule/"},{"category":null,"content":"Discover #  Introduction #  In Discover, you can search and query the data under the index or view according to conditions such as time and fields.\nSearch toolbar #  Index (View) #  Search #  Time Range #  Field Filter #  Save Search #  Document Details #  Click the \u0026quot; \u0026gt; \u0026quot; button on the left side of a document row to expand and view detailed information. Both Table and JSON viewing modes are supported.\nYou can also edit or delete the document here.\n","subcategory":null,"summary":"","tags":null,"title":"Discover","url":"/console/main/docs/reference/data-insight/discover/"},{"category":null,"content":"Common Commands #  Introduction #  Common commands are used to save frequently used Elasticsearch requests in Dev toolss, so that if you need to use them later, Just use the LOAD command in the Dev tools to load, and it can be used quickly.\nSave frequently used commands #  Open the Dev tools (Ctrl+shift+o) in the upper right corner of the console, and select the Elasticsearch request to be saved in the Dev tools (Supports selecting multiple requests at one time and saving them as common commands), after selecting, click Save As Command in the toolbar to submit.\nLoad common commands #  In the Dev tools, input LOAD + saved command name keyword will automatically prompt related saved common commands, After selecting the command to be loaded, press the Input key to automatically load the corresponding common command.\nCommon command list #  In the list of common commands, you can query the saved common commands\nClick the name column of common commands in the list to view the specific information of common commands, and you can also modify the name and tag information\nDelete common commands #  Click the Delete button in the list of frequently used commands to confirm twice, and then execute the delete operation.\n","subcategory":null,"summary":"","tags":null,"title":"Common Commands","url":"/console/main/docs/reference/dev-tools/command/"},{"category":null,"content":"Cluster Monitoring #  Introduction #  When the monitoring of the registered cluster is enabled, the INFINI Console will periodically collect data from the target cluster according to the corresponding configuration. Including some metrics at the cluster, node, and index level. These metrics can then be observed in cluster monitoring to understand the running status of the target cluster.\nList of Elasticsearch API permissions required for monitoring :\n _cluster/health _cluster/stats _cat/shards _nodes/\u0026lt;node_id\u0026gt;/stats _cat/indices _stats _cluster/state _nodes _alias _cluster/settings  Enable Cluster Monitoring #  When registering the cluster or modifying the cluster configuration, you can see the following interface\nYou can see that there is a Monitored switch. When this switch is turned on, it means that the current cluster is monitored. When a cluster is registered, monitoring is enabled by default. The monitoring configuration includes cluster health metrics, cluster metrics, node metrics and index metrics. And you can set whether to open and the collection time interval respectively.\n The above are the settings for a single cluster. In the configuration file console.yaml, you can set the monitoring start and stop of all clusters. By default, you can see the following configuration in the configuration file:\nmetrics: enabled: true major_ip_pattern: \u0026quot;192.*\u0026quot; queue: metrics elasticsearch: enabled: true cluster_stats: true node_stats: true index_stats: true If metrics\u0026gt;enable is set to false, then all cluster monitoring is disabled; If metrics\u0026gt;elasticsearch\u0026gt;cluster_stats\u0026gt;enabled is set to false, then all The cluster will not collect related metrics at the cluster level.\n View Cluster Metrics #  After monitoring is enabled, you can view the monitoring information of the cluster in the monitoring report under the platform management on the left menu of INFINI Console, as follows:\nClick the Advanced tab to view more metrics at the cluster level;\nAs shown in the figure, you can specify multiple nodes in a cluster to view node-related metrics and compare them horizontally. By default, the top 5 node metrics are displayed (top 5 nodes are calculated based on the sum of the query qps and write qps of the node in the last 15 minutes). Switching to the index tab page here can also specify several related metrics to view the index, similar to the node. Switch to the Thread Pool tab to view the related metrics of the node\u0026rsquo;s thread pool.\nView Cluster TopN Metrics #  TopN is designed to quickly identify the top N key metric data points. With powerful multidimensional comparative analysis capabilities, it helps users optimize performance and make informed decisions more efficiently.\nFor detailed instructions on how to use TopN, please refer to this blog: Getting Started with the TopN Metrics Feature in INFINI Console\nView Cluster Logs #  View Node Metrics #  Click the Nodes tab to view a list of cluster nodes.\nClick the node name in the list to view the monitoring of the specified node.\nHere you can view the metrics monitoring information and related fragmentation information of a single node.\nView Index Metrics #  Click the Indexes tab to see a list of cluster indexes.\nClick the index name in the list to view the monitoring of the specified index\n","subcategory":null,"summary":"","tags":null,"title":"Cluster Monitoring","url":"/console/main/docs/reference/platform/monitoring/"},{"category":null,"content":"Cluster Management #  Introduction #  Cluster management can quickly and easily help us manage multiple Elasticsearch clusters across versions.\nCluster list #  The registered Elasticsearch cluster can be queried in the cluster list\nCluster registration #  The first step is to fill in the cluster address, and enable TLS and authentication as needed (you need to input a user name and password after enabling authentication).\nThe second step is to confirm the information\n Modify the cluster name and cluster description as needed; Whether to enable monitoring (enabled by default), after enabling monitoring, you can view various metrics of the Elasticsearch cluster in the console monitoring function Whether to enable Discovery (recommended), after enabling, the console will automatically discover all nodes in the cluster. When the configured cluster address is unavailable, the console will try to use the automatically discovered addresses available in other nodes to interact with Elasticsearch  Update cluster configuration #  Click the Edit button in the cluster list table to input the update interface\nModify the configuration as needed, then click the save button to submit\nDelete cluster #  Click the delete button in the cluster list table to confirm the second time. After confirming the deletion, execute the delete operation.\n","subcategory":null,"summary":"","tags":null,"title":"Cluster","url":"/console/main/docs/reference/resource/cluster/"},{"category":null,"content":"Alias Management #  Alias list #  The alias list includes addition, deletion, modification, and search operations for aliases.\nNew alias #   Alias: Input an alias name Index: Select the target index corresponding to the alias, and use (*) to bind multiple indexes. Is Write Index: specify whether the selected index is writable. If the alias only binds one index, the index is writable by default; if multiple indexes are bound by (*), it is most necessary to specify one of the indexes as writable .  Alias and index relationship list #  Clicking the + button at the beginning of the alias list row will expand and display the index list bound to the alias, and at the same time, you can set and delete the relational binding update of the index.\n","subcategory":null,"summary":"","tags":null,"title":"Alias","url":"/console/main/docs/reference/data/alias/"},{"category":null,"content":"Runtime Management #  Introduction #  Runtime Management allows for quick and convenient administration of multiple runtime instances (such as gateway, console, agent, etc.).\nInstance List #  You can view the list of created instances.\nCreate Instance #  Step 1: Enter the instance address, and optionally enable TLS and authentication (if authentication is enabled, a username and password are required).\nStep 2: Confirm the information, and optionally modify the instance name, tags, and description.\nUpdate Instance Configuration #  Click the edit button in the instance list row to enter the edit interface.\nModify the configuration as needed, then click the save button to submit.\nDelete Instance #  Click the delete button in the instance list row to perform a secondary confirmation. After confirming, the instance will be deleted.\n","subcategory":null,"summary":"","tags":null,"title":"Runtime","url":"/console/main/docs/reference/resource/runtime/"},{"category":null,"content":"Platform Overview #  Introduction #  You can view the main indicators at these levels(cluster, node, indice and host) to understand the operation status.\nClusters #  By switching between list and card views, users can explore cluster status information from multiple perspectives.\n1. List mode #  2. Card mode #  Clicking on a single row provides a quick preview of key cluster metrics and access to more detailed cluster information.\nNodes #  Indices #  ","subcategory":null,"summary":"","tags":null,"title":"Platform Overview","url":"/console/main/docs/reference/platform/overview/"},{"category":null,"content":"Messages #  Introduction #  By default, the message center displays the alerting events that are currently occurring in the system, which is convenient for administrators to quickly preview the execution status of the system.\nMessage list #  The message list aggregates all triggered alerting events. If each alerting rule repeatedly triggers multiple alerting messages, only one will be aggregated and displayed here. Click the details to see more information.\nMessage details #  Click the Details button in the message list row and column to view the detailed content of the current alerting event message, including the basic information of the event message, the timing curve within the event trigger period, and the history of rule execution detection, etc., as shown in the following figure:\nIgnore warning messages #  If you think that the alerting event does not need to be processed or is not important, you can ignore it. After ignoring, the alerting message will not be displayed in the message list by default, but it can be queried by status filtering.\nOperation steps: Click the ignore button in the message list form to confirm the second time, fill in the ignore reason, and execute the ignore operation after submitting.\n","subcategory":null,"summary":"","tags":null,"title":"Messages","url":"/console/main/docs/reference/alerting/message/"},{"category":null,"content":"Index management #  Index list #  The index list includes addition, deletion, modification, and lookup operations on indexes.\nNew index #  Input the new index name and index settings to complete the addition.\nIndex details #  You can view the index health status, number of shards, number of documents, storage size and other details, as well as view and modify Mappings and Edit settings.\n","subcategory":null,"summary":"","tags":null,"title":"Index","url":"/console/main/docs/reference/data/indices/"},{"category":null,"content":"Dev Tools #  Introduction #  Use Dev Tools to quickly write and execute Elasticsearch queries and other elasticsearch APIs. When installation verification is enabled, all requests will go through API level permission verification\nOpen Dev Tools #  Use the Ctrl+Shift+O shortcut to open or click the icon in the upper right corner of the console.\nExecute request shortcuts #  Command+Enter or Ctrl+Enter\nMulti-cluster multi-tab page support #  The Dev Tools supports the use of tab pages to open multiple clusters at the same time. Even if it is the same cluster, multiple clusters can be opened, and the status of the tab pages is independent. The tab page uses the cluster name as the title by default, and can be modified by double-clicking the tab page title. Below the Dev Tools is a status bar, and on the left is the health status, http address, and version information of the current cluster. On the right is the response status and duration of the elasticsearch interface request.\nView request header information #  After using the Dev Tools to execute the elasticsearch request, you can click the headers Tab page on the right to view the request header information.\n","subcategory":null,"summary":"","tags":null,"title":"Dev Tools","url":"/console/main/docs/reference/dev-tools/dev-tools/"}]
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Getting Started on Coco Server</title><link>/coco-server/v0.5.0/docs/getting-started/</link><description>Recent content in Getting Started on Coco Server</description><generator>Hugo -- gohugo.io</generator><atom:link href="/coco-server/v0.5.0/docs/getting-started/index.xml" rel="self" type="application/rss+xml"/><item><title>Installation</title><link>/coco-server/v0.5.0/docs/getting-started/install/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/coco-server/v0.5.0/docs/getting-started/install/</guid><description>Getting Started # Quickstart with Docker # # -------------------------------------------------- # Coco Server Docker Deployment Script and Commands # -------------------------------------------------- # Quick Start Coco Server (using default configuration) # # Command Explanation: # docker run: Create and run a new Docker container # -d: Run the container in the background (detached mode) # --name cocoserver: Assign a name to the container (cocoserver) # -p 9000:9000: Map the container&amp;#39;s port 9000 to the host&amp;#39;s port 9000 (Web UI port) # infinilabs/coco:0.</description></item><item><title>Setup Wizard</title><link>/coco-server/v0.5.0/docs/getting-started/setup/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/coco-server/v0.5.0/docs/getting-started/setup/</guid><description>Setup Wizard # Open your browser and enter http://localhost:9000/#/guide to access the initialization wizard, as shown below:
Enter your username, email, and password, then click Next, as shown:
Select the LLM type: DeepSeek, Ollama, or OpenAI Configure the LLM endpoint Set the default model Enable keepalive and set an appropriate interval Provide the token Click Next to complete the initialization. Login # After initialization, youâ€™ll be redirected to the login page, as shown:</description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Enrichment on Coco Server</title><link>/coco-server/main/docs/references/pipeline_processors/enrichment/</link><description>Recent content in Enrichment on Coco Server</description><generator>Hugo -- gohugo.io</generator><atom:link href="/coco-server/main/docs/references/pipeline_processors/enrichment/index.xml" rel="self" type="application/rss+xml"/><item><title>File Type Detection</title><link>/coco-server/main/docs/references/pipeline_processors/enrichment/file_type_detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/coco-server/main/docs/references/pipeline_processors/enrichment/file_type_detection/</guid><description>File Type Detection Processor # Detects file types based on file extensions and sets appropriate metadata.
Configuration # Parameter Type Default Description message_field string documents The field in the pipeline context containing the documents to process output_queue object null Optional queue configuration for sending processed documents to a output queue Example # - file_type_detection: {}</description></item><item><title>Misc File Extraction</title><link>/coco-server/main/docs/references/pipeline_processors/enrichment/file_extraction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/coco-server/main/docs/references/pipeline_processors/enrichment/file_extraction/</guid><description>Misc File Extraction Processor # Comprehensive file processing for various file types. Extracts text content, metadata, generates thumbnails, and performs face detection.
Configuration # Parameter Type Required Default Description message_field string documents The field in the pipeline context containing the documents to process output_queue object null Optional queue configuration for sending processed documents to a output queue tika_endpoint string No http://127.</description></item><item><title>Summary</title><link>/coco-server/main/docs/references/pipeline_processors/enrichment/document_summarization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/coco-server/main/docs/references/pipeline_processors/enrichment/document_summarization/</guid><description>Summary Processor # Generates AI-powered document summaries and insights with structured analysis.
Configuration # Parameter Type Required Default Description message_field string documents The field in the pipeline context containing the documents to process output_queue object null Optional queue configuration for sending processed documents to a output queue model_provider string Yes - ID of the LLM provider model string Yes - Name of the LLM model model_context_length uint32 Yes - Minimum context length (min: 4000 tokens) min_input_document_length uint32 No 100 Minimum bytes to process a document max_input_document_length uint32 No 100000 Maximum document size to process ai_insights_max_length uint32 No 500 Target length for AI insights (in tokens) Example # - document_summarization: model_provider: openai model: gpt-4o-mini model_context_length: 4000 min_input_document_length: 100 max_input_document_length: 100000 ai_insights_max_length: 500</description></item><item><title>Extract Tags</title><link>/coco-server/main/docs/references/pipeline_processors/enrichment/extract_tags/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/coco-server/main/docs/references/pipeline_processors/enrichment/extract_tags/</guid><description>Extract Tags Processor # Extracts structured tags from AI insights stored in document metadata using an LLM.
Configuration # Parameter Type Required Default Description message_field string documents The field in the pipeline context containing the documents to process output_queue object null Optional queue configuration for sending processed documents to a output queue model_provider string Yes - ID of the LLM provider model string Yes - Name of the LLM model model_context_length uint32 Yes - Minimum context length (min: 4000 tokens) Example # - extract_tags: model_provider: openai model: gpt-4o-mini model_context_length: 4000</description></item><item><title>Embedding</title><link>/coco-server/main/docs/references/pipeline_processors/enrichment/document_embedding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/coco-server/main/docs/references/pipeline_processors/enrichment/document_embedding/</guid><description>Embedding Processor # Generates vector embeddings for document chunks using AI models.
This processor enables semantic search and retrieval by converting text chunks into dense vector representations.
Configuration # Parameter Type Required Default Description message_field string documents The field in the pipeline context containing the documents to process output_queue object null Optional queue configuration for sending processed documents to a output queue model_provider string Yes - ID of the AI model provider for embeddings model string Yes - Name of the embedding model (e.</description></item></channel></rss>
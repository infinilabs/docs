<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Getting Started on Coco Server</title><link>/coco-server/v0.9.1/docs/getting-started/</link><description>Recent content in Getting Started on Coco Server</description><generator>Hugo -- gohugo.io</generator><atom:link href="/coco-server/v0.9.1/docs/getting-started/index.xml" rel="self" type="application/rss+xml"/><item><title>Installation</title><link>/coco-server/v0.9.1/docs/getting-started/install/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/coco-server/v0.9.1/docs/getting-started/install/</guid><description>Coco Server User Guide # Run Coco Server with Docker Manual install Coco Server 1. Quick Start (Recommended for Most Users) # This method is the simplest way to get Coco Server running. It uses Docker-managed volumes, which handles data persistence automatically without requiring manual directory setup on your host machine.
Command:
docker run -d \ --name cocoserver \ -p 9000:9000 \ -v coco_data_vol:/app/easysearch/data \ -v coco_config_vol:/app/easysearch/config \ -v coco_logs_vol:/app/easysearch/logs \ infinilabs/coco:0.</description></item><item><title>Setup Wizard</title><link>/coco-server/v0.9.1/docs/getting-started/setup/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/coco-server/v0.9.1/docs/getting-started/setup/</guid><description>Setup Wizard # Open your browser and enter http://localhost:9000/#/guide to access the initialization wizard, as shown below:
Enter your username, email, and password, then click Next, as shown:
Select the LLM type: DeepSeek, Ollama, or OpenAI Configure the LLM endpoint Set the default model Enable keepalive and set an appropriate interval Provide the token Click Next to complete the initialization. Login # After initialization, youâ€™ll be redirected to the login page, as shown:</description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>离线处理器 on INFINI Gateway</title><link>/gateway/v1.29.6/zh/docs/references/processors/</link><description>Recent content in 离线处理器 on INFINI Gateway</description><generator>Hugo -- gohugo.io</generator><atom:link href="/gateway/v1.29.6/zh/docs/references/processors/index.xml" rel="self" type="application/rss+xml"/><item><title>bulk_indexing</title><link>/gateway/v1.29.6/zh/docs/references/processors/bulk_indexing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/bulk_indexing/</guid><description>bulk_indexing # 描述 # bulk_indexing 处理器用来异步消费队列里面的 bulk 请求。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - bulk_indexing: queue_selector.labels: type: bulk_reshuffle level: cluster 参数说明 # 名称 类型 说明 elasticsearch string 默认的 Elasticsearch 集群 ID,如果队列 Labels 里面没有指定 elasticsearch 的话会使用这个参数 max_connection_per_node int 目标节点允许的最大连接数，默认 1 max_worker_size int 最大允许同时运行的 worker 大小,默认 10 num_of_slices int 并行消费单个队列的线程, 运行时最大的 slice 大小 slices array 允许的 slice 编号, int 数组 queue_selector.</description></item><item><title>consumer</title><link>/gateway/v1.29.6/zh/docs/references/processors/consumer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/consumer/</guid><description>consumer # 描述 # consumer 处理器用来消费 queue 记录的消息请求，但是不处理，目标是提供数据消费管道的入口，由后续的 processor 进行数据加工。
配置示例 # 一个简单的示例如下：
pipeline: - name: consume_queue_messages auto_start: true keep_running: true retry_delay_in_ms: 5000 processor: - consumer: consumer: fetch_max_messages: 1 max_worker_size: 200 num_of_slices: 1 idle_timeout_in_seconds: 30 queue_selector: keys: - email_messages processor: - xxx1: - xxx2: 上面的例子，订阅并消费队列 email_messages，队列消息保存在当前 Pipeline 管道的上下文里面，Consumer 提供了一个 processor 参数，这个参数里面是一系列 Processor，依次执行，任何一个 Processor 如果执行返回出错，consumer 则退出切不会 commit 这批数据。
参数说明 # 名称 类型 说明 message_field string 从队列获取到的消息，存放到上下文的字段名称, 默认 messages max_worker_size int 最大允许同时运行的 worker 大小,默认 10 num_of_slices int 并行消费单个队列的线程, 运行时最大的 slice 大小 slices array 允许的 slice 编号, int 数组 queue_selector.</description></item><item><title>dag</title><link>/gateway/v1.29.6/zh/docs/references/processors/dag/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/dag/</guid><description>dag # 描述 # dag 处理器用来管理任务的并行调度。
配置示例 # 下面的这个例子，定义了一个名为 racing_example 的服务，auto_start 设置为自动启动，processor 设置依次执行的每个处理单元，其中 dag 处理器支持多个任务并行执行，支持 wait_all 和 first_win 两种聚合模式，如下：
pipeline: - name: racing_example auto_start: true processor: - echo: #ready, set, go message: read,set,go - dag: mode: wait_all #first_win, wait_all parallel: - echo: #player1 message: player1 - echo: #player2 message: player2 - echo: #player3 message: player3 end: - echo: #checking score message: checking score - echo: #announce champion message: 'announce champion' - echo: #done message: racing finished 上面的 echo 处理器非常简单，用来输出一个指定的消息，这个管道模拟的是一个赛跑的场景，palyer1、2、3 并行赛跑，全部跑完之后再进行算分和宣布比赛冠军，最后输出结束信息，程序运行输出如下：</description></item><item><title>dump_hash</title><link>/gateway/v1.29.6/zh/docs/references/processors/dump_hash/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/dump_hash/</guid><description>dump_hash # 描述 # dump_hash 处理器用来导出集群的索引文档并计算 Hash。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - dump_hash: #dump es1's doc indices: &amp;quot;medcl-dr3&amp;quot; scroll_time: &amp;quot;10m&amp;quot; elasticsearch: &amp;quot;source&amp;quot; query: &amp;quot;field1:elastic&amp;quot; fields: &amp;quot;doc_hash&amp;quot; output_queue: &amp;quot;source_docs&amp;quot; batch_size: 10000 slice_size: 5 参数说明 # 名称 类型 说明 elasticsearch string 目标集群的名称 scroll_time string Scroll 回话超时时间 batch_size int Scroll 批次大小，默认 5000 slice_size int Slice 大小，默认 1 sort_type string 文档排序类型，默认 asc sort_field string 文档排序字段 indices string 索引 level string 请求处理级别，可以设置为 cluster 则表示请求不进行节点和分片级别的拆分，适用于 Elasticsearch 前有代理的情况 query string 查询过滤条件 fields string 要返回的字段列表 sort_document_fields bool hash 计算之前是否对 _source 里面的字段进行排序，默认 false hash_func string hash 函数，可选 xxhash32、xxhash64、fnv1a，默认 xxhash32 output_queue string 输出结果的队列名称</description></item><item><title>flow_replay</title><link>/gateway/v1.29.6/zh/docs/references/processors/flow_replay/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/flow_replay/</guid><description>flow_replay # 描述 # flow_replay 处理器用来异步消费队列里面的请求并使用异步用于在线请求的处理流程来进行消费处理。
配置示例 # 一个简单的示例如下：
pipeline: - name: backup-flow-request-reshuffle auto_start: true keep_running: true singleton: true retry_delay_in_ms: 10 processor: - consumer: max_worker_size: 100 queue_selector: labels: type: &amp;quot;primary_write_ahead_log&amp;quot; consumer: group: request-reshuffle fetch_max_messages: 10000 fetch_max_bytes: 20485760 fetch_max_wait_ms: 10000 processor: - flow_replay: flow: backup-flow-request-reshuffle commit_on_tag: &amp;quot;commit_message_allowed&amp;quot; 参数说明 # 名称 类型 说明 message_field string 从队列获取到的消息，存放到上下文的字段名称, 默认 messages flow string 以什么样的流程来消费队列里面的请求消息 commit_on_tag string 只有当前请求的上下文里面出现指定 tag 才会 commit 消息，默认为空表示执行完就 commit</description></item><item><title>flow_runner</title><link>/gateway/v1.29.6/zh/docs/references/processors/flow_runner/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/flow_runner/</guid><description>flow_runner # 描述 # flow_runner 处理器用来异步消费队列里面的请求并使用异步用于在线请求的处理流程来进行消费处理。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - flow_runner: input_queue: &amp;quot;primary_deadletter_requests&amp;quot; flow: primary-flow-post-processing when: cluster_available: [ &amp;quot;primary&amp;quot; ] 参数说明 # 名称 类型 说明 input_queue string 订阅的队列名称 flow string 以什么样的流程来消费队列里面的请求消息 commit_on_tag string 只有当前请求的上下文里面出现指定 tag 才会 commit 消息，默认为空表示执行完就 commit</description></item><item><title>index_diff</title><link>/gateway/v1.29.6/zh/docs/references/processors/index_diff/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/index_diff/</guid><description>index_diff # 描述 # index_diff 处理器用来对两个结果集进行差异对比。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - index_diff: diff_queue: &amp;quot;diff_result&amp;quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 参数说明 # 名称 类型 说明 source_queue string 来源数据的名称 target_queue string 目标数据的名称 diff_queue string 存放 diff 结果的队列 buffer_size int 内存 buffer 大小 keep_source bool diff 结果里面是否包含文档 source 信息 text_report bool 是否输出文本格式的结果</description></item><item><title>indexing_merge</title><link>/gateway/v1.29.6/zh/docs/references/processors/indexing_merge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/indexing_merge/</guid><description>indexing_merge # 描述 # indexing_merge 处理器用来消费队列里面的纯 JSON 文档，并合并成 Bulk 请求保存到指定的队列里面，需要配合 bulk_indexing 处理器进行消费，用批量写入代替单次请求来提高写入吞吐。
配置示例 # 一个简单的示例如下：
pipeline: - name: indexing_merge auto_start: true keep_running: true processor: - indexing_merge: input_queue: &amp;quot;request_logging&amp;quot; elasticsearch: &amp;quot;logging-server&amp;quot; index_name: &amp;quot;infini_gateway_requests&amp;quot; output_queue: name: &amp;quot;gateway_requests&amp;quot; label: tag: &amp;quot;request_logging&amp;quot; worker_size: 1 bulk_size_in_mb: 10 - name: logging_requests auto_start: true keep_running: true processor: - bulk_indexing: bulk: compress: true batch_size_in_mb: 10 batch_size_in_docs: 5000 consumer: fetch_max_messages: 100 queues: type: indexing_merge when: cluster_available: [ &amp;quot;logging-server&amp;quot; ] 参数说明 # 名称 类型 说明 input_queue string 订阅的队列名称 worker_size int 并行执行消费任务的线程数，默认 1 idle_timeout_in_seconds int 消费队列的超时时间，默认 5，单位秒 bulk_size_in_kb int 批次请求的单位大小，单位 KB bulk_size_in_mb int 批次请求的单位大小，单位 MB，默认 10 elasticsearch string 保存到目标集群的名称 index_name string 保存到目标集群的索引名称 type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc output_queue.</description></item><item><title>json_indexing</title><link>/gateway/v1.29.6/zh/docs/references/processors/json_indexing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/json_indexing/</guid><description>json_indexing # 描述 # json_indexing 处理器用来消费队列里面的纯 JSON 文档，并保存到指定的 Elasticsearch 服务器里面。
配置示例 # 一个简单的示例如下：
pipeline: - name: request_logging_index auto_start: true keep_running: true processor: - json_indexing: index_name: &amp;quot;gateway_requests&amp;quot; elasticsearch: &amp;quot;dev&amp;quot; input_queue: &amp;quot;request_logging&amp;quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 参数说明 # 名称 类型 说明 input_queue string 订阅的队列名称 worker_size int 并行执行消费任务的线程数，默认 1 idle_timeout_in_seconds int 消费队列的超时时间，默认 5，单位秒 bulk_size_in_kb int 批次请求的单位大小，单位 KB bulk_size_in_mb int 批次请求的单位大小，单位 MB elasticsearch string 保存到目标集群的名称 index_name string 保存到目标集群的索引名称 type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc</description></item><item><title>merge_to_bulk</title><link>/gateway/v1.29.6/zh/docs/references/processors/merge_to_bulk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/merge_to_bulk/</guid><description>merge_to_bulk # 描述 # merge_to_bulk 处理器用来消费队列里面的纯 JSON 文档，并合并成 Bulk 请求保存到指定的队列里面，需要配合 consumer 处理器进行消费，用批量写入代替单次请求来提高写入吞吐。
配置示例 # 一个简单的示例如下：
pipeline: - name: messages_merge_async_bulk_results auto_start: true keep_running: true singleton: true processor: - consumer: queue_selector: keys: - bulk_result_messages consumer: group: merge_to_bulk processor: - merge_to_bulk: elasticsearch: &amp;quot;logging&amp;quot; index_name: &amp;quot;.infini_async_bulk_results&amp;quot; output_queue: name: &amp;quot;merged_async_bulk_results&amp;quot; label: tag: &amp;quot;bulk_logging&amp;quot; worker_size: 1 bulk_size_in_mb: 10 参数说明 # 名称 类型 说明 message_field string 从队列获取到的消息，存放到上下文的字段名称, 默认 messages bulk_size_in_kb int 批次请求的单位大小，单位 KB bulk_size_in_mb int 批次请求的单位大小，单位 MB，默认 10 elasticsearch string 保存到目标集群的名称 index_name string 保存到目标集群的索引名称 type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc output_queue.</description></item><item><title>queue_consumer</title><link>/gateway/v1.29.6/zh/docs/references/processors/queue_consumer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/queue_consumer/</guid><description>queue_consumer # 描述 # queue_consumer 处理器用来异步消费队列里面的请求到 Elasticsearch。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - queue_consumer: input_queue: &amp;quot;backup&amp;quot; elasticsearch: &amp;quot;backup&amp;quot; waiting_after: [ &amp;quot;backup_failure_requests&amp;quot;] worker_size: 20 when: cluster_available: [ &amp;quot;backup&amp;quot; ] 参数说明 # 名称 类型 说明 input_queue string 订阅的队列名称 worker_size int 并行执行消费任务的线程数，默认 1 idle_timeout_in_seconds int 消费队列的超时时间，默认 1 elasticsearch string 保存到目标集群的名称 waiting_after array 需要先等将这些指定队列消费完才能开始消费主队列里面的数据 failure_queue string 因为后端故障执行失败的请求，默认为 %input_queue%-failure invalid_queue string 状态码返回为 4xx 的请求，默认为 %input_queue%-invalid compress bool 是否压缩请求，默认 false safety_parse bool 是否启用安全解析，即不采用 buffer 的方式，占用内存更高一点，默认为 true doc_buffer_size bool 单次请求处理的最大文档 buff size，建议设置超过单个文档的最大大小，默认 256*1024</description></item><item><title>replay</title><link>/gateway/v1.29.6/zh/docs/references/processors/replay/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/replay/</guid><description>replay # 描述 # replay 处理器用来重放 record 过滤器记录的请求。
配置示例 # 一个简单的示例如下：
pipeline: - name: play_requests auto_start: true keep_running: false processor: - replay: filename: requests.txt schema: &amp;quot;http&amp;quot; host: &amp;quot;localhost:8000&amp;quot; 参数说明 # 名称 类型 说明 filename string 包含重放消息的文件名称 schema string 请求协议类型，http 或 https host string 接受请求的目标服务器，格式 host:port</description></item><item><title>smtp</title><link>/gateway/v1.29.6/zh/docs/references/processors/smtp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/v1.29.6/zh/docs/references/processors/smtp/</guid><description>smtp # 描述 # smtp 处理器用来发送邮件，支持普通的文本邮件和 HTML 邮件，支持模版变量，支持附件嵌入到邮件正文，邮件的消息来自上下文。
配置示例 # 一个简单的示例如下：
pipeline: - name: send_email auto_start: true keep_running: true retry_delay_in_ms: 5000 processor: - consumer: consumer: fetch_max_messages: 1 max_worker_size: 200 num_of_slices: 1 idle_timeout_in_seconds: 30 queue_selector: keys: - email_messages processor: - smtp: idle_timeout_in_seconds: 1 server: host: &amp;quot;smtp.ym.163.com&amp;quot; port: 994 tls: true auth: username: &amp;quot;notify-test@infini.ltd&amp;quot; password: &amp;quot;xxx&amp;quot; sender: &amp;quot;notify-test@infini.ltd&amp;quot; recipients: # to: [&amp;quot;Test &amp;lt;medcl@infini.ltd&amp;gt;&amp;quot;] # cc: [&amp;quot;INFINI Labs &amp;lt;hello@infini.ltd&amp;gt;&amp;quot;] variables: #default variables, can be used in templates license_code: &amp;quot;N/A&amp;quot; templates: trial_license: subject: &amp;quot;$[[name]] 您好，请查收您的免费授权信息!</description></item></channel></rss>
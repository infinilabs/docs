[{"category":null,"content":"translog #  描述 #  translog 过滤器用来将收到的请求保存到本地文件，并压缩存放，可记录部分或完整的请求日志，用于归档和请求重放。\n配置示例 #  一个简单的示例如下：\nflow: - name: translog filter: - translog: max_file_age: 7 max_file_count: 10 参数说明 #     名称 类型 说明     path string 日志存放根目录，默认为网关数据目录下的 translog 子目录   category string 区分不同日志的二级分类子目录，默认为 default   filename string 设置日志的文件名，默认为 translog.log   rotate.compress_after_rotate bool 文件滚动之后是否压缩归档，默认为 true   rotate.max_file_age int 最多保留的归档文件天数，默认为 30 天   rotate.max_file_count int 最多保留的归档文件个数，默认为 100 个   rotate.max_file_size_in_mb int 单个归档文件的最大字节数，默认为 1024 MB    ","subcategory":null,"summary":"","tags":null,"title":"translog","url":"/gateway/v1.29.7/zh/docs/references/filters/translog/"},{"category":null,"content":"switch #  描述 #  switch 过滤器用来将流量按照请求路径转发到另外的一个处理流程，可以方便的实现跨集群操作，且 Elasticsearch 集群不需要做任何修改，且各个集群内所有的 API 都可以访问，包括索引的读写和集群操作。\n配置示例 #  一个简单的示例如下：\nflow: - name: es1-flow filter: - elasticsearch: elasticsearch: es1 - name: es2-flow filter: - elasticsearch: elasticsearch: es2 - name: cross_cluste_search filter: - switch: path_rules: - prefix: \u0026quot;es1:\u0026quot; flow: es1-flow - prefix: \u0026quot;es2:\u0026quot; flow: es2-flow - elasticsearch: elasticsearch: dev #elasticsearch configure reference name 上面的例子中，以 es1: 开头的索引将转发给集群 es1 集群，以 es2: 开头的索引转发给 es2 集群，不匹配的转发给 dev 集群，在一个 Kibana 里面可以直接操作不同版本的集群了，如下：\n# GET es1:_cluster/health { \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;status\u0026quot; : \u0026quot;yellow\u0026quot;, \u0026quot;timed_out\u0026quot; : false, \u0026quot;number_of_nodes\u0026quot; : 1, \u0026quot;number_of_data_nodes\u0026quot; : 1, \u0026quot;active_primary_shards\u0026quot; : 37, \u0026quot;active_shards\u0026quot; : 37, \u0026quot;relocating_shards\u0026quot; : 0, \u0026quot;initializing_shards\u0026quot; : 0, \u0026quot;unassigned_shards\u0026quot; : 9, \u0026quot;delayed_unassigned_shards\u0026quot; : 0, \u0026quot;number_of_pending_tasks\u0026quot; : 0, \u0026quot;number_of_in_flight_fetch\u0026quot; : 0, \u0026quot;task_max_waiting_in_queue_millis\u0026quot; : 0, \u0026quot;active_shards_percent_as_number\u0026quot; : 80.43478260869566 } GET es2:_cluster/health { \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;status\u0026quot; : \u0026quot;yellow\u0026quot;, \u0026quot;timed_out\u0026quot; : false, \u0026quot;number_of_nodes\u0026quot; : 1, \u0026quot;number_of_data_nodes\u0026quot; : 1, \u0026quot;active_primary_shards\u0026quot; : 6, \u0026quot;active_shards\u0026quot; : 6, \u0026quot;relocating_shards\u0026quot; : 0, \u0026quot;initializing_shards\u0026quot; : 0, \u0026quot;unassigned_shards\u0026quot; : 6, \u0026quot;delayed_unassigned_shards\u0026quot; : 0, \u0026quot;number_of_pending_tasks\u0026quot; : 0, \u0026quot;number_of_in_flight_fetch\u0026quot; : 0, \u0026quot;task_max_waiting_in_queue_millis\u0026quot; : 0, \u0026quot;active_shards_percent_as_number\u0026quot; : 50.0 } 通过命令行也同样可以：\nroot@infini:/opt/gateway# curl -v 192.168.3.4:8000/es1:_cat/nodes * Trying 192.168.3.4... * TCP_NODELAY set * Connected to 192.168.3.4 (192.168.3.4) port 8000 (#0) \u0026gt; GET /es1:_cat/nodes HTTP/1.1 \u0026gt; Host: 192.168.3.4:8000 \u0026gt; User-Agent: curl/7.58.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Thu, 14 Oct 2021 10:37:39 GMT \u0026lt; content-type: text/plain; charset=UTF-8 \u0026lt; Content-Length: 45 \u0026lt; X-Backend-Cluster: dev1 \u0026lt; X-Backend-Server: 192.168.3.188:9299 \u0026lt; X-Filters: filters-\u0026gt;switch-\u0026gt;filters-\u0026gt;elasticsearch-\u0026gt;skipped \u0026lt; 192.168.3.188 48 38 5 cdhilmrstw * LENOVO * Connection #0 to host 192.168.3.4 left intact root@infini:/opt/gateway# curl -v 192.168.3.4:8000/es2:_cat/nodes * Trying 192.168.3.4... * TCP_NODELAY set * Connected to 192.168.3.4 (192.168.3.4) port 8000 (#0) \u0026gt; GET /es2:_cat/nodes HTTP/1.1 \u0026gt; Host: 192.168.3.4:8000 \u0026gt; User-Agent: curl/7.58.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Thu, 14 Oct 2021 10:37:48 GMT \u0026lt; content-type: text/plain; charset=UTF-8 \u0026lt; Content-Length: 146 \u0026lt; X-elastic-product: Elasticsearch \u0026lt; Warning: 299 Elasticsearch-7.14.0-dd5a0a2acaa2045ff9624f3729fc8a6f40835aa1 \u0026quot;Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.14/security-minimal-setup.html to enable security.\u0026quot; \u0026lt; X-Backend-Cluster: dev \u0026lt; X-Backend-Server: 192.168.3.188:9216 \u0026lt; X-Filters: filters-\u0026gt;switch-\u0026gt;filters-\u0026gt;elasticsearch-\u0026gt;skipped \u0026lt; 192.168.3.188 26 38 3 cdfhilmrstw - node-714-1 192.168.3.188 45 38 3 cdfhilmrstw * LENOVO 192.168.3.188 43 38 4 cdfhilmrstw - node-714-2 * Connection #0 to host 192.168.3.4 left intact 参数说明 #\n    名称 类型 说明     path_rules array 根据 URL 路径的匹配规则   path_rules.prefix string 匹配的不包含 /开头的前缀字符串，，建议以 : 结尾，匹配之后会移除该 URL 前缀转发给后面的 flow。   path_rules.flow string 匹配之后用于处理该请求的 flow 名称。   remove_prefix bool 转发请求之前，是否移除前缀匹配上的字符串，默认 true   continue bool 匹配跳转之后，是否还继续执行后面的流程，设置成 false 则立即返回，默认 false。   unescape bool 是否对 path 参数进行 URL Decode 解码，默认 true.    ","subcategory":null,"summary":"","tags":null,"title":"switch","url":"/gateway/v1.29.7/zh/docs/references/filters/switch/"},{"category":null,"content":"smtp #  描述 #  smtp 处理器用来发送邮件，支持普通的文本邮件和 HTML 邮件，支持模版变量，支持附件嵌入到邮件正文，邮件的消息来自上下文。\n配置示例 #  一个简单的示例如下：\npipeline: - name: send_email auto_start: true keep_running: true retry_delay_in_ms: 5000 processor: - consumer: consumer: fetch_max_messages: 1 max_worker_size: 200 num_of_slices: 1 idle_timeout_in_seconds: 30 queue_selector: keys: - email_messages processor: - smtp: idle_timeout_in_seconds: 1 server: host: \u0026quot;smtp.ym.163.com\u0026quot; port: 994 tls: true auth: username: \u0026quot;notify-test@infini.ltd\u0026quot; password: \u0026quot;xxx\u0026quot; sender: \u0026quot;notify-test@infini.ltd\u0026quot; recipients: # to: [\u0026quot;Test \u0026lt;medcl@infini.ltd\u0026gt;\u0026quot;] # cc: [\u0026quot;INFINI Labs \u0026lt;hello@infini.ltd\u0026gt;\u0026quot;] variables: #default variables, can be used in templates license_code: \u0026quot;N/A\u0026quot; templates: trial_license: subject: \u0026quot;$[[name]] 您好，请查收您的免费授权信息! [INFINI Labs]\u0026quot; # content_type: 'text/plain' # body: \u0026quot;$[[name]] 您好，请查收您的免费授权信息! [INFINI Labs]\u0026quot; content_type: 'text/html' body_file: '/Users/medcl/go/src/infini.sh/ops/assets/email_templates/send_trial_license.html' # attachments: #use cid in html: \u0026lt;img width=100 height=100 id=\u0026quot;1\u0026quot; src=\u0026quot;cid:myimg1\u0026quot;\u0026gt; # - file: '/Users/medcl/Desktop/WechatIMG2783.png' # content_type: 'image/png' # cid: 'myimg1' 消息格式 #  SMTP 过滤器从上下文获取需要发送的邮件信息，如发给谁，使用哪个邮件模版，给邮件模版的变量参数等，消息格式为固定的，结果如下：\n{ \u0026quot;template\u0026quot;: \u0026quot;trial_license\u0026quot;, \u0026quot;email\u0026quot;:[\u0026quot;medcl@example.com\u0026quot;], \u0026quot;variables\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;Medcl\u0026quot;, \u0026quot;company\u0026quot;: \u0026quot;INFINI Labs\u0026quot;, \u0026quot;phone\u0026quot;: \u0026quot;400-139-9200\u0026quot; } } 字段 template 代表使用配置里面的模版，email 表示邮件的收件人信息，variables 定义了在模版里面需要用到的变量信息。\n参数说明 #     名称 类型 说明     dial_timeout_in_seconds int 发送邮件的超时时间设置   server.host string 邮件服务器地址   server.port int 邮件服务器端口   tls bool 是否开启 TLS 传输加密   auth.username string 邮件服务器访问身份   auth.password string 邮件服务器访问密码   sender string 发送人，默认和 auth.username 保持一致   recipients.to array 收件人，选填   recipients.cc array 抄送人，选填   recipients.bcc array 密送人，选填   templates[NAME].content_type string 邮件类型，text/plain 或者 text/html   templates[NAME].subject string 邮件主题，支持模版变量   templates[NAME].body string 邮件正文，支持模版变量   templates[NAME].body_file string 来自文件的邮件正文，支持模版变量   templates[NAME].attachments[i].cid string 附件CID，可以在正文中引用，如：\u0026lt;img width=100 height=100 id=\u0026quot;1\u0026quot; src=\u0026quot;cid:myimg1\u0026quot;\u0026gt;   templates[NAME].attachments[i].file string 附件文件路径   templates[NAME].attachments[i].content_type string 附件文件类型，参考：http://en.wikipedia.org/wiki/MIME   message_field string 变量来自的上下文字段，默认 message_field   variable_start_tag string 变量 Tag 前缀，默认 $[[   variable_end_tag string 变量 Tag 后缀，默认 ]]   variables array 内置变量， 可被上下文变量覆盖    ","subcategory":null,"summary":"","tags":null,"title":"smtp","url":"/gateway/v1.29.7/zh/docs/references/processors/smtp/"},{"category":null,"content":"sleep #  描述 #  sleep 过滤器用来添加一个固定的延迟到请求，可以人为降速。\n配置示例 #  一个简单的示例如下：\nflow: - name: slow_query_logging_test filter: - sleep: sleep_in_million_seconds: 1024 参数说明 #     名称 类型 说明     sleep_in_million_seconds int64 需要添加的延迟长度，单位为毫秒    ","subcategory":null,"summary":"","tags":null,"title":"sleep","url":"/gateway/v1.29.7/zh/docs/references/filters/sleep/"},{"category":null,"content":"set_response_header #  描述 #  set_response_header 过滤器用来设置请求响应的 Header 头信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_response_header filter: - set_response_header: headers: - Trial -\u0026gt; true - Department -\u0026gt; Engineering 参数说明 #     名称 类型 说明     headers map 使用 -\u0026gt; 作为标识符的键值对，用于设置 Header 信息    ","subcategory":null,"summary":"","tags":null,"title":"set_response_header","url":"/gateway/v1.29.7/zh/docs/references/filters/set_response_header/"},{"category":null,"content":"set_response #  描述 #  set_response 过滤器用来设置请求响应返回信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_response filter: - set_response: status: 200 content_type: application/json body: '{\u0026quot;message\u0026quot;:\u0026quot;hello world\u0026quot;}' 参数说明 #     名称 类型 说明     status int 请求状态码，默认 200   content_type string 设置请求返回的内容类型   body string 设置请求返回的结构体    ","subcategory":null,"summary":"","tags":null,"title":"set_response","url":"/gateway/v1.29.7/zh/docs/references/filters/set_response/"},{"category":null,"content":"set_request_query_args #  描述 #  set_request_query_args 过滤器用来设置请求的 QueryString 参数信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_request_query_args filter: - set_request_query_args: args: - size -\u0026gt; 10 为避免\n参数说明 #     名称 类型 说明     args map 使用 -\u0026gt; 作为标识符的键值对，用于设置 QueryString 参数信息    ","subcategory":null,"summary":"","tags":null,"title":"set_request_query_args","url":"/gateway/v1.29.7/zh/docs/references/filters/set_request_query_args/"},{"category":null,"content":"set_request_header #  描述 #  set_request_header 过滤器用来设置请求的 Header 头信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_request_header filter: - set_request_header: headers: - Trial -\u0026gt; true - Department -\u0026gt; Engineering 为避免\n参数说明 #     名称 类型 说明     headers map 使用 -\u0026gt; 作为标识符的键值对，用于设置 Header 信息    ","subcategory":null,"summary":"","tags":null,"title":"set_request_header","url":"/gateway/v1.29.7/zh/docs/references/filters/set_request_header/"},{"category":null,"content":"set_hostname #  描述 #  set_hostname 过滤器用来设置请求 Header 关于要访问的主机或域名信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_hostname filter: - set_hostname: hostname: api.infini.cloud 为避免\n参数说明 #     名称 类型 说明     hostname string 主机信息    ","subcategory":null,"summary":"","tags":null,"title":"set_hostname","url":"/gateway/v1.29.7/zh/docs/references/filters/set_hostname/"},{"category":null,"content":"set_context #  描述 #  set_context 过滤器用来设置请求上下文的相关信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - set_response: body: '{\u0026quot;message\u0026quot;:\u0026quot;hello world\u0026quot;}' - set_context: context: # _ctx.request.uri: http://baidu.com # _ctx.request.path: new_request_path # _ctx.request.host: api.infinilabs.com # _ctx.request.method: DELETE # _ctx.request.body: \u0026quot;hello world\u0026quot; # _ctx.request.body_json.explain: true # _ctx.request.query_args.from: 100 # _ctx.request.header.ENV: dev # _ctx.response.content_type: \u0026quot;application/json\u0026quot; # _ctx.response.header.TIMES: 100 # _ctx.response.status: 419 # _ctx.response.body: \u0026quot;new_body\u0026quot; _ctx.response.body_json.success: true - dump: request: true 参数说明 #     名称 类型 说明     context map 请求的上下文及对应的新值    支持的上下文变量列表如下：\n   名称 类型 说明     _ctx.request.uri string 完整请求的 URL 地址   _ctx.request.path string 请求的路径   _ctx.request.host string 请求的主机   _ctx.request.method string 请求 Method 类型   _ctx.request.body string 请求体   _ctx.request.body_json.[JSON_PATH] string JSON 请求对象的 Path   _ctx.request.query_args.[KEY] string URL 查询请求参数   _ctx.request.header.[KEY] string 请求头信息   _ctx.response.content_type string 请求体类型   _ctx.response.header.[KEY] string 返回头信息   _ctx.response.status int 返回状态码   _ctx.response.body string 返回响应体   _ctx.response.body_json.[JSON_PATH] string JSON 返回对象的 Path    ","subcategory":null,"summary":"","tags":null,"title":"set_context","url":"/gateway/v1.29.7/zh/docs/references/filters/set_context/"},{"category":null,"content":"set_basic_auth #  描述 #  set_basic_auth 过滤器用来设置请求的身份认证信息，可以用于重置请求的身份信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_basic_auth filter: - set_basic_auth: username: admin password: password 参数说明 #     名称 类型 说明     username string 用户名   password string 密码    ","subcategory":null,"summary":"","tags":null,"title":"set_basic_auth","url":"/gateway/v1.29.7/zh/docs/references/filters/set_basic_auth/"},{"category":null,"content":"security #  描述 #  security 过滤器用来对请求的 API 进行安全过滤，结合 Console 来进行统一的身份管理，包括鉴权和授权的集中化管控，同时支持与 LDAP 的身份集成。\n配置示例 #  一个简单的示例如下：\nflow: - name: security_request filter: - security: elasticsearch: es-server - elasticsearch: elasticsearch: es-server elastic: elasticsearch: es-server remote_configs: true health_check: enabled: false availability_check: enabled: false orm: enabled: true init_template: false init_schema: true index_prefix: \u0026quot;.infini_\u0026quot; elasticsearch:\n name: es-server enabled: true endpoints:  http://127.0.0.1:9200    security: enabled: true authc: realms: ldap:\ntest: #setup guide: https://github.com/infinilabs/testing/blob/main/setup/gateway/cases/elasticsearch/elasticsearch-with-ldap.yml enabled: true host: \u0026quot;localhost\u0026quot; port: 3893 bind_dn: \u0026quot;cn=serviceuser,ou=svcaccts,dc=glauth,dc=com\u0026quot; bind_password: \u0026quot;mysecret\u0026quot; base_dn: \u0026quot;dc=glauth,dc=com\u0026quot; user_filter: \u0026quot;(cn=%s)\u0026quot; group_attribute: \u0026quot;ou\u0026quot; bypass_api_key: true cache_ttl: \u0026quot;10s\u0026quot; role_mapping: group: superheros: [ \u0026quot;Administrator\u0026quot; ] uid: hackers: [ \u0026quot;Administrator\u0026quot; ]  testing: enabled: true host: \u0026amp;quot;ldap.forumsys.com\u0026amp;quot; port: 389 bind_dn: \u0026amp;quot;cn=read-only-admin,dc=example,dc=com\u0026amp;quot; bind_password: \u0026amp;quot;password\u0026amp;quot; base_dn: \u0026amp;quot;dc=example,dc=com\u0026amp;quot; user_filter: \u0026amp;quot;(uid=%s)\u0026amp;quot; cache_ttl: \u0026amp;quot;10s\u0026amp;quot; role_mapping: uid: tesla: [ \u0026amp;quot;test-data\u0026amp;quot; ]  参数说明 #\n    名称 类型 说明     elasticsearch string Elasticsearch 集群实例名称     由于需要用到 Console 中配置的用户权限信息，elastic 模块下 elasticsearch 配置需要与 Console 配置的系统集群配置为同一个集群\n ","subcategory":null,"summary":"","tags":null,"title":"security","url":"/gateway/v1.29.7/zh/docs/references/filters/security/"},{"category":null,"content":"sample #  描述 #  sample 过滤器用来将正常的流量按照比例采样，对于海量查询的场景，全流量收集日志需要耗费大量的资源，可以考虑进行抽样统计，对查询日志进行采样分析。\n配置示例 #  一个简单的示例如下：\nflow: - name: sample filter: - sample: ratio: 0.2 参数说明 #     名称 类型 说明     ratio float 采样比例    ","subcategory":null,"summary":"","tags":null,"title":"sample","url":"/gateway/v1.29.7/zh/docs/references/filters/sample/"},{"category":null,"content":"rewrite_to_bulk #  描述 #  rewrite_to_bulk 可以分析 Elasticsearch 的普通文档创建和修改操作并改写为 Bulk 批次请求。\n配置示例 #  一个简单的示例如下：\nflow: - name: replicate-primary-writes-to-backup-queue filter: - flow: flows: - set-auth-for-backup-flow - rewrite_to_bulk: #rewrite docs create/update/delete operation to bulk request - bulk_reshuffle: #handle bulk requests when: contains: _ctx.request.path: /_bulk elasticsearch: \u0026quot;backup\u0026quot; queue_name_prefix: \u0026quot;async_bulk\u0026quot; level: cluster #cluster,node,index,shard partition_size: 10 fix_null_id: true - queue: #handle none-bulk requests\u0026lt;1. send to none-bulk queue\u0026gt; queue_name: \u0026quot;backup\u0026quot; 参数说明 #     名称 类型 说明     auto_generate_doc_id bool 如果是创建操作，并且没有指定文档 ID，是否自动生成文档 ID，默认 true   prefix string 给 UUID 增加一个固定前缀   type_removed bool 新版本 ES 移除了 _type 类型，这个参数用来避免在 Bulk 请求元数据添加类型参数    ","subcategory":null,"summary":"","tags":null,"title":"rewrite_to_bulk","url":"/gateway/v1.29.7/zh/docs/references/filters/rewrite_to_bulk/"},{"category":null,"content":"retry_limiter #  描述 #  retry_limiter 过滤器用来判断一个请求是否达到最大重试次数，避免一个请求的无限重试。\n配置示例 #  一个简单的示例如下：\nflow: - name: retry_limiter filter: - retry_limiter: queue_name: \u0026quot;deadlock_messages\u0026quot; max_retry_times: 3 参数说明 #     名称 类型 说明     max_retry_times int 最大重试次数，默认为 3   queue_name string 达到重试最大次数后，输出消息到指定消息队列的名称   tag_on_success array 触发重试条件之后，请求上下文打上指定标记    ","subcategory":null,"summary":"","tags":null,"title":"retry_limiter","url":"/gateway/v1.29.7/zh/docs/references/filters/retry_limiter/"},{"category":null,"content":"response_status_filter #  描述 #  response_status_filter 过滤器用来按后端服务响应的状态码来进行过滤。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - response_status_filter: message: \u0026quot;Request filtered!\u0026quot; exclude: - 404 include: - 200 - 201 - 500 参数说明 #     名称 类型 说明     exclude array 拒绝通过的响应码   include array 允许通过的响应码   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  ","subcategory":null,"summary":"","tags":null,"title":"response_status_filter","url":"/gateway/v1.29.7/zh/docs/references/filters/response_status_filter/"},{"category":null,"content":"response_header_format #  描述 #  response_header_format 过滤器用来将请求响应的 Header 信息里面的 Key 都转换成小写。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - response_header_format: ","subcategory":null,"summary":"","tags":null,"title":"response_header_format","url":"/gateway/v1.29.7/zh/docs/references/filters/response_header_format/"},{"category":null,"content":"response_header_filter #  描述 #  response_header_filter 过滤器用来按请求响应的 Header 信息来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: ... - response_header_filter: exclude: - INFINI-CACHE: CACHED 上面的例子表示，当 Header 信息里面出现 INFINI-CACHE: CACHED 的请求不允许通过。\n参数说明 #     名称 类型 说明     exclude array 拒绝通过的响应 Header 信息   include array 允许通过的响应 Header 信息   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  ","subcategory":null,"summary":"","tags":null,"title":"response_header_filter","url":"/gateway/v1.29.7/zh/docs/references/filters/response_header_filter/"},{"category":null,"content":"response_body_regex_replace #  描述 #  response_body_regex_replace 过滤器使用正则表达式来替换请求响应内容的字符串。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - echo: message: \u0026quot;hello infini\\n\u0026quot; - response_body_regex_replace: pattern: infini to: world 上面的结果输出为 hello world。\n参数说明 #     名称 类型 说明     pattern string 用于匹配替换的正则表达式   to string 替换为目标的字符串内容    ","subcategory":null,"summary":"","tags":null,"title":"response_body_regex_replace","url":"/gateway/v1.29.7/zh/docs/references/filters/response_body_regex_replace/"},{"category":null,"content":"request_user_limiter #  描述 #  request_user_limiter 过滤器用来按照用户名来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_user_limiter: user: - elastic - medcl max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: \u0026quot;you reached our limit\u0026quot; 上面的配置中，对 medcl 和 elastic 这两个用户进行限速，允许的最大 qps 为 256 每秒。\n参数说明 #     名称 类型 说明     user array 设置哪些用户会参与限速，不设置表示所有用户参与   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   burst_requests int 单位间隔内极限允许的请求次数   max_bytes int 单位间隔内最大的请求流量限额   burst_bytes int 单位间隔内极限允许的流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_delay_in_ms int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息   log_warn_message bool 是否输出警告消息到日志    ","subcategory":null,"summary":"","tags":null,"title":"request_user_limiter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_user_limiter/"},{"category":null,"content":"request_user_filter #  描述 #  当 Elasticsearch 是通过 Basic Auth 方式来进行身份认证的时候，request_user_filter 过滤器可用来按请求的用户名信息来进行过滤。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_user_filter: include: - \u0026quot;elastic\u0026quot; 上面的例子表示，只有来自 elastic 的请求才被允许通过。\n参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求的用户名列表   include array 允许通过的请求的用户名列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  ","subcategory":null,"summary":"","tags":null,"title":"request_user_filter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_user_filter/"},{"category":null,"content":"request_reshuffle #  描述 #  request_reshuffle 可以分析 Elasticsearch 的非批次请求，归档存储在队列中，通过先落地存储，业务端请求可以快速返回，从而解耦前端写入和后端 Elasticsearch 集群。request_reshuffle 需要离线管道消费任务来配合使用。\n配置示例 #  一个简单的示例如下：\nflow: - name: backup-flow-request-reshuffle filter: - flow: flows: - set-auth-for-backup-flow - request_reshuffle: #reshuffle none-bulk requests elasticsearch: \u0026quot;backup\u0026quot; queue_name_prefix: \u0026quot;request_reshuffle\u0026quot; partition_size: $[[env.REQUEST_RESHUFFLE_PARTITION_SIZE]] tag_on_success: [ \u0026quot;commit_message_allowed\u0026quot; ] 参数说明 #     名称 类型 说明     elasticsearch string Elasticsearch 集群实例名称   queue_name_prefix string 队列的名称前缀，默认为 async_bulk ，默认的 Label type:request_reshuffle   partition_size int 在 level 的基础上，会再次基于文档 _id 进行分区，通过此参数可以设置最大的分区大小   continue_after_reshuffle bool 执行完 Reshuffle 之后是否继续后续的流程，默认 false   tag_on_success array 将所有 bulk 请求处理完成之后，请求上下文打上指定标记    ","subcategory":null,"summary":"","tags":null,"title":"request_reshuffle","url":"/gateway/v1.29.7/zh/docs/references/filters/request_reshuffle/"},{"category":null,"content":"request_path_limiter #  描述 #  request_path_limiter 过滤器用来定义请求的限速规则，可以实现索引级别的限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_path_limiter: message: \u0026quot;Hey, You just reached our request limit!\u0026quot; rules: - pattern: \u0026quot;/(?P\u0026lt;index_name\u0026gt;medcl)/_search\u0026quot; max_qps: 3 group: index_name - pattern: \u0026quot;/(?P\u0026lt;index_name\u0026gt;.*?)/_search\u0026quot; max_qps: 100 group: index_name 上面的配置中，对 medcl 这个索引执行查询，允许的最大 qps 为 3，而对其它的索引执行查询的 qps 为 100。\n参数说明 #     名称 类型 说明     message string 设置达到限速条件的请求的返回消息   rules array 设置限速的策略，支持多种规则，按照配置的先后顺序处理，先匹配的先执行   rules.pattern string 使用正则表达式来对 URL 的 Path 进行规则匹配，必须提供一个 group 名称，用于作为限速的 bucket key   rules.group string 正则表达式里面定义的 group 名称，将用于请求次数的统计，相同的 group 值视为一类请求   rules.max_qps int 定义每组请求的最大的 qps 参数，超过该值将触发限速行为    ","subcategory":null,"summary":"","tags":null,"title":"request_path_limiter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_path_limiter/"},{"category":null,"content":"request_path_filter #  描述 #  request_path_filter 过滤器用来按请求的 Path 路径来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_path_filter: must: #must match all rules to continue prefix: - /medcl contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl must_not: # any match will be filtered prefix: - /.kibana - /_security - /_security - /gateway_requests* - /.reporting - /_monitoring/bulk contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl should: prefix: - /medcl contain: - _search - _async_search suffix: - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl 参数说明 #     名称 类型 说明     must.* object 必须都满足所设置条件的情况下才能允许通过   must_not.* object 必须都不满足所设置条件的情况下才能通过   should.* object 满足任意所设置条件的情况下即可通过   *.prefix array 判断是否由特定字符开头   *.suffix array 判断是否由特定字符结尾   *.contain array 判断是否包含特定字符   *.wildcard array 判断是否符合通配符匹配规则   *.regex array 判断是否符合正则表达式匹配规则   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    Note: 当仅设置了 should 条件的情况下，必须至少满足 should 设置的其中一种才能被允许通过。\n","subcategory":null,"summary":"","tags":null,"title":"request_path_filter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_path_filter/"},{"category":null,"content":"request_method_filter #  描述 #  request_method_filter 过滤器用来按请求 Method 来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_method_filter: exclude: - PUT - POST include: - GET - HEAD - DELETE 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求 Method   include array 允许通过的请求 Method   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  ","subcategory":null,"summary":"","tags":null,"title":"request_method_filter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_method_filter/"},{"category":null,"content":"request_host_limiter #  描述 #  request_host_limiter 过滤器用来按照请求主机（域名）来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_host_limiter: host: - api.elasticsearch.cn:8000 - logging.elasticsearch.cn:8000 max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: \u0026quot;you reached our limit\u0026quot; 上面的配置中，对 api.elasticsearch.cn 和 logging.elasticsearch.cn 这两个访问域名进行限速，允许的最大 qps 为 256 每秒。\n参数说明 #     名称 类型 说明     host array 设置哪些主机域名会参与限速，不设置表示都参与，注意，如果访问的域名带端口号，这里也需包含端口号，如 localhost:8080   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   burst_requests int 单位间隔内极限允许的请求次数   max_bytes int 单位间隔内最大的请求流量限额   burst_bytes int 单位间隔内极限允许的流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_delay_in_ms int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息   log_warn_message bool 是否输出警告消息到日志    ","subcategory":null,"summary":"","tags":null,"title":"request_host_limiter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_host_limiter/"},{"category":null,"content":"request_host_filter #  描述 #  request_host_filter 过滤器主要用来按照指定的域名或者主机名来进行请求过滤，适合只有一个 IP 多个域名需要进行域名访问控制的场景。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_host_filter: include: - domain-test2.com:8000 上面的例子表示，只有访问的是这个域名 domain-test2.com:8000 的请求才被允许通过。\n示例如下： #  ✗ curl -k -u user:passwd http://domain-test4.com:8000/ -v  Trying 192.168.3.67\u0026hellip; TCP_NODELAY set Connected to domain-test4.com (192.168.3.67) port 8000 (#0) Server auth using Basic with user \u0026lsquo;medcl\u0026rsquo; \u0026gt; GET / HTTP/1.1 \u0026gt; Host: domain-test4.com:8000 \u0026gt; Authorization: Basic 123= \u0026gt; User-Agent: curl/7.64.1 \u0026gt; Accept: / \u0026gt; \u0026lt; HTTP/1.1 403 Forbidden \u0026lt; Server: INFINI \u0026lt; Date: Fri, 15 Jan 2021 13:53:01 GMT \u0026lt; Content-Length: 0 \u0026lt; FILTERED: true \u0026lt; Connection #0 to host domain-test4.com left intact Closing connection 0  ✗ curl -k -u user:passwd http://domain-test2.com:8000/ -v\n Trying 192.168.3.67\u0026hellip; TCP_NODELAY set Connected to domain-test2.com (192.168.3.67) port 8000 (#0) Server auth using Basic with user \u0026lsquo;medcl\u0026rsquo; \u0026gt; GET / HTTP/1.1 \u0026gt; Host: domain-test2.com:8000 \u0026gt; Authorization: Basic 123= \u0026gt; User-Agent: curl/7.64.1 \u0026gt; Accept: / \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Fri, 15 Jan 2021 13:52:53 GMT \u0026lt; Content-Type: application/json; charset=UTF-8 \u0026lt; Content-Length: 480 \u0026lt; UPSTREAM: 192.168.3.203:9200 \u0026lt; CACHE-HASH: a2902f950b4ade804b21a062257387ef \u0026lt; { \u0026quot;name\u0026quot; : \u0026quot;node3\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;pi\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;Z_HcN_6ESKWicV-eLsyU4g\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;6.4.2\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;tar\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;04711c2\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2018-09-26T13:34:09.098244Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;7.4.0\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;5.6.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;5.0.0\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } Connection #0 to host domain-test2.com left intact Closing connection 0 参数说明 #      名称 类型 说明     exclude array 拒绝通过的请求的主机列表   include array 允许通过的请求的主机列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  ","subcategory":null,"summary":"","tags":null,"title":"request_host_filter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_host_filter/"},{"category":null,"content":"request_header_filter #  描述 #  request_header_filter 过滤器用来按请求的 Header 信息来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_header_filter: include: - TRACE: true 上面的例子表示，当 Header 里面包含 TRACE: true 的请求才被允许通过。\ncurl 192.168.3.4:8000 -v -H 'TRACE: true' 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求 Header 信息   include array 允许通过的请求 Header 信息   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  ","subcategory":null,"summary":"","tags":null,"title":"request_header_filter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_header_filter/"},{"category":null,"content":"request_client_ip_limiter #  描述 #  request_client_ip_limiter 过滤器用来按照请求客户端 IP 来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_client_ip_limiter: ip: #only limit for specify ips - 127.0.0.1 max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: \u0026quot;your ip reached our limit\u0026quot; 上面的配置中，对 127.0.0.1 这个 IP 进行限速，允许的最大 qps 为 256。\n参数说明 #     名称 类型 说明     ip array 设置哪些客户端 IP 会参与限速，不设置表示所有 IP 参与   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   burst_requests int 单位间隔内极限允许的请求次数   max_bytes int 单位间隔内最大的请求流量限额   burst_bytes int 单位间隔内极限允许的流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_delay_in_ms int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息   log_warn_message bool 是否输出警告消息到日志    ","subcategory":null,"summary":"","tags":null,"title":"request_client_ip_limiter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_client_ip_limiter/"},{"category":null,"content":"request_client_ip_filter #  描述 #  request_client_ip_filter 过滤器用来按请求的来源用户 IP 信息来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_client_ip_filter: exclude: - 192.168.3.67 上面的例子表示，来自 192.168.3.67 的请求不允许通过。\n路由跳转的例子:\nflow: - name: echo filter: - echo: message: hello stanger - name: default_flow filter: - request_client_ip_filter: action: redirect_flow flow: echo exclude: - 192.168.3.67 来自 192.168.3.67 会跳转到另外的 echo 流程。\n参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求 IP 数组列表   include array 允许通过的请求 IP 数组列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  ","subcategory":null,"summary":"","tags":null,"title":"request_client_ip_filter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_client_ip_filter/"},{"category":null,"content":"request_body_regex_replace #  描述 #  request_body_regex_replace 过滤器使用正则表达式来替换请求体正文的字符串内容。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_body_regex_replace: pattern: '\u0026quot;size\u0026quot;: 10000' to: '\u0026quot;size\u0026quot;: 100' - elasticsearch: elasticsearch: prod - dump: request: true 上面的示例将会替换发送给 Elasticsearch 请求体里面，size 设置为 10000 的部分修改为 100，可以用来动态修复错误或者不合理的查询。\n测试如下：\ncurl -XPOST \u0026quot;http://localhost:8000/myindex/_search\u0026quot; -H 'Content-Type: application/json' -d' { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\u0026quot;size\u0026quot;: 10000 }' 实际发生的查询：\n { \u0026quot;_index\u0026quot; : \u0026quot;gateway_requests\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;EH5bG3gBsbC2s3iWFzCF\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;tls\u0026quot; : false, \u0026quot;@timestamp\u0026quot; : \u0026quot;2021-03-10T08:57:30.645Z\u0026quot;, \u0026quot;conn_time\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;flow\u0026quot; : { \u0026quot;from\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;process\u0026quot; : [ \u0026quot;request_body_regex_replace\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;date_range_precision_tuning\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;elasticsearch\u0026quot;, \u0026quot;set_cache\u0026quot;, \u0026quot;||\u0026quot;, \u0026quot;request_logging\u0026quot; ], \u0026quot;relay\u0026quot; : \u0026quot;192.168.43.101-Quartz\u0026quot;, \u0026quot;to\u0026quot; : [ \u0026quot;localhost:9200\u0026quot; ] }, \u0026quot;id\u0026quot; : 3, \u0026quot;local_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;remote_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;request\u0026quot; : { \u0026quot;body_length\u0026quot; : 53, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot; { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\u0026quot;size\u0026quot;: 100 } \u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;content-type\u0026quot; : \u0026quot;application/json\u0026quot;, \u0026quot;User-Agent\u0026quot; : \u0026quot;curl/7.54.0\u0026quot;, \u0026quot;Accept\u0026quot; : \u0026quot;/\u0026quot;, \u0026quot;Host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;53\u0026quot; }, \u0026quot;host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:8000\u0026quot;, \u0026quot;method\u0026quot; : \u0026quot;POST\u0026quot;, \u0026quot;path\u0026quot; : \u0026quot;/myindex/_search\u0026quot;, \u0026quot;remote_addr\u0026quot; : \u0026quot;127.0.0.1:63309\u0026quot;, \u0026quot;started\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;uri\u0026quot; : \u0026quot;http://localhost:8000/myindex/_search\u0026quot; }, \u0026quot;response\u0026quot; : { \u0026quot;body_length\u0026quot; : 441, \u0026quot;cached\u0026quot; : false, \u0026quot;elapsed\u0026quot; : 9.878, \u0026quot;status_code\u0026quot; : 200, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot;{\u0026quot;took\u0026quot;:0,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;max_score\u0026quot;:1.0,\u0026quot;hits\u0026quot;:[{\u0026quot;_index\u0026quot;:\u0026quot;myindex\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;c132mhq3r0otidqkac1g\u0026quot;,\u0026quot;_score\u0026quot;:1.0,\u0026quot;_source\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;local\u0026quot;,\u0026quot;enabled\u0026quot;:true,\u0026quot;endpoint\u0026quot;:\u0026quot;http://localhost:9200\u0026quot;,\u0026quot;basic_auth\u0026quot;:{},\u0026quot;discovery\u0026quot;:{\u0026quot;refresh\u0026quot;:{}},\u0026quot;created\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;,\u0026quot;updated\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;}}]}}\u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;UPSTREAM\u0026quot; : \u0026quot;localhost:9200\u0026quot;, \u0026quot;process\u0026quot; : \u0026quot;request_body_regex_replace-\u0026gt;get_cache-\u0026gt;date_range_precision_tuning-\u0026gt;get_cache-\u0026gt;elasticsearch-\u0026gt;set_cache\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;441\u0026quot;, \u0026quot;content-type\u0026quot; : \u0026quot;application/json; charset=UTF-8\u0026quot;, \u0026quot;Server\u0026quot; : \u0026quot;INFINI\u0026quot;, \u0026quot;CLUSTER\u0026quot; : \u0026quot;dev\u0026quot; }, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:63310\u0026quot; } } } 参数说明 #\n    名称 类型 说明     pattern string 用于匹配替换的正则表达式   to string 替换为目标的字符串内容    ","subcategory":null,"summary":"","tags":null,"title":"request_body_regex_replace","url":"/gateway/v1.29.7/zh/docs/references/filters/request_body_regex_replace/"},{"category":null,"content":"request_body_json_set #  描述 #  request_body_json_set 过滤器用来修改 JSON 格式的请求体。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_body_json_set: path: - aggs.total_num.terms.field -\u0026gt; \u0026quot;name\u0026quot; - aggs.total_num.terms.size -\u0026gt; 3 - size -\u0026gt; 0 参数说明 #     名称 类型 说明     path map 使用 -\u0026gt; 作为标识符的键值对， JSON PATH 和需要替换的值   ignore_missing bool 如果这个 JSON Path 不存在，是否忽略处理，默认 false    ","subcategory":null,"summary":"","tags":null,"title":"request_body_json_set","url":"/gateway/v1.29.7/zh/docs/references/filters/request_body_json_set/"},{"category":null,"content":"request_body_json_del #  描述 #  request_body_json_del 过滤器用来删除 JSON 格式的请求体里面的部分字段。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_body_json_del: path: - query.bool.should.[0] - query.bool.must 参数说明 #     名称 类型 说明     path array 需要删除的 JSON PATH 键值   ignore_missing bool 如果这个 JSON Path 不存在，是否忽略处理，默认 false    ","subcategory":null,"summary":"","tags":null,"title":"request_body_json_del","url":"/gateway/v1.29.7/zh/docs/references/filters/request_body_json_del/"},{"category":null,"content":"request_api_key_limiter #  描述 #  request_api_key_limiter 过滤器用来按照 API Key 来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_api_key_limiter: id: - VuaCfGcBCdbkQm-e5aOx max_requests: 1 action: drop # retry or drop message: \u0026quot;your api_key reached our limit\u0026quot; 上面的配置中，对 VuaCfGcBCdbkQm-e5aOx 这个 API ID 进行限速，允许的最大 qps 为 1 每秒。\n➜ ~ curl localhost:8000 -H \u0026quot;Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw==\u0026quot; -v * Rebuilt URL to: localhost:8000/ * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET / HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw== \u0026gt; \u0026lt; HTTP/1.1 429 Too Many Requests \u0026lt; Server: INFINI \u0026lt; Date: Mon, 12 Apr 2021 15:14:52 GMT \u0026lt; content-type: text/plain; charset=utf-8 \u0026lt; content-length: 30 \u0026lt; process: request_api_key_limiter \u0026lt; * Connection #0 to host localhost left intact your api_key reached our limit% 参数说明 #     名称 类型 说明     id array 设置哪些 API ID 会参与限速，不设置表示所有 API Key 参与   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   burst_requests int 单位间隔内极限允许的请求次数   max_bytes int 单位间隔内最大的请求流量限额   burst_bytes int 单位间隔内极限允许的流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_delay_in_ms int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息   log_warn_message bool 是否输出警告消息到日志    ","subcategory":null,"summary":"","tags":null,"title":"request_api_key_limiter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_api_key_limiter/"},{"category":null,"content":"request_api_key_filter #  描述 #  当 Elasticsearch 是通过 API Key 方式来进行身份认证的时候，request_api_key_filter 过滤器可用来按请求的 API ID 来进行过滤。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_api_key_filter: message: \u0026quot;Request filtered!\u0026quot; exclude: - VuaCfGcBCdbkQm-e5aOx 上面的例子表示，来自 VuaCfGcBCdbkQm-e5aOx 的请求会被拒绝，如下。\n➜ ~ curl localhost:8000 -H \u0026quot;Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw==\u0026quot; -v * Rebuilt URL to: localhost:8000/ * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET / HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw== \u0026gt; \u0026lt; HTTP/1.1 403 Forbidden \u0026lt; Server: INFINI \u0026lt; Date: Mon, 12 Apr 2021 15:02:37 GMT \u0026lt; content-type: text/plain; charset=utf-8 \u0026lt; content-length: 17 \u0026lt; FILTERED: true \u0026lt; process: request_api_key_filter \u0026lt; * Connection #0 to host localhost left intact {\u0026quot;error\u0026quot;:true,\u0026quot;message\u0026quot;:\u0026quot;Request filtered!\u0026quot;}% ➜ ~ 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求的用户名列表   include array 允许通过的请求的用户名列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  ","subcategory":null,"summary":"","tags":null,"title":"request_api_key_filter","url":"/gateway/v1.29.7/zh/docs/references/filters/request_api_key_filter/"},{"category":null,"content":"replay #  描述 #  replay 处理器用来重放 record 过滤器记录的请求。\n配置示例 #  一个简单的示例如下：\npipeline: - name: play_requests auto_start: true keep_running: false processor: - replay: filename: requests.txt schema: \u0026quot;http\u0026quot; host: \u0026quot;localhost:8000\u0026quot; 参数说明 #     名称 类型 说明     filename string 包含重放消息的文件名称   schema string 请求协议类型，http 或 https   host string 接受请求的目标服务器，格式 host:port    ","subcategory":null,"summary":"","tags":null,"title":"replay","url":"/gateway/v1.29.7/zh/docs/references/processors/replay/"},{"category":null,"content":"redis_pubsub #  描述 #  reids 过滤器用来将收到的请求和响应结果保存到 Redis 消息队列中。\n配置示例 #  一个简单的示例如下：\nflow: - name: redis_pubsub filter: - redis_pubsub: host: 127.0.0.1 port: 6379 channel: gateway response: true 参数说明 #     名称 类型 说明     host string Reids 主机名，默认 localhost   port int Reids 端口号，默认为 6379   password string Redis 密码   db int Redis 默认选择的数据库，默认为 0   channel string Redis 消息队列名称，必填，没有默认值   response bool 是否包含响应结果，默认为 true    ","subcategory":null,"summary":"","tags":null,"title":"redis_pubsub","url":"/gateway/v1.29.7/zh/docs/references/filters/redis_pubsub/"},{"category":null,"content":"redirect #  描述 #  redirect 过滤器用来跳转到一个指定的 URL。\n配置示例 #  一个简单的示例如下：\nflow: - name: redirect filter: - redirect: uri: https://infinilabs.com 参数说明 #     名称 类型 说明     uri string 需要跳转的完整目标 URI 地址   code int 状态码设置，默认 302    ","subcategory":null,"summary":"","tags":null,"title":"redirect","url":"/gateway/v1.29.7/zh/docs/references/filters/redirect/"},{"category":null,"content":"record #  描述 #  record 过滤器是一个记录请求的过滤器，输出的请求可以直接复制到 Kibana 的 Console 中用于调试。\n配置示例 #  一个简单的示例如下：\nflow: - name: request_logging filter: - record: stdout: true filename: requests.txt record 过滤器输出的请求日志，格式示例如下：\nGET /_cluster/state/version,master_node,routing_table,metadata/* GET /_alias\nGET /_cluster/health\nGET /_cluster/stats\nGET /_nodes/0NSvaoOGRs2VIeLv3lLpmA/stats 参数说明 #\n    名称 类型 说明     filename string 录制请求日志在 data 目录下保存的文件名   stdout bool 是否在终端也打印输出，默认为 false    ","subcategory":null,"summary":"","tags":null,"title":"record","url":"/gateway/v1.29.7/zh/docs/references/filters/record/"},{"category":null,"content":"ratio #  描述 #  ratio 过滤器用来将正常的流量按照比例迁移转发到另外的一个处理流程，可以实现灰度发布、流量迁移导出，或者将部分流量切换到不同版本集群用于测试的能力。\n配置示例 #  一个简单的示例如下：\nflow: - name: ratio_traffic_forward filter: - ratio: ratio: 0.1 flow: hello_world continue: true 参数说明 #     名称 类型 说明     ratio float 需要迁移的流量比例   action string 当命中之后的行为，可以为 drop 或 redirect_flow，默认 redirect_flow   flow string 指定新的流量处理流程   continue bool 流量迁移出去之后，是否还继续执行之前的既定流程，设置成 false 则立即返回，默认 false。    ","subcategory":null,"summary":"","tags":null,"title":"ratio","url":"/gateway/v1.29.7/zh/docs/references/filters/ratio/"},{"category":null,"content":"queue_consumer #  描述 #  queue_consumer 处理器用来异步消费队列里面的请求到 Elasticsearch。\n配置示例 #  一个简单的示例如下：\npipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - queue_consumer: input_queue: \u0026quot;backup\u0026quot; elasticsearch: \u0026quot;backup\u0026quot; waiting_after: [ \u0026quot;backup_failure_requests\u0026quot;] worker_size: 20 when: cluster_available: [ \u0026quot;backup\u0026quot; ] 参数说明 #     名称 类型 说明     input_queue string 订阅的队列名称   worker_size int 并行执行消费任务的线程数，默认 1   idle_timeout_in_seconds int 消费队列的超时时间，默认 1   elasticsearch string 保存到目标集群的名称   waiting_after array 需要先等将这些指定队列消费完才能开始消费主队列里面的数据   failure_queue string 因为后端故障执行失败的请求，默认为 %input_queue%-failure   invalid_queue string 状态码返回为 4xx 的请求，默认为 %input_queue%-invalid   compress bool 是否压缩请求，默认 false   safety_parse bool 是否启用安全解析，即不采用 buffer 的方式，占用内存更高一点，默认为 true   doc_buffer_size bool 单次请求处理的最大文档 buff size，建议设置超过单个文档的最大大小，默认 256*1024    ","subcategory":null,"summary":"","tags":null,"title":"queue_consumer","url":"/gateway/v1.29.7/zh/docs/references/processors/queue_consumer/"},{"category":null,"content":"queue #  描述 #  queue 过滤器用来保存请求到消息队列。\n配置示例 #  一个简单的示例如下：\nflow: - name: queue filter: - queue: #handle dirty_writes, second-commit queue_name: \u0026quot;primary_final_commit_log##$[[partition_id]]\u0026quot; labels: type: \u0026quot;primary_final_commit_log\u0026quot; partition_id: \u0026quot;$[[partition_id]]\u0026quot; message: \u0026quot;$[[_ctx.request.header.X-Replicated-ID]]#$[[_ctx.request.header.LAST_PRODUCED_MESSAGE_OFFSET]]#$[[_sys.unix_timestamp_of_now]]\u0026quot; when: equals: _ctx.request.header.X-Replicated: \u0026quot;true\u0026quot; 参数说明 #     名称 类型 说明     depth_threshold int 大于队列指定深度才能存入队列，默认为 0   type string 指定消息队列的类型，支持 kafka 和 disk   queue_name string 消息队列名称   labels map 给新增的消息队列 Topic 添加自定义的标签   message string 自定义消息内容，支持变量   save_last_produced_message_offset bool 是否保留最后一次写入成功的消息的 Offset 到上下文中，可以作为变量随后使用   last_produced_message_offset_key string 自定义最后一次写入成功的消息的 Offset 保留到上下文中的变量名，默认 LAST_PRODUCED_MESSAGE_OFFSET    ","subcategory":null,"summary":"","tags":null,"title":"queue","url":"/gateway/v1.29.7/zh/docs/references/filters/queue/"},{"category":null,"content":"merge_to_bulk #  描述 #  merge_to_bulk 处理器用来消费队列里面的纯 JSON 文档，并合并成 Bulk 请求保存到指定的队列里面，需要配合 consumer 处理器进行消费，用批量写入代替单次请求来提高写入吞吐。\n配置示例 #  一个简单的示例如下：\npipeline: - name: messages_merge_async_bulk_results auto_start: true keep_running: true singleton: true processor: - consumer: queue_selector: keys: - bulk_result_messages consumer: group: merge_to_bulk processor: - merge_to_bulk: elasticsearch: \u0026quot;logging\u0026quot; index_name: \u0026quot;.infini_async_bulk_results\u0026quot; output_queue: name: \u0026quot;merged_async_bulk_results\u0026quot; label: tag: \u0026quot;bulk_logging\u0026quot; worker_size: 1 bulk_size_in_mb: 10 参数说明 #     名称 类型 说明     message_field string 从队列获取到的消息，存放到上下文的字段名称, 默认 messages   bulk_size_in_kb int 批次请求的单位大小，单位 KB   bulk_size_in_mb int 批次请求的单位大小，单位 MB，默认 10   elasticsearch string 保存到目标集群的名称   index_name string 保存到目标集群的索引名称   type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc   output_queue.name string 保存到目标队列的名称   output_queue.label map 保存到目标队列的标签，内置 type:merge_to_bulk    ","subcategory":null,"summary":"","tags":null,"title":"merge_to_bulk","url":"/gateway/v1.29.7/zh/docs/references/processors/merge_to_bulk/"},{"category":null,"content":"logging #  描述 #  logging 过滤器用来按请求记录下来，通过异步记录到本地磁盘的方式，尽可能降低对请求的延迟影响，对于流量很大的场景，建议配合其它请求过滤器来降低日志的总量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - logging: queue_name: request_logging 记录的请求日志样例如下：\n { \u0026quot;_index\u0026quot; : \u0026quot;gateway_requests\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;EH5bG3gBsbC2s3iWFzCF\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;tls\u0026quot; : false, \u0026quot;@timestamp\u0026quot; : \u0026quot;2021-03-10T08:57:30.645Z\u0026quot;, \u0026quot;conn_time\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;flow\u0026quot; : { \u0026quot;from\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;process\u0026quot; : [ \u0026quot;request_body_regex_replace\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;date_range_precision_tuning\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;elasticsearch\u0026quot;, \u0026quot;set_cache\u0026quot;, \u0026quot;||\u0026quot;, \u0026quot;request_logging\u0026quot; ], \u0026quot;relay\u0026quot; : \u0026quot;192.168.43.101-Quartz\u0026quot;, \u0026quot;to\u0026quot; : [ \u0026quot;localhost:9200\u0026quot; ] }, \u0026quot;id\u0026quot; : 3, \u0026quot;local_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;remote_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;request\u0026quot; : { \u0026quot;body_length\u0026quot; : 53, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot; { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\u0026quot;size\u0026quot;: 100 } \u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;content-type\u0026quot; : \u0026quot;application/json\u0026quot;, \u0026quot;User-Agent\u0026quot; : \u0026quot;curl/7.54.0\u0026quot;, \u0026quot;Accept\u0026quot; : \u0026quot;/\u0026quot;, \u0026quot;Host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;53\u0026quot; }, \u0026quot;host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:8000\u0026quot;, \u0026quot;method\u0026quot; : \u0026quot;POST\u0026quot;, \u0026quot;path\u0026quot; : \u0026quot;/myindex/_search\u0026quot;, \u0026quot;remote_addr\u0026quot; : \u0026quot;127.0.0.1:63309\u0026quot;, \u0026quot;started\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;uri\u0026quot; : \u0026quot;http://localhost:8000/myindex/_search\u0026quot; }, \u0026quot;response\u0026quot; : { \u0026quot;body_length\u0026quot; : 441, \u0026quot;cached\u0026quot; : false, \u0026quot;elapsed\u0026quot; : 9.878, \u0026quot;status_code\u0026quot; : 200, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot;{\u0026quot;took\u0026quot;:0,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;max_score\u0026quot;:1.0,\u0026quot;hits\u0026quot;:[{\u0026quot;_index\u0026quot;:\u0026quot;myindex\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;c132mhq3r0otidqkac1g\u0026quot;,\u0026quot;_score\u0026quot;:1.0,\u0026quot;_source\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;local\u0026quot;,\u0026quot;enabled\u0026quot;:true,\u0026quot;endpoint\u0026quot;:\u0026quot;http://localhost:9200\u0026quot;,\u0026quot;basic_auth\u0026quot;:{},\u0026quot;discovery\u0026quot;:{\u0026quot;refresh\u0026quot;:{}},\u0026quot;created\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;,\u0026quot;updated\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;}}]}}\u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;UPSTREAM\u0026quot; : \u0026quot;localhost:9200\u0026quot;, \u0026quot;process\u0026quot; : \u0026quot;request_body_regex_replace-\u0026gt;get_cache-\u0026gt;date_range_precision_tuning-\u0026gt;get_cache-\u0026gt;elasticsearch-\u0026gt;set_cache\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;441\u0026quot;, \u0026quot;content-type\u0026quot; : \u0026quot;application/json; charset=UTF-8\u0026quot;, \u0026quot;Server\u0026quot; : \u0026quot;INFINI\u0026quot;, \u0026quot;CLUSTER\u0026quot; : \u0026quot;dev\u0026quot; }, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:63310\u0026quot; } } } 参数说明 #\n    名称 类型 说明     queue_name string 将请求日志保存的本地磁盘的队列名称   format_header_keys bool 是否将 Header 标准化，都转成小写，默认 false   remove_authorization bool 是否将 Authorization 信息从 Header 里面移除，默认 true   max_request_body_size int 是否将过长的请求消息进行截断，默认 1024 ，即保留 1024 个字符   max_response_body_size int 是否将过长的返回消息进行截断，默认 1024 ，即保留 1024 个字符   min_elapsed_time_in_ms int 按照请求的响应时间进行过滤，最低超过多少 ms 的请求才会被记录下来   bulk_stats_details bool 是否记录 bulk 请求详细的按照索引的统计信息，默认 true    ","subcategory":null,"summary":"","tags":null,"title":"logging","url":"/gateway/v1.29.7/zh/docs/references/filters/logging/"},{"category":null,"content":"ldap_auth #  描述 #  ldap_auth 过滤器用来设置基于 LDAP 的身份认证。\n配置示例 #  一个简单的示例如下：\nflow: - name: ldap_auth filter: - ldap_auth: host: \u0026quot;ldap.forumsys.com\u0026quot; port: 389 bind_dn: \u0026quot;cn=read-only-admin,dc=example,dc=com\u0026quot; bind_password: \u0026quot;password\u0026quot; base_dn: \u0026quot;dc=example,dc=com\u0026quot; user_filter: \u0026quot;(uid=%s)\u0026quot; 上面的配置使用的是在线的免费 LDAP 测试服务器，测试用户 tesla，密码 password。\n➜ curl http://127.0.0.1:8000/ -u tesla:password { \u0026quot;name\u0026quot; : \u0026quot;192.168.3.7\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;ZGTwWtBfSLWRpsS1VKQDiQ\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;7.8.0\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;tar\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;757314695644ea9a1dc2fecd26d1a43856725e65\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2020-06-14T19:35:50.234439Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;8.5.1\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;6.8.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;6.0.0-beta1\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } ➜ curl http://127.0.0.1:8000/ -u tesla:password1 Unauthorized% 参数说明 #     名称 类型 说明     host string LDAP 服务器地址   port int LDAP 服务器端口，默认 389   tls bool LDAP 服务器是否为 TLS 安全传输协议，默认 false   bind_dn string 执行 LDAP 查询的用户信息   bind_password string 执行 LDAP 查询的密码信息   base_dn string 过滤 LDAP 用户的根域   user_filter string 过滤 LDAP 用户的查询条件，默认 (uid=%s)   uid_attribute string 用于用户 ID 的属性，默认 uid   group_attribute string 用于用户组的属性，默认 cn   attribute array 指定 LDAP 查询返回的属性列表   max_cache_items int 最大的缓存格式，默认不限制   cache_ttl duration 缓存过期时间格式，默认 300s    ","subcategory":null,"summary":"","tags":null,"title":"ldap_auth","url":"/gateway/v1.29.7/zh/docs/references/filters/ldap_auth/"},{"category":null,"content":"json_indexing #  描述 #  json_indexing 处理器用来消费队列里面的纯 JSON 文档，并保存到指定的 Elasticsearch 服务器里面。\n配置示例 #  一个简单的示例如下：\npipeline: - name: request_logging_index auto_start: true keep_running: true processor: - json_indexing: index_name: \u0026quot;gateway_requests\u0026quot; elasticsearch: \u0026quot;dev\u0026quot; input_queue: \u0026quot;request_logging\u0026quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 参数说明 #     名称 类型 说明     input_queue string 订阅的队列名称   worker_size int 并行执行消费任务的线程数，默认 1   idle_timeout_in_seconds int 消费队列的超时时间，默认 5，单位秒   bulk_size_in_kb int 批次请求的单位大小，单位 KB   bulk_size_in_mb int 批次请求的单位大小，单位 MB   elasticsearch string 保存到目标集群的名称   index_name string 保存到目标集群的索引名称   type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc    ","subcategory":null,"summary":"","tags":null,"title":"json_indexing","url":"/gateway/v1.29.7/zh/docs/references/processors/json_indexing/"},{"category":null,"content":"javascript #  描述 #  javascript 过滤器可用于通过用 javascript 编写脚本来执行您自己的处理逻辑，从而提供最大的灵活性。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - javascript: source: \u0026gt; function process(ctx) { var console = require('console'); console.log(\u0026quot;hello from javascript\u0026quot;); } 这个脚本里面的 process 是一个内置的函数，用来处理传进来的上下文信息，函数里面可以自定义业务逻辑。\n如果脚本比较复杂，也支持通过文件的方式从加载：\nflow: - name: test filter: - javascript: file: example.js 这里的 example.js 是文件的保存路径。\n参数说明 #     名称 类型 描述     source string 要执行的 Javascript 代码。   file string 要加载的脚本文件的路径。相对路径被解释为相对于网关实例数据目录的 scripts 子目录。   params map 一个参数字典，传递给脚本的 register 方法。    上下文 API #  传递给处理方法的上下文对象具有以下 API 可以被使用。有关上下文的更多信息，请查看 Request Context。\n   方法 描述     Get(string) 从上下文中获取一个值。如果字段不存在，则返回 null。 eg: var value = event.Get(key);   Put(string, value) 在上下文中输入一个值。如果字段已经设置，则返回以前的值。如果字段存在但不是对象无法设置，则会抛出异常。 eg: var old = event.Put(key, value);   Rename(string, string) 在上下文中重命名一个字段。目标键必须不存在。如果成功地将源键重命名为目标键，则返回 true。 eg: var success = event.Rename(\u0026quot;source\u0026quot;, \u0026quot;target\u0026quot;);   Delete(string) 从上下文中删除一个字段。成功时返回 true。 eg: var deleted = event.Delete(\u0026quot;user.email\u0026quot;);   Tag(string) 如果 Tag 不存在，则将 Tag 追加到 Tag 字段。如果 Tag 存在但不是字符串或字符串列表，则抛出异常。 eg: event.Tag(\u0026quot;user_event\u0026quot;);   AppendTo(string, string) 一个专门的追加字段值的方法，它将现有值转换为数组，并在值不存在时追加该值。如果现有值不是字符串或字符串数组，则抛出异常。 eg: event.AppendTo(\u0026quot;error.message\u0026quot;, \u0026quot;invalid file hash\u0026quot;);    外部参数的使用 #  下面的例子，介绍了如何使用 params 来传递变量，脚本可以加载来自文件，方便复用程序脚本。\nflow: - name: test filter: - javascript: params: keyword: [ \u0026quot;hello\u0026quot;, \u0026quot;world\u0026quot;, \u0026quot;scripts\u0026quot; ] source: \u0026gt; var console = require('console'); var params = {keyword: []}; function register(scriptParams) { params = scriptParams; } function process(ctx) { console.info(\u0026quot;keyword comes from params: [%s]\u0026quot;, params.keyword); } register 是一个内置的函数，用来初始化外部参数。\n","subcategory":null,"summary":"","tags":null,"title":"javascript","url":"/gateway/v1.29.7/zh/docs/references/filters/javascript/"},{"category":null,"content":"indexing_merge #  描述 #  indexing_merge 处理器用来消费队列里面的纯 JSON 文档，并合并成 Bulk 请求保存到指定的队列里面，需要配合 bulk_indexing 处理器进行消费，用批量写入代替单次请求来提高写入吞吐。\n配置示例 #  一个简单的示例如下：\npipeline: - name: indexing_merge auto_start: true keep_running: true processor: - indexing_merge: input_queue: \u0026quot;request_logging\u0026quot; elasticsearch: \u0026quot;logging-server\u0026quot; index_name: \u0026quot;infini_gateway_requests\u0026quot; output_queue: name: \u0026quot;gateway_requests\u0026quot; label: tag: \u0026quot;request_logging\u0026quot; worker_size: 1 bulk_size_in_mb: 10 - name: logging_requests auto_start: true keep_running: true processor: - bulk_indexing: bulk: compress: true batch_size_in_mb: 10 batch_size_in_docs: 5000 consumer: fetch_max_messages: 100 queues: type: indexing_merge when: cluster_available: [ \u0026quot;logging-server\u0026quot; ] 参数说明 #     名称 类型 说明     input_queue string 订阅的队列名称   worker_size int 并行执行消费任务的线程数，默认 1   idle_timeout_in_seconds int 消费队列的超时时间，默认 5，单位秒   bulk_size_in_kb int 批次请求的单位大小，单位 KB   bulk_size_in_mb int 批次请求的单位大小，单位 MB，默认 10   elasticsearch string 保存到目标集群的名称   index_name string 保存到目标集群的索引名称   type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc   output_queue.name string 保存到目标队列的名称   output_queue.label map 保存到目标队列的标签，内置 type:indexing_merge   failure_queue string 保存可重试的失败请求的队列名称   invalid_queue string 保存不合法的失败请求的队列名称    ","subcategory":null,"summary":"","tags":null,"title":"indexing_merge","url":"/gateway/v1.29.7/zh/docs/references/processors/indexing_merge/"},{"category":null,"content":"index_diff #  描述 #  index_diff 处理器用来对两个结果集进行差异对比。\n配置示例 #  一个简单的示例如下：\npipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - index_diff: diff_queue: \u0026quot;diff_result\u0026quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 参数说明 #     名称 类型 说明     source_queue string 来源数据的名称   target_queue string 目标数据的名称   diff_queue string 存放 diff 结果的队列   buffer_size int 内存 buffer 大小   keep_source bool diff 结果里面是否包含文档 source 信息   text_report bool 是否输出文本格式的结果    ","subcategory":null,"summary":"","tags":null,"title":"index_diff","url":"/gateway/v1.29.7/zh/docs/references/processors/index_diff/"},{"category":null,"content":"http #  描述 #  http 过滤器用来将请求代理转发到指定的 http 服务器。\n配置示例 #  一个简单的示例如下：\nflow: - name: default_flow filter: - basic_auth: valid_users: medcl: passwd - http: schema: \u0026quot;http\u0026quot; #https or http #host: \u0026quot;192.168.3.98:5601\u0026quot; hosts: - \u0026quot;192.168.3.98:5601\u0026quot; - \u0026quot;192.168.3.98:5602\u0026quot; 参数说明 #     名称 类型 说明     schema string http 或是 https   host string 目标主机地址，带端口，如 localhost:9200   hosts array 主机地址列表，遇到故障，依次尝试   skip_failure_host bool 是否跳过不可以的主机，默认 true   max_connection_per_node int 主机的最大连接数，默认 5000   max_response_size int 支持的最大响应体大小   max_retry_times int 出错的最大重试次数，默认 0   retry_delay_in_ms int 重试的延迟，默认 1000   skip_cleanup_hop_headers bool 是否移除不兼容的 Hop-by-hop 头信息   max_conn_wait_timeout duration 建立连接的超时时间，默认 30s   max_idle_conn_duration duration 空闲连接的超时时间，默认 30s   max_conn_duration duration 长连接的超时时间，默认 0s   timeout duration 请求的超时时间，默认 30s   read_timeout duration 读请求的超时时间，默认 0s   write_timeout duration 写请求的超时时间，默认 0s   read_buffer_size int 读请求的缓冲区大小，默认 16384   write_buffer_size int 写请求的缓冲区大小，默认 16384   tls_insecure_skip_verify bool 是否忽略 TLS 的校验，默认 true    ","subcategory":null,"summary":"","tags":null,"title":"http","url":"/gateway/v1.29.7/zh/docs/references/filters/http/"},{"category":null,"content":"hash_mod #  描述 #  hash_mod 过滤器用来使用请求的上下文通过哈希取模得到一个唯一的分区编号，一般用于后续的请求转发。\n配置示例 #  一个简单的示例如下：\nflow: - name: default_flow filter: - hash_mod: #hash requests to different queues source: \u0026quot;$[[_ctx.remote_ip]]_$[[_ctx.request.username]]_$[[_ctx.request.path]]\u0026quot; target_context_name: \u0026quot;partition_id\u0026quot; mod: 10 #hash to 10 partitions add_to_header: true - set_context: context: _ctx.request.header.X-Replicated-ID: $[[_util.increment_id.request_number_id]]_$[[_util.generate_uuid]] _ctx.request.header.X-Replicated-Timestamp: $[[_sys.unix_timestamp_of_now]] _ctx.request.header.X-Replicated: \u0026quot;true\u0026quot; 参数说明 #     名称 类型 说明     source string 哈希的输入输入，支持变量参数   target_context_name string 将分区编号保持到上下文的主键名称   mod int 最大分区数   add_to_request_header bool 是否添加到请求头，默认 true，分别为：X-Partition-ID 和 X-Partition-Size   add_to_response_header bool 是否添加到响应头，默认 false    ","subcategory":null,"summary":"","tags":null,"title":"hash_mod","url":"/gateway/v1.29.7/zh/docs/references/filters/hash_mod/"},{"category":null,"content":"flow_runner #  描述 #  flow_runner 处理器用来异步消费队列里面的请求并使用异步用于在线请求的处理流程来进行消费处理。\n配置示例 #  一个简单的示例如下：\npipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - flow_runner: input_queue: \u0026quot;primary_deadletter_requests\u0026quot; flow: primary-flow-post-processing when: cluster_available: [ \u0026quot;primary\u0026quot; ] 参数说明 #     名称 类型 说明     input_queue string 订阅的队列名称   flow string 以什么样的流程来消费队列里面的请求消息   commit_on_tag string 只有当前请求的上下文里面出现指定 tag 才会 commit 消息，默认为空表示执行完就 commit    ","subcategory":null,"summary":"","tags":null,"title":"flow_runner","url":"/gateway/v1.29.7/zh/docs/references/processors/flow_runner/"},{"category":null,"content":"flow_replay #  描述 #  flow_replay 处理器用来异步消费队列里面的请求并使用异步用于在线请求的处理流程来进行消费处理。\n配置示例 #  一个简单的示例如下：\npipeline: - name: backup-flow-request-reshuffle auto_start: true keep_running: true singleton: true retry_delay_in_ms: 10 processor: - consumer: max_worker_size: 100 queue_selector: labels: type: \u0026quot;primary_write_ahead_log\u0026quot; consumer: group: request-reshuffle fetch_max_messages: 10000 fetch_max_bytes: 20485760 fetch_max_wait_ms: 10000 processor: - flow_replay: flow: backup-flow-request-reshuffle commit_on_tag: \u0026quot;commit_message_allowed\u0026quot; 参数说明 #     名称 类型 说明     message_field string 从队列获取到的消息，存放到上下文的字段名称, 默认 messages   flow string 以什么样的流程来消费队列里面的请求消息   commit_on_tag string 只有当前请求的上下文里面出现指定 tag 才会 commit 消息，默认为空表示执行完就 commit    ","subcategory":null,"summary":"","tags":null,"title":"flow_replay","url":"/gateway/v1.29.7/zh/docs/references/processors/flow_replay/"},{"category":null,"content":"flow #  描述 #  flow 过滤器用来跳转或执行某个或一系列其他流程。\n配置示例 #  一个简单的示例如下：\nflow: - name: flow filter: - flow: flows: - request_logging 使用上下文的动态 Flow:\nflow: - name: dns-flow filter: - flow: ignore_undefined_flow: true context_flow: context: _ctx.request.host context_parse_pattern: (?P\u0026lt;uuid\u0026gt;^[0-9a-z_\\-]+)\\. flow_id_template: flow_$[[uuid]] - set_response: status: 503 content_type: application/json body: '{\u0026quot;message\u0026quot;:\u0026quot;invalid HOST\u0026quot;}' 支持的上下文变量，请访问 上下文 .\n参数说明 #     名称 类型 说明     flow string 流程 ID，支持指定单个 flow 执行   flows array 流程 ID，数组格式，可以指定多个，依次执行   ignore_undefined_flow bool 是否忽略未知的 flow，继续执行   context_flow.context string 用来查找 flow_id 的上下文变量   context_flow.context_parse_pattern string 用来抽取变量的正则表达式   context_flow.flow_id_template string 用来生成 flow_id 的模版   context_flow.continue string 上下文映射的 Flow 执行完毕之后是否继续下一个过滤器，默认 false    ","subcategory":null,"summary":"","tags":null,"title":"flow","url":"/gateway/v1.29.7/zh/docs/references/filters/flow/"},{"category":null,"content":"elasticsearch_health_check #  描述 #  elasticsearch_health_check 过滤器用来以限速模式下主动探测 Elasticsearch 的健康情况， 当出现后端故障的情况下，可以触发一次主动的集群健康检查，而不用等待 Elasticsearch 默认的轮询检查结果，限速设置为最多每秒发送一次检查请求给后端 Elasticsearch。\n配置示例 #  一个简单的示例如下：\nflow: - name: elasticsearch_health_check filter: - elasticsearch_health_check: elasticsearch: dev 参数说明 #     名称 类型 说明     elasticsearch string 集群 ID   interval int 设置最少执行请求的时间间隔，单位秒，默认 1    ","subcategory":null,"summary":"","tags":null,"title":"elasticsearch_health_check","url":"/gateway/v1.29.7/zh/docs/references/filters/elasticsearch_health_check/"},{"category":null,"content":"elasticsearch #  描述 #  elasticsearch 过滤器是一个用于请求转发给后端 Elasticsearch 集群的过滤器。\n配置示例 #  使用 elasticsearch 过滤器之前，需要提前定义一个 Elasticsearch 的集群配置节点，如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 流程的配置示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod 上面的例子即将请求转发给 prod 集群。\n自动更新 #  对于一个大规模的集群，可能存在很多的节点，不可能一一配置后端的所有节点，只需要先指定 Elasticsearch 模块允许自动发现后端节点，如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true basic_auth: username: elastic password: pass 然后过滤器这边的配置也开启刷新，即可访问后端所有节点，且节点上下线也会自动更新，示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 设置权重 #  如果后端集群很多，极限网关支持对不同的节点设置不同的访问权重，配置示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod balancer: weight refresh: enabled: true interval: 30s weights: - host: 192.168.3.201:9200 weight: 10 - host: 192.168.3.202:9200 weight: 20 - host: 192.168.3.203:9200 weight: 30 上面的例子中，发往 Elasticsearch 集群的流量，将以 3：2：1 的比例分别发给 203、202 和 201 这三个节点。\n过滤节点 #  极限网关还支持按照节点的 IP、标签、角色来进行过滤，可以用来将请求避免发送给特定的节点，如 Master、冷节点等，配置示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod balancer: weight refresh: enabled: true interval: 30s filter: hosts: exclude: - 192.168.3.201:9200 include: - 192.168.3.202:9200 - 192.168.3.203:9200 tags: exclude: - temp: cold include: - disk: ssd roles: exclude: - master include: - data - ingest 参数说明 #     名称 类型 说明     elasticsearch string Elasticsearch 集群的名称   max_connection_per_node int 限制访问 Elasticsearch 集群每个节点的最大 TCP 连接数，默认 5000   max_response_size int 限制 Elasticsearch 请求返回的最大消息体大小，默认 100*1024*1024   max_retry_times int 限制 Elasticsearch 出错的重试次数，默认 0   max_conn_wait_timeout duration 限制 Elasticsearch 等待空闲链接的超时时间，默认 30s   max_idle_conn_duration duration 限制 Elasticsearch 连接的空闲时间，默认 30s   max_conn_duration duration 限制 Elasticsearch 连接的持续时间，默认 0s   timeout duration 等待 Elasticsearch 请求返回超时时间，默认 30s。警告：timeout 不会终止请求本身。请求将在后台继续，响应将被丢弃。如果请求时间过长并且连接池已满，请尝试设置读取超时。   dial_timeout duration 限制 Elasticsearch 请求的 dial 超时时间，默认3s   read_timeout duration 限制 Elasticsearch 请求的读取超时时间，默认 0s   write_timeout duration 限制 Elasticsearch 请求的写入超时时间，默认 0s   read_buffer_size int 设置 Elasticsearch 请求的读缓存大小，默认 4096*4   write_buffer_size int 设置 Elasticsearch 请求的写缓存大小，默认 4096*4   tls_insecure_skip_verify bool 是否忽略 Elasticsearch 集群的 TLS 证书校验，默认 true   balancer string 后端 Elasticsearch 节点的负载均衡算法，目前只有 weight 基于权重的算法   skip_metadata_enrich bool 是否跳过 Elasticsearch 元数据的处理，不添加 X-* 元数据到请求和响应的头信息   refresh.enable bool 是否开启节点状态变化的自动刷新，可感知后端 Elasticsearch 拓扑的变化   refresh.interval int 节点状态刷新的间隔时间   weights array 可以设置后端节点的优先级，权重高的转发请求的比例相应提高   filter object 后端 Elasticsearch 节点的过滤规则，可以将请求转发给特定的节点   filter.hosts object 按照 Elasticsearch 的访问地址来进行过滤   filter.tags object 按照 Elasticsearch 的标签来进行过滤   filter.roles object 按照 Elasticsearch 的角色来进行过滤   filter.*.exclude array 排除特定的条件，任何匹配的节点会被拒绝执行请求的代理   filter.*.include array 允许符合条件的 Elasticsearch 节点来代理请求，在 exclude 参数没有配置的情况下，如果配置了 include 条件，则必须要满足任意一个 include 条件，否则不允许进行请求的代理    ","subcategory":null,"summary":"","tags":null,"title":"elasticsearch","url":"/gateway/v1.29.7/zh/docs/references/filters/elasticsearch/"},{"category":null,"content":"dump_hash #  描述 #  dump_hash 处理器用来导出集群的索引文档并计算 Hash。\n配置示例 #  一个简单的示例如下：\npipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - dump_hash: #dump es1's doc indices: \u0026quot;medcl-dr3\u0026quot; scroll_time: \u0026quot;10m\u0026quot; elasticsearch: \u0026quot;source\u0026quot; query: \u0026quot;field1:elastic\u0026quot; fields: \u0026quot;doc_hash\u0026quot; output_queue: \u0026quot;source_docs\u0026quot; batch_size: 10000 slice_size: 5 参数说明 #     名称 类型 说明     elasticsearch string 目标集群的名称   scroll_time string Scroll 回话超时时间   batch_size int Scroll 批次大小，默认 5000   slice_size int Slice 大小，默认 1   sort_type string 文档排序类型，默认 asc   sort_field string 文档排序字段   indices string 索引   level string 请求处理级别，可以设置为 cluster 则表示请求不进行节点和分片级别的拆分，适用于 Elasticsearch 前有代理的情况   query string 查询过滤条件   fields string 要返回的字段列表   sort_document_fields bool hash 计算之前是否对 _source 里面的字段进行排序，默认 false   hash_func string hash 函数，可选 xxhash32、xxhash64、fnv1a，默认 xxhash32   output_queue string 输出结果的队列名称    ","subcategory":null,"summary":"","tags":null,"title":"dump_hash","url":"/gateway/v1.29.7/zh/docs/references/processors/dump_hash/"},{"category":null,"content":"dump #  描述 #  dump 过滤器是一个用于在终端打印 Dump 输出相关请求信息的过滤器，主要用于调试。\n配置示例 #  一个简单的示例如下：\nflow: - name: hello_world filter: - dump: request: true response: true 参数说明 #  dump 过滤器比较简单，在需要的流程处理阶段插入 dump 过滤器，即可在终端输出相应阶段的请求信息，方便调试。\n   名称 类型 说明     request bool 是否输出全部完整的请求信息   response bool 是否输出全部完整的返回信息   uri bool 是否输出请求的 URI 信息   query_args bool 是否输出请求的参数信息   user bool 是否输出请求的用户信息   api_key bool 是否输出请求的 APIKey 信息   request_header bool 是否输出请求的头信息   response_header bool 是否输出响应的头信息   status_code bool 是否输出响应的状态码   context array 输出自定义的上下文信息    输出上下文 #  可以使用 context 参数来调试请求上下文信息，示例配置文件：\nflow: - name: echo filter: - set_response: status: 201 content_type: \u0026quot;text/plain; charset=utf-8\u0026quot; body: \u0026quot;hello world\u0026quot; - set_response_header: headers: - Env -\u0026gt; Dev - dump: context: - _ctx.id - _ctx.tls - _ctx.remote_addr - _ctx.local_addr - _ctx.request.host - _ctx.request.method - _ctx.request.uri - _ctx.request.path - _ctx.request.body - _ctx.request.body_length - _ctx.request.query_args.from - _ctx.request.query_args.size - _ctx.request.header.Accept - _ctx.request.user - _ctx.response.status - _ctx.response.body - _ctx.response.content_type - _ctx.response.body_length - _ctx.response.header.Env 启动网关，执行如下命令：\ncurl http://localhost:8000/medcl/_search\\?from\\=1\\\u0026amp;size\\=100 -d'{search:query123}' -v -u 'medcl:123' 网关终端输出如下信息：\n---- dumping context ---- _ctx.id : 21474836481 _ctx.tls : false _ctx.remote_addr : 127.0.0.1:50925 _ctx.local_addr : 127.0.0.1:8000 _ctx.request.host : localhost:8000 _ctx.request.method : POST _ctx.request.uri : http://localhost:8000/medcl/_search?from=1\u0026amp;size=100 _ctx.request.path : /medcl/_search _ctx.request.body : {search:query123} _ctx.request.body_length : 17 _ctx.request.query_args.from : 1 _ctx.request.query_args.size : 100 _ctx.request.header.Accept : */* _ctx.request.user : medcl _ctx.response.status : 201 _ctx.response.body : hello world _ctx.response.content_type : text/plain; charset=utf-8 _ctx.response.body_length : 11 _ctx.response.header.Env : Dev ","subcategory":null,"summary":"","tags":null,"title":"dump","url":"/gateway/v1.29.7/zh/docs/references/filters/dump/"},{"category":null,"content":"drop #  描述 #  drop 过滤器用来丢弃某个消息，提前结束请求的处理。\n配置示例 #  一个简单的示例如下：\nflow: - name: drop filter: - drop: ","subcategory":null,"summary":"","tags":null,"title":"drop","url":"/gateway/v1.29.7/zh/docs/references/filters/drop/"},{"category":null,"content":"date_range_precision_tuning #  描述 #  date_range_precision_tuning 过滤器用来重设时间范围查询的时间精度，通过调整精度，可以让短时间内邻近的重复请求更容易被缓存，对于有一些对于时间精度不那么高但是数据量非常大的场景，比如使用 Kibana 来做报表分析，通过缩减精度来缓存重复的查询请求，从而降低后端服务器压力，前端报表展现的提速非常明显。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - date_range_precision_tuning: time_precision: 4 - get_cache: - elasticsearch: elasticsearch: dev - set_cache: 精度说明 #  Kibana 默认发往 Elasticsearch 的查询，使用的是当前时间 Now，精度到毫秒，通过设置不同的精度来改写查询，以下面的查询为例：\n{\u0026quot;range\u0026quot;:{\u0026quot;@timestamp\u0026quot;:{\u0026quot;gte\u0026quot;:\u0026quot;2019-09-26T08:21:12.152Z\u0026quot;,\u0026quot;lte\u0026quot;:\u0026quot;2020-09-26T08:21:12.152Z\u0026quot;,\u0026quot;format\u0026quot;:\u0026quot;strict_date_optional_time\u0026quot;} 分别设置不同的精度，改写之后的查询结果如下：\n   精度 新的查询     0 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T00:00:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T23:59:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   1 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T00:00:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T09:59:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   2 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:00:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:59:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   3 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:20:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:29:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   4 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   5 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:10.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:19.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   6 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   7 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.100Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.199Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   8 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.150Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.159Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   9 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.152Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.152Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}    参数说明 #     名称 类型 说明     time_precision int 时间的精度长度，对于时间呈现长度位数，默认为 4，有效范围 0 到 9   path_keywords array 只对包含所设置关键字的请求进行时间精度重置，避免对不必要的请求进行解析，默认 _search 和 _async_search    ","subcategory":null,"summary":"","tags":null,"title":"date_range_precision_tuning","url":"/gateway/v1.29.7/zh/docs/references/filters/date_range_precision_tuning/"},{"category":null,"content":"dag #  描述 #  dag 处理器用来管理任务的并行调度。\n配置示例 #  下面的这个例子，定义了一个名为 racing_example 的服务，auto_start 设置为自动启动，processor 设置依次执行的每个处理单元，其中 dag 处理器支持多个任务并行执行，支持 wait_all 和 first_win 两种聚合模式，如下：\npipeline: - name: racing_example auto_start: true processor: - echo: #ready, set, go message: read,set,go - dag: mode: wait_all #first_win, wait_all parallel: - echo: #player1 message: player1 - echo: #player2 message: player2 - echo: #player3 message: player3 end: - echo: #checking score message: checking score - echo: #announce champion message: 'announce champion' - echo: #done message: racing finished 上面的 echo 处理器非常简单，用来输出一个指定的消息，这个管道模拟的是一个赛跑的场景，palyer1、2、3 并行赛跑，全部跑完之后再进行算分和宣布比赛冠军，最后输出结束信息，程序运行输出如下：\n[10-12 14:59:22] [INF] [echo.go:36] message:read,set,go [10-12 14:59:22] [INF] [echo.go:36] message:player1 [10-12 14:59:22] [INF] [echo.go:36] message:player2 [10-12 14:59:22] [INF] [echo.go:36] message:player3 [10-12 14:59:22] [INF] [echo.go:36] message:checking score [10-12 14:59:22] [INF] [echo.go:36] message:announce champion [10-12 14:59:22] [INF] [echo.go:36] message:racing finished 参数说明 #     名称 类型 说明     mode string 任务结果的聚合模式，设置 first_win 表示并行里面的任意任务执行完就继续往下执行，而设置 wait_all 表示需要等待所有任务执行完毕才继续往后执行。   parallel array 任务数组列表，依次定义多个子任务   end array 任务数组列表，并行任务之后再执行的任务    ","subcategory":null,"summary":"","tags":null,"title":"dag","url":"/gateway/v1.29.7/zh/docs/references/processors/dag/"},{"category":null,"content":"context_switch #  描述 #  context_switch 过滤器用来使用上下文变量来进行条件判断实现灵活跳转。\n配置示例 #  一个简单的示例如下：\nflow: - name: context_switch filter: - context_switch: context: logging.month default_flow: echo_message_not_found switch: - case: [\u0026quot;02\u0026quot;,\u0026quot;01\u0026quot;] action: redirect_flow flow: echo_message_01_02 - case: [\u0026quot;03\u0026quot;] action: redirect_flow flow: echo_message_03 参数说明 #     名称 类型 说明     context string 上下文变量名称   skip_error bool 是否忽略错误直接返回，如上下文变量不存在   default_action string 默认的执行动作，支持 redirect_flow 和 drop，默认 redirect_flow   default_flow string 默认的 flow 名称   stringify_value bool 是否将参数都统一成字符来进行处理，默认 true。   continue bool 匹配跳转之后，是否还继续执行后面的流程，设置成 false 则立即返回，默认 false。   switch array 条件判断枚举数组   switch[i].case []string 符合匹配条件的字符枚举   switch[i].action string 匹配之后的执行动作，支持 redirect_flow 和 drop，默认 redirect_flow   switch[i].flow string 如果动作是 redirect_flow，则跳转到该 flow，否则执行默认的 flow    ","subcategory":null,"summary":"","tags":null,"title":"context_switch","url":"/gateway/v1.29.7/zh/docs/references/filters/context_switch/"},{"category":null,"content":"context_regex_replace #  描述 #  context_regex_replace 过滤器用来通过正则表达式来替换修改请求上下文的相关信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - context_regex_replace: context: \u0026quot;_ctx.request.path\u0026quot; pattern: \u0026quot;^/\u0026quot; to: \u0026quot;/cluster:\u0026quot; when: contains: _ctx.request.path: /_search - dump: request: true 这个例子可以将请求 curl localhost:8000/abc/_search 替换为 curl localhost:8000/cluster:abc/_search\n参数说明 #     名称 类型 说明     context string 请求的上下文及对应的 Key   pattern string 用于匹配替换的正则表达式   to string 替换为目标的字符串内容    支持修改的上下文变量列表如下：\n   名称 类型 说明     _ctx.request.uri string 完整请求的 URL 地址   _ctx.request.path string 请求的路径   _ctx.request.host string 请求的主机   _ctx.request.body string 请求体   _ctx.request.body_json.[JSON_PATH] string JSON 请求对象的 Path   _ctx.request.query_args.[KEY] string URL 查询请求参数   _ctx.request.header.[KEY] string 请求头信息   _ctx.response.header.[KEY] string 返回头信息   _ctx.response.body string 返回响应体   _ctx.response.body_json.[JSON_PATH] string JSON 返回对象的 Path    ","subcategory":null,"summary":"","tags":null,"title":"context_regex_replace","url":"/gateway/v1.29.7/zh/docs/references/filters/context_regex_replace/"},{"category":null,"content":"context_parse #  描述 #  context_parse 过滤器用来对上下文变量进行字段的提取，并存放到上下文中。\n配置示例 #  一个简单的示例如下：\nflow: - name: context_parse filter: - context_parse: context: _ctx.request.path pattern: ^\\/.*?\\d{4}\\.(?P\u0026lt;month\u0026gt;\\d{2})\\.(?P\u0026lt;day\u0026gt;\\d{2}).*? group: \u0026quot;parsed_index\u0026quot; 通过 context_parse 可以提取请求如：/abd-2023.02.06-abc/_search，得到新的上下文变量 parsed_index.month 和 parsed_index.day。\n参数说明 #     名称 类型 说明     context string 上下文变量名称   pattern string 用来提取字段的正则表达式   skip_error bool 是否忽略错误直接返回，如上下文变量不存在   group string 提取的字段是否存放到一个单独的分组下面    ","subcategory":null,"summary":"","tags":null,"title":"context_parse","url":"/gateway/v1.29.7/zh/docs/references/filters/context_parse/"},{"category":null,"content":"context_limiter #  描述 #  context_limiter 过滤器用来按照请求上下文来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: default_flow filter: - context_limiter: max_requests: 1 action: drop context: - _ctx.request.path - _ctx.request.header.Host - _ctx.request.header.Env 上面的配置中，对 _ctx.request.path 、 _ctx.request.header.Host 和 _ctx.request.header.Env 这三个上下文变量来组成一个 bucket 进行限速。 允许的最大 qps 为 1每秒，达到限速直接拒绝范围外的后续请求。\n参数说明 #     名称 类型 说明     context array 设置上下文变量，依次组合成一个 bucket key   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   burst_requests int 单位间隔内极限允许的请求次数   max_bytes int 单位间隔内最大的请求流量限额   burst_bytes int 单位间隔内极限允许的流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_delay_in_ms int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息   log_warn_message bool 是否输出警告消息到日志    ","subcategory":null,"summary":"","tags":null,"title":"context_limiter","url":"/gateway/v1.29.7/zh/docs/references/filters/context_limiter/"},{"category":null,"content":"context_filter #  描述 #  context_filter 过滤器用来按请求上下文来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - context_filter: context: _ctx.request.path message: \u0026quot;request not allowed.\u0026quot; status: 403 must: #must match all rules to continue prefix: - /medcl contain: - _search suffix: - _search wildcard: - /*/_search regex: - ^/m[\\w]+dcl must_not: # any match will be filtered prefix: - /.kibana - /_security - /_security - /gateway_requests* - /.reporting - /_monitoring/bulk contain: - _refresh suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/\\.m[\\w]+dcl should: prefix: - /medcl contain: - _search - _async_search suffix: - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl 参数说明 #     名称 类型 说明     context string 上下文变量   exclude array 拒绝通过的请求的变量列表   include array 允许通过的请求的变量列表   must.* object 必须都满足所设置条件的情况下才能允许通过   must_not.* object 必须都不满足所设置条件的情况下才能通过   should.* object 满足任意所设置条件的情况下即可通过   *.prefix array 判断是否由特定字符开头   *.suffix array 判断是否由特定字符结尾   *.contain array 判断是否包含特定字符   *.wildcard array 判断是否符合通配符匹配规则   *.regex array 判断是否符合正则表达式匹配规则   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    Note: 当仅设置了 should 条件的情况下，必须至少满足 should 设置的其中一种才能被允许通过。\n","subcategory":null,"summary":"","tags":null,"title":"context_filter","url":"/gateway/v1.29.7/zh/docs/references/filters/context_filter/"},{"category":null,"content":"consumer #  描述 #  consumer 处理器用来消费 queue 记录的消息请求，但是不处理，目标是提供数据消费管道的入口，由后续的 processor 进行数据加工。\n配置示例 #  一个简单的示例如下：\npipeline: - name: consume_queue_messages auto_start: true keep_running: true retry_delay_in_ms: 5000 processor: - consumer: consumer: fetch_max_messages: 1 max_worker_size: 200 num_of_slices: 1 idle_timeout_in_seconds: 30 queue_selector: keys: - email_messages processor: - xxx1: - xxx2: 上面的例子，订阅并消费队列 email_messages，队列消息保存在当前 Pipeline 管道的上下文里面，Consumer 提供了一个 processor 参数，这个参数里面是一系列 Processor，依次执行，任何一个 Processor 如果执行返回出错，consumer 则退出切不会 commit 这批数据。\n参数说明 #     名称 类型 说明     message_field string 从队列获取到的消息，存放到上下文的字段名称, 默认 messages   max_worker_size int 最大允许同时运行的 worker 大小,默认 10   num_of_slices int 并行消费单个队列的线程, 运行时最大的 slice 大小   slices array 允许的 slice 编号, int 数组   queue_selector.labels map 根据 Label 来过滤一组需要消费的队列, 同 queues 配置   queue_selector.ids array 指定要消费的队列的 UUID, 字符数组   queue_selector.keys array 指定要消费的队列的唯一 Key 路径, 字符数组   queues map 根据 Label 来过滤一组需要消费的队列, 同 queue_selector.labels 配置   waiting_after array 是否等待指定队列消费完成才开始消费, 队列的 UUID, 字符数组   idle_timeout_in_seconds int 消费队列的超时时间，默认 5, 即 5s   detect_active_queue bool 是否自动检测符合条件的新的队列,默认 true   detect_interval int 自动检测符合条件的新的队列的时间间隔,单位毫秒, 默认 5000   quite_detect_after_idle_in_ms bool 退出自动检测的闲置时间间隔,单位毫秒, 默认 30000   skip_empty_queue bool 是否跳过空队列的消费, 默认 true   quit_on_eof_queue bool 队列执行到最后一条消息自动退出消费, 默认 true   consumer.source string 消费者来源   consumer.id string 消费者唯一标识   consumer.name string 消费者名称   consumer.group string 消费者组名称   consumer.fetch_min_bytes int 拉取消息最小的字节大小, 默认 1   consumer.fetch_max_bytes int 拉取消息最大的字节大小, 默认 10485760, 即 10MB   consumer.fetch_max_messages int 拉取最大的消息个数, 默认 1   consumer.fetch_max_wait_ms int 拉取最大的等待时间, 单位毫秒, 默认 10000   consumer.eof_retry_delay_in_ms int 达到文件末尾重试的等待时间, 单位毫秒, 默认 500    ","subcategory":null,"summary":"","tags":null,"title":"consumer","url":"/gateway/v1.29.7/zh/docs/references/processors/consumer/"},{"category":null,"content":"clone #  描述 #  clone 过滤器用来将流量克隆转发到另外的一个处理流程，可以实现双写、多写、多数据中心同步、集群升级、版本切换等需求。\n配置示例 #  一个简单的示例如下：\nflow: - name: double_write filter: - clone: flows: - write_to_region_a - write_to_region_b #last one's response will be output to client - name: write_to_region_a filter: - elasticsearch: elasticsearch: es1 - name: write_to_region_b filter: - elasticsearch: elasticsearch: es2 上面的例子可以将 Elasticsearch 的请求复制到两个不同的异地集群。\n参数说明 #     名称 类型 说明     flows array 指定多个流量处理的流程，依次同步执行，将最后一个流程处理的结果输出给客户端   continue bool 流量迁移出去之后，是否还继续执行之前的既定流程，设置成 false 则立即返回，默认 false。    ","subcategory":null,"summary":"","tags":null,"title":"clone","url":"/gateway/v1.29.7/zh/docs/references/filters/clone/"},{"category":null,"content":"cache #  描述 #  cache 过滤器由 get_cache 和 set_cache 两组过滤器组成，一般需要组合使用，可用于缓存加速查询，抵挡重复请求，降低后端集群查询压力。\nget_cache 过滤器 #  过滤器 get_cache 用来从缓存里面获取之前出现的消息，直接返回给客户端，避免访问后端 Elasticsearch，用于缓存热点数据。\n配置示例如下：\nflow: - name: get_cache filter: - get_cache: pass_patterns: [\u0026quot;_cat\u0026quot;,\u0026quot;scroll\u0026quot;, \u0026quot;scroll_id\u0026quot;,\u0026quot;_refresh\u0026quot;,\u0026quot;_cluster\u0026quot;,\u0026quot;_ccr\u0026quot;,\u0026quot;_count\u0026quot;,\u0026quot;_flush\u0026quot;,\u0026quot;_ilm\u0026quot;,\u0026quot;_ingest\u0026quot;,\u0026quot;_license\u0026quot;,\u0026quot;_migration\u0026quot;,\u0026quot;_ml\u0026quot;,\u0026quot;_rollup\u0026quot;,\u0026quot;_data_stream\u0026quot;,\u0026quot;_open\u0026quot;, \u0026quot;_close\u0026quot;] 参数说明 #     名称 类型 说明     pass_patterns string 设置忽略缓存的请求规则，URL 包含其中的任意关键字将跳过缓存    set_cache 过滤器 #  过滤器 set_cache 用来将后端查询拿到的返回结果存到缓存里面，可以设置过期时间。\n配置示例如下：\nflow: - name: get_cache filter: - set_cache: min_response_size: 100 max_response_size: 1024000 cache_ttl: 30s max_cache_items: 100000 参数说明 #     名称 类型 说明     cache_type string 缓存类型，支持 ristretto，ccache 和 redis，默认 ristretto   cache_ttl string 缓存的过期时间，默认 10s   async_search_cache_ttl string 异步请求结果的缓存过期时间，默认 10m   min_response_size int 最小符合缓存要求的消息体大小，默认 -1 表示不限制   max_response_size int 最大符合缓存要求的消息体大小，默认为 int 的最大值   max_cached_item int 最大的缓存消息总数，默认 1000000，当类型为 ccache有效   max_cached_size int 最大的缓存内存开销，默认 1000000000 即 1GB，当类型为 ristretto 有效   validated_status_code array 允许被缓存的请求状态码，默认 200,201,404,403,413,400,301    其它参数 #  如果希望主动忽略缓存，可以在 URL 的参数里面传递一个 no_cache 来让网关忽略缓存。如：\ncurl http://localhost:8000/_search?no_cache=true ","subcategory":null,"summary":"","tags":null,"title":"cache","url":"/gateway/v1.29.7/zh/docs/references/filters/cache/"},{"category":null,"content":"bulk_response_process #  描述 #  bulk_response_process 过滤器用来处理 Elasticsearch 的 Bulk 请求。\n配置示例 #  一个简单的示例如下：\nflow: - name: bulk_response_process filter: - bulk_response_process: success_queue: \u0026quot;success_queue\u0026quot; tag_on_success: [\u0026quot;commit_message_allowed\u0026quot;] 参数说明 #     名称 类型 说明     invalid_queue string 保存非法请求的队列名称，必填。   failure_queue string 保存失败请求的队列名称，必填。   save_partial_success_requests bool 是否保存 bulk 请求里面部分执行成功的请求，默认 false。   success_queue string 保存 bulk 请求里面部分执行成功的请求的队列。   continue_on_error bool bulk 请求出错之后是否继续执行后面的 filter，默认 false   message_truncate_size int bulk 请求出错日志截断长度，默认 1024   safety_parse bool 是否采用安全的 bulk 元数据解析方法，默认 true   doc_buffer_size int 当采用不安全的 bulk 元数据解析方法时，使用的 buffer 大小，默认 256 * 1024   tag_on_success array 将所有 bulk 请求处理完成之后，请求上下文打上指定标记   tag_on_error array 请求出现错误的情况下，请求上下文打上指定标记   tag_on_partial array 部分请求执行成功的情况下，请求上下文打上指定标记   tag_on_failure array 部分请求出现失败（可重试）的情况下，请求上下文打上指定标记   tag_on_invalid array 出现不合法请求错误的情况下，请求上下文打上指定标记   success_flow string 请求成功执行的 Flow   invalid_flow string 非法请求执行的 Flow   failure_flow string 失败请求执行的 Flow    ","subcategory":null,"summary":"","tags":null,"title":"bulk_response_process","url":"/gateway/v1.29.7/zh/docs/references/filters/bulk_response_process/"},{"category":null,"content":"bulk_reshuffle #  描述 #  bulk_reshuffle 可以分析 Elasticsearch 的批次请求，并按照文档进行解析，可以根据需要将文档分门别类，归档存储在队列中，通过先落地存储，业务端请求可以快速返回，从而解耦前端写入和后端 Elasticsearch 集群。bulk_reshuffle 需要离线管道消费任务来配合使用。\n通过 bulk_reshuffle 过滤器生成的队列，元数据会默认带上 \u0026quot;type\u0026quot;: \u0026quot;bulk_reshuffle\u0026quot; 以及 Elasticsearch 的集群信息，如：\u0026quot;elasticsearch\u0026quot;: \u0026quot;dev\u0026quot;，通过网关查看队列的 API 也可以查看，如下：\ncurl http://localhost:2900/queue/stats { \u0026quot;queue\u0026quot;: { \u0026quot;disk\u0026quot;: { \u0026quot;async_bulk-cluster##dev\u0026quot;: { \u0026quot;depth\u0026quot;: 0, \u0026quot;metadata\u0026quot;: { \u0026quot;source\u0026quot;: \u0026quot;dynamic\u0026quot;, \u0026quot;id\u0026quot;: \u0026quot;c71f7pqi4h92kki4qrvg\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;async_bulk-cluster##dev\u0026quot;, \u0026quot;label\u0026quot;: { \u0026quot;elasticsearch\u0026quot;: \u0026quot;dev\u0026quot;, \u0026quot;level\u0026quot;: \u0026quot;cluster\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;bulk_reshuffle\u0026quot; } } } } } } 节点级别的异步提交 #  极限网关可以本地计算每个索引文档对应后端 Elasticsearch 集群的目标存放位置，从而能够精准的进行请求定位，在一批 bulk 请求中，可能存在多个后端节点的数据，bulk_reshuffle 过滤器用来将正常的 bulk 请求打散，按照目标节点或者分片进行拆分重新组装，避免 Elasticsearch 节点收到请求之后再次进行请求分发， 从而降低 Elasticsearch 集群间的流量和负载，也能避免单个节点成为热点瓶颈，确保各个数据节点的处理均衡，从而提升集群总体的索引吞吐能力。\n定义流程 #  一个简单的示例如下：\nflow: - name: online_indexing_merge filter: - bulk_reshuffle: elasticsearch: prod level: node #cluster,node,shard,partition - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s elastic: enabled: true remote_configs: false health_check: enabled: true interval: 30s availability_check: enabled: true interval: 60s metadata_refresh: enabled: true interval: 30s cluster_settings_check: enabled: false interval: 20s 以上配置表示会将 bulk 请求拆分，按照索引文档所对应的目标节点，重新拆组装，将数据先落地到本地磁盘队列，然后通过单独的任务来消费提交，分别提交到目标 Elasticsearch 节点。\n使用该 filter 的好处是，即使后端 Elasticsearch 集群出现故障也不会影响索引操作的正常进行，因为请求都已经存放在网关本地的磁盘队列，从而解耦了前端索引和后端集群的依赖。因此就算后端 Elasticsearch 集群出现故障、进行重启、或是版本升级都不会影响正常的索引操作。  配置消费管道 #  网关将请求落地磁盘之后，需要配置一个消费队列的管道来进行数据的提交，如下：\npipeline: - name: bulk_request_ingest auto_start: true processor: - bulk_indexing: queues: type: bulk_reshuffle level: node 这里使用了一个名为 bulk_request_ingest 的管道任务，并且设置要订阅的目标的队列的过滤条件为：type: bulk_reshuffle 和 level: node，还可以设置 bulk 提交的批次大小。 这样当极限网关收到的节点级别的请求会自动的发送到对应的 Elasticsearch 节点。\n分片级别的异步提交 #  分片级别的异步提交比较适合单个索引数据量很大，需要单独处理的场景，通过将索引拆分到分片为单位，然后让 bulk 请求以分片为单位进行提交，进一步提高后端 Elasticsearch 处理的效率。\n具体的配置如下：\n定义流程 #  flow: - name: online_indexing_merge filter: - bulk_reshuffle: elasticsearch: prod level: shard - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 将拆装的级别设置为分片类型。\n定义管道 #  pipeline: - name: bulk_request_ingest auto_start: true processor: - bulk_indexing: queues: type: bulk_reshuffle level: shard 相比前面节点级别的配置，这里主要修改了 level 参数用来监听分片级别类型的磁盘队列，如果索引很多的话本地磁盘队列太多会造成额外的开销，建议仅针对特定要优化吞吐的索引开启该模式。\n参数说明 #     名称 类型 说明     elasticsearch string Elasticsearch 集群实例名称   level string 请求的 shuffle 级别，默认为 cluster，也就是集群级别，还可以设置为 cluster、node、index 和 shard 级别   queue_name_prefix string 队列的名称前缀，默认为 async_bulk   partition_size int 在 level 的基础上，会再次基于文档 _id 进行分区，通过此参数可以设置最大的分区大小   fix_null_id bool 如果 bulk 索引请求的文档里面没有指定文档 id，是否自动生成一个随机的 UUID，适合日志类型数据，默认 true   continue_metadata_missing bool 上下文需要的节点或者分片信息如果不存在是否继续交由后续的过滤器处理请求，否则抛错给客户端，默认 false   continue_after_reshuffle bool 执行完 Reshuffle 之后是否继续后续的流程，默认 false   index_stats_analysis bool 是否记录索引名称统计信息到请求日志，默认 true   action_stats_analysis bool 是否记录批次操作统计信息到请求日志，默认 true   shards array 字符数组类型，如 \u0026quot;0\u0026quot;，设置哪些索引的分片允许被处理，默认所有分片，可以开启只允许特定分片   tag_on_success array 将所有 bulk 请求处理完成之后，请求上下文打上指定标记    ","subcategory":null,"summary":"","tags":null,"title":"bulk_reshuffle","url":"/gateway/v1.29.7/zh/docs/references/filters/bulk_reshuffle/"},{"category":null,"content":"bulk_request_throttle #  描述 #  bulk_request_throttle 过滤器用来对 Elasticsearch 的 Bulk 请求进行限速。\n配置示例 #  一个简单的示例如下：\nflow: - name: bulk_request_mutate filter: - bulk_request_throttle: indices: test: max_requests: 5 action: drop message: \u0026quot;test writing too fast。\u0026quot; log_warn_message: true filebeat-*: max_bytes: 512 action: drop message: \u0026quot;filebeat indices writing too fast。\u0026quot; log_warn_message: true 参数说明 #     名称 类型 说明     indices map 用于限速的索引，可以分别设置限速规则   indices.[NAME].interval string 评估限速的单位时间间隔，默认为 1s   indices.[NAME].max_requests int 单位间隔内最大的请求次数限额   indices.[NAME].burst_requests int 单位间隔内极限允许的请求次数   indices.[NAME].max_bytes int 单位间隔内最大的请求流量限额   indices.[NAME].burst_bytes int 单位间隔内极限允许的流量限额   indices.[NAME].action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   indices.[NAME].status string 设置达到限速条件的返回状态码，默认 429   indices.[NAME].message string 设置达到限速条件的请求的拒绝返回消息   indices.[NAME].retry_delay_in_ms int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   indices.[NAME].max_retry_times int 限速重试的最大重试次数，默认 1000   indices.[NAME].failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息   indices.[NAME].log_warn_message bool 是否输出警告消息到日志    ","subcategory":null,"summary":"","tags":null,"title":"bulk_request_throttle","url":"/gateway/v1.29.7/zh/docs/references/filters/bulk_request_throttle/"},{"category":null,"content":"bulk_request_mutate #  描述 #  bulk_request_mutate 过滤器用来干预 Elasticsearch 的 Bulk 请求。\n配置示例 #  一个简单的示例如下：\nflow: - name: bulk_request_mutate filter: - bulk_request_mutate: fix_null_id: true generate_enhanced_id: true # fix_null_type: true # default_type: m-type # default_index: m-index # index_rename: # \u0026quot;*\u0026quot;: index-new # index1: index-new # index2: index-new # index3: index3-new # index4: index3-new # medcl-dr3: index3-new # type_rename: # \u0026quot;*\u0026quot;: type-new # type1: type-new # type2: type-new # doc: type-new # doc1: type-new \u0026hellip; 参数说明 #\n    名称 类型 说明     fix_null_type bool 是否修复不带 _type 的请求，和参数 default_type 配合使用   fix_null_id bool 是否修复不带 _id 的请求，生成一个随机 id，如 c616rhkgq9s7q1h89ig0   remove_type bool 是否移除 _type 参数，Elasticsearch 8.0 之后不支持 _type 参数   generate_enhanced_id bool 是否生成一个增强的 id 类型，如 c616rhkgq9s7q1h89ig0-1635937734071093-10   default_index string 默认的索引名称，如果元数据里面没有指定，则使用该默认值   default_type string 默认的文档 type，如果没有元数据里面没有指定，则使用该默认值   index_rename map 将索引名称进行重命名，支持 * 来覆盖所有的索引名称   type_rename map 将 type 进行重命名，支持 * 来覆盖所有的 type 名称   pipeline string 指定 bulk 请求的 pipeline 参数   remove_pipeline bool 是否移除 bulk 请求中的 pipeline 参数   safety_parse bool 是否采用安全的 bulk 元数据解析方法，默认 true   doc_buffer_size int 当采用不安全的 bulk 元数据解析方法时，使用的 buffer 大小，默认 256 * 1024    ","subcategory":null,"summary":"","tags":null,"title":"bulk_request_mutate","url":"/gateway/v1.29.7/zh/docs/references/filters/bulk_request_mutate/"},{"category":null,"content":"bulk_indexing #  描述 #  bulk_indexing 处理器用来异步消费队列里面的 bulk 请求。\n配置示例 #  一个简单的示例如下：\npipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - bulk_indexing: queue_selector.labels: type: bulk_reshuffle level: cluster 参数说明 #     名称 类型 说明     elasticsearch string 默认的 Elasticsearch 集群 ID,如果队列 Labels 里面没有指定 elasticsearch 的话会使用这个参数   max_connection_per_node int 目标节点允许的最大连接数，默认 1   max_worker_size int 最大允许同时运行的 worker 大小,默认 10   num_of_slices int 并行消费单个队列的线程, 运行时最大的 slice 大小   slices array 允许的 slice 编号, int 数组   queue_selector.labels map 根据 Label 来过滤一组需要消费的队列, 同 queues 配置   queue_selector.ids array 指定要消费的队列的 UUID, 字符数组   queue_selector.keys array 指定要消费的队列的唯一 Key 路径, 字符数组   queues map 根据 Label 来过滤一组需要消费的队列, 同 queue_selector.labels 配置   waiting_after array 是否等待指定队列消费完成才开始消费, 队列的 UUID, 字符数组   idle_timeout_in_seconds int 消费队列的超时时间，默认 5, 即 5s   detect_active_queue bool 是否自动检测符合条件的新的队列,默认 true   detect_interval bool 自动检测符合条件的新的队列的时间间隔,单位毫秒, 默认 5000   skip_info_missing bool 忽略不满足条件的队列，如节点、索引、分片信息不存在时则需等待信息获取后再消费，默认为 false，否则会随机挑选一个 es 节点来发送请求   skip_empty_queue bool 是否跳过空队列的消费, 默认 true   consumer.source string 消费者来源   consumer.id string 消费者唯一标识   consumer.name string 消费者名称   consumer.group string 消费者组名称   consumer.fetch_min_bytes int 拉取消息最小的字节大小, 默认 1   consumer.fetch_max_bytes int 拉取消息最大的字节大小, 默认 10485760, 即 10MB   consumer.fetch_max_messages int 拉取最大的消息个数, 默认 1   consumer.fetch_max_wait_ms int 拉取最大的等待时间, 单位毫秒, 默认 10000   consumer.eof_retry_delay_in_ms int 达到文件末尾重试的等待时间, 单位毫秒, 默认 500   bulk.compress bool 是否开启请求压缩   bulk.batch_size_in_kb int 批次请求的单位大小，单位 KB   bulk.batch_size_in_mb int 批次请求的单位大小，单位 MB,默认 10   bulk.batch_size_in_docs int 批次请求的文档个数, 默认 1000   bulk.retry_delay_in_seconds int 请求重试的等待时间，默认 1   bulk.reject_retry_delay_in_seconds int 请求拒绝的等待时间，默认 1   bulk.max_retry_times int 最大重试次数   bulk.request_timeout_in_second int HTTP 请求执行的超时时间   bulk.invalid_queue string 因为请求不合法的 4xx 请求队列   bulk.dead_letter_queue string 超过最大重试次数的请求队列   bulk.remove_duplicated_newlines bool 是否主动移除 Bulk 请求里面重复的换行符   bulk.response_handle.save_success_results bool 是否保存执行成功的请求结果，默认 false   bulk.response_handle.output_bulk_stats bool 输出 bulk 统计信息，默认 false   bulk.response_handle.include_index_stats bool 将索引信息包含在 bulk 统计信息内，默认 true   bulk.response_handle.include_action_stats bool 将索引信息包含在 bulk 统计信息内，默认 true   bulk.response_handle.save_error_results bool 是否保存执行出错的请求结果，默认 true   bulk.response_handle.include_error_details bool 包含额外的单条请求的错误日志，默认 true   bulk.response_handle.max_error_details_count bool 单条请求的错误日志总条数，默认 50   bulk.response_handle.save_busy_results bool 是否保存繁忙 429 的日志，默认 true   bulk.response_handle.bulk_result_message_queue string 保存异步日志的消息队列名称，默认 bulk_result_messages   bulk.response_handle.max_request_body_size int 最大的请求体大小，超出截断，默认 10k 即 10240   bulk.response_handle.max_response_body_size int 最大的响应体大小，超出截断，默认 10k 即 10240   bulk.response_handle.retry_rules.retry_429 bool 是否重试 429，默认 true   bulk.response_handle.retry_rules.retry_4xx bool 是否重试 429 以外的 4xx 状态码 ，默认 false   bulk.response_handle.retry_rules.default bool 是否重试retry_rules未配置的其他状态码，默认true   bulk.response_handle.retry_rules.permitted.status []int 允许重试的状态码列表   bulk.response_handle.retry_rules.permitted.keyword []string 允许重试的关键字列表，只要是请求里面包含该任意关键字则重试   bulk.response_handle.retry_rules.denied.status []int 不允许重试的状态码列表   bulk.response_handle.retry_rules.denied.keyword []string 不允许重试的关键字列表，只要是请求里面包含该任意关键字则不重试    ","subcategory":null,"summary":"","tags":null,"title":"bulk_indexing","url":"/gateway/v1.29.7/zh/docs/references/processors/bulk_indexing/"},{"category":null,"content":"basic_auth #  描述 #  basic_auth 过滤器用来验证请求的身份认证信息，适用于简单的身份认证。\n配置示例 #  一个简单的示例如下：\nflow: - name: basic_auth filter: - basic_auth: valid_users: medcl: passwd medcl1: abc ... 参数说明 #     名称 类型 说明     valid_users map 用户名和密码    ","subcategory":null,"summary":"","tags":null,"title":"basic_auth","url":"/gateway/v1.29.7/zh/docs/references/filters/basic_auth/"},{"category":null,"content":"auto_generate_doc_id #  描述 #  过滤器 auto_generate_doc_id 用于在创建文档时为其添加 UUID（通用唯一标识符），当创建文档时没有显式指定 UUID 时使用该过滤器。通常情况下，这适用于不希望后端系统自动生成 ID 的情况。例如，如果您想在集群之间复制文档，最好为文档分配一个已知的 ID，而不是让每个集群为文档生成自己的 ID。否则，这可能导致集群之间的不一致性。\n配置示例 #  A simple example is as follows:\nflow: - name: test_auto_generate_doc_id filter: - auto_generate_doc_id: 参数说明 #     名称 类型 说明     prefix string 给 UUID 增加一个固定前缀    ","subcategory":null,"summary":"","tags":null,"title":"auto_generate_doc_id","url":"/gateway/v1.29.7/zh/docs/references/filters/auto_generate_doc_id/"},{"category":null,"content":"其它配置 #  高级用法 #  配置模板 #  示例：\nconfigs.template: - name: \u0026quot;es_gw1\u0026quot; path: ./sample-configs/config_template.tpl variable: name: \u0026quot;es_gw1\u0026quot; binding_host: \u0026quot;0.0.0.0:8000\u0026quot; tls_on_entry: true elasticsearch_endpoint: \u0026quot;http://localhost:9200\u0026quot;    名称 类型 说明     configs.template array 配置模板，可以指定多个模板和对应的参数   configs.template[].name string 配置的名称   configs.template[].path string 模板配置路径   configs.template[].variable map 模板的参数设置，变量在模板里面的用法：$[[变量名]]    使用环境变量 #  极限网关支持在配置里面使用环境变量来进行灵活的参数控制。\n首先在配置里面定义环境变量的默认值，如下：\nenv: PROD_ES_ENDPOINT: http://localhost:9200 PROD_ES_USER: elastic PROD_ES_PASS: password 然后就可以在配置里面通过如下语法来使用环境变量了：\nelasticsearch: - name: prod enabled: true endpoints: - $[[env.PROD_ES_ENDPOINT]] discovery: enabled: false basic_auth: username: $[[env.PROD_ES_USER]] password: $[[env.PROD_ES_PASS]] 注意，外部环境变量的优先级会大于配置内部的环境变量设置，比如希望在启动程序的时候覆盖环境变量，操作如下：\nPROD_ES_ENDPOINT=http://1.1.1.1:9200 LOGGING_ES_ENDPOINT=http://2.2.2.2:9201 ./bin/gateway Path #  配置、数据、日志相关路径配置。\n示例：\npath.data: data path.logs: log path.configs: \u0026#34;config\u0026#34;    名称 类型 说明     path.data string 数据目录，默认为 data   path.logs string 日志目录，默认为 log   path.configs string 配置目录，默认为 config    Log #  日志相关配置。\n示例：\nlog: level: info debug: false    名称 类型 说明     log.level string 日志级别，默认为 info   log.debug bool 是否开启调试模式，当开启的时候，一旦出现异常程序直接退出，打印完整堆栈，仅用于调试定位故障点，默认为 false，生产环境不要开启，可能丢数据   log.format bool 日志格式，默认为 [%Date(01-02) %Time] [%LEV] [%File:%Line] %Msg%n， Format References   log.disable_file_output bool 是否关闭本地文件的日志输出，默认为 false，容器环境不希望本地日志输出的可以开启本参数    Configs #  配置管理相关配置。\n示例：\nconfigs: auto_reload: true managed: true panic_on_config_error: false interval: \u0026#34;1s\u0026#34; servers: - \u0026#34;http://localhost:9000\u0026#34; max_backup_files: 5 soft_delete: false tls: enabled: false cert_file: /etc/ssl.crt key_file: /etc/ssl.key skip_insecure_verify: false    名称 类型 说明     configs.auto_reload bool 是否支持 path.configs 里面配置的动态加载   configs.managed bool 是否支持由配置中心进行配置管理   configs.servers []string 配置中心地址   configs.interval string 配置同步间隔   configs.soft_delete bool 配置文件删除为软删除，默认 true   configs.panic_on_config_error bool 配置加载如果有错误就直接崩溃，默认 true   configs.max_backup_files int 配置文件最大备份数，默认 10   configs.valid_config_extensions []string 有效的配置文件后缀，默认 .tpl, .json, .yml, .yaml   configs.tls object TLS 配置（请参考通用 TLS 配置）   configs.always_register_after_restart bool 实例重启后是否进行注册，实例运行在 K8S 环境下，需开启此参数。   configs.allow_generated_metrics_tasks bool 允许自动生成采集指标任务   configs.ignored_path []string 需要忽略的配置文件路径    本地磁盘队列 #  示例：\ndisk_queue: upload_to_s3: true s3: server: my_blob_store location: cn-beijing-001 bucket: infini-store max_bytes_per_file: 102400    名称 类型 说明     disk_queue.min_msg_size int 发送到队列单条消息的最小字节限制，默认 1   disk_queue.max_msg_size int 发送到队列单条消息的最大字节限制，默认 104857600，即 100MB   disk_queue.sync_every_records int 每隔多少条记录进行一次 sync 磁盘同步操作，默认 1000   disk_queue.sync_timeout_in_ms int 每隔多长时间进行一次 sync 磁盘同步操作，默认 1000 毫秒   disk_queue.max_bytes_per_file int 本地磁盘队列单个文件的最大值，超过此大小自动滚动新文件，默认 104857600，即 100MB   disk_queue.max_used_bytes int 本地磁盘队列可允许的最大存储使用空间大小   disk_queue.warning_free_bytes int 磁盘达到告警阈值的空闲存储空间大小，默认 10737418240 即 10GB   disk_queue.reserved_free_bytes int 磁盘空闲存储空间大小的保护值，达到会变成只读，不允许写，默认 5368709120 即 5GB   disk_queue.auto_skip_corrupted_file bool 是否自动跳过损坏的磁盘文件，默认 true   disk_queue.upload_to_s3 bool 是否将磁盘队列文件上传到 S3，默认 false   disk_queue.s3.async bool 是否异步上传到 S3 服务器   disk_queue.s3.server string S3 服务器 ID   disk_queue.s3.location string S3 服务器位置   disk_queue.s3.bucket string S3 服务器 Bucket   disk_queue.retention.max_num_of_local_files int 上传 s3 完的文件，按照最新的文件排序，保留在本地磁盘上的最大文件数，默认 3   disk_queue.compress.segment.enabled bool 是否开启文件级别的压缩，默认 false    S3 #  示例：\ns3: my_blob_store: endpoint: \u0026quot;192.168.3.188:9000\u0026quot; access_key: \u0026quot;admin\u0026quot; access_secret: \u0026quot;gogoaminio\u0026quot;    名称 类型 说明     s3.[id].endpoint string S3 服务器地址   s3.[id].access_key string S3 服务器 Key   s3.[id].access_secret string S3 服务器秘钥   s3.[id].token string S3 服务器 Token 信息   s3.[id].ssl bool S3 服务器是否开启了 TLS   s3.[id].skip_insecure_verify bool 是否忽略 TLS 证书校验    Kafka #  极限网关支持在使用分布式 Kafka 作为后端队列，相关参数如下。\n   名称 类型 说明     kafka.enabled bool Kafka 模块是否开启   kafka.default bool Kafka 模块是否作为默认 Queue 的实现   kafka.num_of_partition int 默认的分区数量，默认 1   kafka.num_of_replica int 默认的分区副本数量，默认 1   kafka.producer_batch_max_bytes int 最大提交请求大小，默认 50 * 1024 * 1024   kafka.max_buffered_records int 最大缓存请求记录数，默认 10000   kafka.manual_flushing bool 是否手动 flushing，默认 false   kafka.brokers []string 服务器地址信息   kafka.username string 用户信息   kafka.password string 密码信息    Badger #  Badger 是一个轻量级的基于磁盘的 KeyValue 存储引擎，极限网关使用 Badger 来实现 KV 模块的存储。\n   名称 类型 说明     badger.enabled bool 是否启用 Badger实现的 KV 模块，默认为 true   badger.single_bucket_mode bool Badger 模块使用单桶模式，默认为 true   badger.sync_writes bool Badger 模块使用同步写，默认为 false   badger.mem_table_size int64 Badger 模块的内存表大小，默认为 10 * 1024 * 1024，即 10485760   badger.value_log_file_size int64 Badger 模块的日志文件大小，默认为 1\u0026lt;\u0026lt;30 - 1，即 1g   badger.value_log_max_entries int64 Badger 模块的日志消息个数，默认为 1000000，即 1million   badger.value_threshold int64 Badger 模块的值大小阈值，默认为 1048576，即 1m   badger.num_mem_tables int64 Badger 模块的内存表个数，默认为 1   badger.num_level0_tables int64 Badger 模块的 Level0 内存表个数，默认为 1    资源限制 #     名称 类型 说明     resource_limit.cpu.max_num_of_cpus int 允许使用的最大 CPU 核数，仅用于 Linux 操作系统，且 taskset 命令可用   resource_limit.cpu.affinity_list string 允许使用的 CPU 绑定设置，eg: 0,2,5 或 0-8，仅用于 Linux 操作系统，且 taskset 命令可用   resource_limit.memory.max_in_bytes string 允许使用的内存的最大大小，软性限制    网络配置 #  公共的网络配置说明。\n   名称 类型 说明     *.network.host string 服务监听的网络地址，例如，192.168.3.10   *.network.port int 服务监听的端口地址，例如，8000   *.network.binding string 服务监听的网络绑定地址，例如，0.0.0.0:8000   *.network.publish string 服务监听的外部访问地址，例如，192.168.3.10:8000   *.network.reuse_port bool 是否在多进程端口共享中重用网络端口   *.network.skip_occupied_port bool 是否自动跳过已占用的端口    TLS 配置 #  公共的 TLS 配置说明。\n   名称 类型 说明     *.tls.enabled bool 是否启用 TLS 安全传输，不指定证书可自动生成   *.tls.ca_file string TLS 安全证书的公共 CA 证书路径   *.tls.cert_file string TLS 安全证书的公共密钥路径   *.tls.key_file string TLS 安全证书的私钥路径   *.tls.skip_insecure_verify bool 是否忽略 TLS 证书验证   *.tls.default_domain string 用于自动生成证书的默认域名   *.tls.skip_domain_verify bool 是否跳过域名验证   *.tls.client_session_cache_size int 设置 TLS 会话恢复的最大客户端会话状态缓存大小    API #     名称 类型 说明     api.enabled bool 是否启用 API 模块， 默认为 true   api.network object 网络配置，请参考通用网络配置部分   api.tls object TLS 配置，请参考通用 TLS 配置部分   api.security object API 模块的安全配置   api.security.enabled bool 是否启用安全性   api.security.username string 安全性的用户名   api.security.password string 安全性的密码   api.cors.allowed_origins []string 跨域请求可以执行的源列表   api.websocket object API 模块的 WebSocket 配置   api.websocket.enabled object 是否启用 WebSocket   api.websocket.permitted_hosts []string 允许访问 WebSocket 服务的主机列表   api.websocket.skip_host_verify bool 是否跳过验证 WebSocket 的主机    Metrics #  配置系统指标采集。\n示例：\nmetrics: enabled: true queue: metrics network: enabled: true summary: true details: true memory: metrics: - swap - memory disk: metrics: - iops - usage cpu: metrics: - idle - system - user - iowait - load    名称 类型 说明     enabled bool 是否开启系统指标采集，默认 true   queue string 指标采集队列   network object 采集网络指标配置   network.enabled bool 是否采集网络指标，默认 true   network.summary bool 是否采集 summary 指标   network.sockets bool 是否采集相关 socket 指标   network.throughput bool 是否采集 throughput 指标   network.details bool 是否将网络 IO 指标进行累计   network.interfaces []string 指定需要采集的网络接口，默认采集所有接口   memory object 采集内存指标配置   memory.enabled bool 是否开启内存指标的采集，默认 true   memory.metrics []string 指定采集相关指标，可选 swap，memory   disk object 采集磁盘指标配置   disk.metrics []string 指定采集相关指标，可选 usage，iops   cpu object 采集 CPU 指标配置   cpu.metrics []string 指定采集相关指标，可选 idle，system，user，iowait，load    Node #  节点相关配置。\n示例：\nnode: major_ip_pattern: \u0026#34;.*\u0026#34; labels: env: dev tags: - linux - x86 - es7    名称 类型 说明     major_ip_pattern string 如果主机上有多个 IP，用 pattern 来控制以哪个 IP 为主，当注册时用于上报。   labels map 自定义标签   tags []string 自定义标签    其它配置 #     名称 类型 说明     preference.pipeline_enabled_by_default map Pipeline 是否默认启动，如果改成 false，则需要每个 Pipeline 配置显式设置 enabled 为 true   allow_multi_instance bool 是否允许同一程序启动多个实例，默认为 false   skip_instance_detect bool 是否跳过实例检测，默认为 false   max_num_of_instances int 同一程序可同时运行的实例的最大个数，默认为 5    ","subcategory":null,"summary":"","tags":null,"title":"其它配置","url":"/gateway/v1.29.7/zh/docs/references/config/"},{"category":null,"content":"在 Kibana 里统一访问来自不同集群的索引 #  现在有这么一个需求，客户根据需要将数据按照业务维度划分，将索引分别存放在了不同的三个集群， 将一个大集群拆分成多个小集群有很多好处，比如降低了耦合，带来了集群可用性和稳定性方面的好处，也避免了单个业务的热点访问造成其他业务的影响， 尽管拆分集群是很常见的玩法，但是管理起来不是那么方便了，尤其是在查询的时候，可能要分别访问三套集群各自的 API，甚至要切换三套不同的 Kibana 来访问集群的数据， 那么有没有办法将他们无缝的联合在一起呢？\n极限网关! #  答案自然是有的，通过将 Kibana 访问 Elasticsearch 的地址切换为极限网关的地址，我们可以将请求按照索引来进行智能的路由， 也就是当访问不同的业务索引时会智能的路由到不同的集群，如下图：\n上图，我们分别有 3 个不同的索引：\n apm-* erp-* mall-*  分别对应不同的三套 Elasticsearch 集群:\n ES1-APM ES2-ERP ES3-MALL  接下来我们来看如何在极限网关里面进行相应的配置来满足这个业务需求。\n配置集群信息 #  首先配置 3 个集群的连接信息。\nelasticsearch: - name: es1-apm enabled: true endpoints: - http://192.168.3.188:9206 - name: es2-erp enabled: true endpoints: - http://192.168.3.188:9207 - name: es3-mall enabled: true endpoints: - http://192.168.3.188:9208 配置服务 Flow #  然后，我们定义 3 个 Flow，分别对应用来访问 3 个不同的 Elasticsearch 集群，如下：\nflow: - name: es1-flow filter: - elasticsearch: elasticsearch: es1-apm - name: es2-flow filter: - elasticsearch: elasticsearch: es2-erp - name: es3-flow filter: - elasticsearch: elasticsearch: es3-mall 然后再定义一个 flow 用来进行路径的判断和转发，如下：\n - name: default-flow filter: - switch: remove_prefix: false path_rules: - prefix: \u0026quot;apm-\u0026quot; flow: es1-flow - prefix: \u0026quot;erp-\u0026quot; flow: es2-flow - prefix: \u0026quot;mall-\u0026quot; flow: es3-flow - flow: #default flow flows: - es1-flow 根据请求路径里面的索引前缀来匹配不同的索引，并转发到不同的 Flow。\n配置路由信息 #  接下来，我们定义路由信息，具体配置如下：\nrouter: - name: my_router default_flow: default-flow 指向上面定义的默认 flow 来统一请求的处理。\n定义服务及关联路由 #  最后，我们定义一个监听为 8000 端口的服务，用来提供给 Kibana 来进行统一的入口访问，如下：\nentry: - name: es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 完整配置 #  最后的完整配置如下：\npath.data: data path.logs: log entry:\n name: es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000  flow:\n name: default-flow filter:  switch: remove_prefix: false path_rules: - prefix: \u0026quot;apm-\u0026quot; flow: es1-flow - prefix: \u0026quot;erp-\u0026quot; flow: es2-flow - prefix: \u0026quot;mall-\u0026quot; flow: es3-flow flow: #default flow flows: - es1-flow   name: es1-flow filter:  elasticsearch: elasticsearch: es1-apm   name: es2-flow filter:  elasticsearch: elasticsearch: es2-erp   name: es3-flow filter:  elasticsearch: elasticsearch: es3-mall    router:\n name: my_router default_flow: default-flow  elasticsearch:\n name: es1-apm enabled: true endpoints:  http://192.168.3.188:9206   name: es2-erp enabled: true endpoints:  http://192.168.3.188:9207   name: es3-mall enabled: true endpoints:  http://192.168.3.188:9208 启动网关 #     直接启动网关，如下：\n➜ gateway git:(master) ✗ ./bin/gateway -config sample-configs/elasticsearch-route-by-index.yml  / _ \\ /\\ /__ /__/ / /\\ \\ /\\ /_/\n/ ////\\ / //\\ \\ / / //\\_ / / /\\/ _ / / //__ \\ /\\ / _ /\n____/_/ _// __/ / /_/ _/_/\n[GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, 2022-04-20 08:23:56, 2023-12-31 10:10:10, 51650a5c3d6aaa436f3c8a8828ea74894c3524b9 [04-21 13:41:21] [INF] [app.go:174] initializing gateway. [04-21 13:41:21] [INF] [app.go:175] using config: /Users/medcl/go/src/infini.sh/gateway/sample-configs/elasticsearch-route-by-index.yml. [04-21 13:41:21] [INF] [instance.go:72] workspace: /Users/medcl/go/src/infini.sh/gateway/data/gateway/nodes/c9bpg0ai4h931o4ngs3g [04-21 13:41:21] [INF] [app.go:283] gateway is up and running now. [04-21 13:41:21] [INF] [api.go:262] api listen at: http://0.0.0.0:2900 [04-21 13:41:21] [INF] [reverseproxy.go:255] elasticsearch [es1-apm] hosts: [] =\u0026gt; [192.168.3.188:9206] [04-21 13:41:21] [INF] [reverseproxy.go:255] elasticsearch [es2-erp] hosts: [] =\u0026gt; [192.168.3.188:9207] [04-21 13:41:21] [INF] [reverseproxy.go:255] elasticsearch [es3-mall] hosts: [] =\u0026gt; [192.168.3.188:9208] [04-21 13:41:21] [INF] [actions.go:349] elasticsearch [es2-erp] is available [04-21 13:41:21] [INF] [actions.go:349] elasticsearch [es1-apm] is available [04-21 13:41:21] [INF] [entry.go:312] entry [es_entry] listen at: http://0.0.0.0:8000 [04-21 13:41:21] [INF] [module.go:116] all modules are started [04-21 13:41:21] [INF] [actions.go:349] elasticsearch [es3-mall] is available [04-21 13:41:55] [INF] [reverseproxy.go:255] elasticsearch [es1-apm] hosts: [] =\u0026gt; [192.168.3.188:9206] 网关启动成功之后，就可以通过网关的 IP+8000 端口来访问目标 Elasticsearch 集群了。\n测试访问 #  首先通过 API 来访问测试一下，如下：\n➜ ~ curl http://localhost:8000/apm-2022/_search -v * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET /apm-2022/_search HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Date: Thu, 21 Apr 2022 05:45:44 GMT \u0026lt; content-type: application/json; charset=UTF-8 \u0026lt; Content-Length: 162 \u0026lt; X-elastic-product: Elasticsearch \u0026lt; X-Backend-Cluster: es1-apm \u0026lt; X-Backend-Server: 192.168.3.188:9206 \u0026lt; X-Filters: filters-\u0026gt;elasticsearch \u0026lt; * Connection #0 to host localhost left intact {\u0026quot;took\u0026quot;:142,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:{\u0026quot;value\u0026quot;:0,\u0026quot;relation\u0026quot;:\u0026quot;eq\u0026quot;},\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}}% 可以看到 apm-2022 指向了后端的 es1-apm 集群。\n继续测试，erp 索引的访问，如下：\n➜ ~ curl http://localhost:8000/erp-2022/_search -v * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET /erp-2022/_search HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Date: Thu, 21 Apr 2022 06:24:46 GMT \u0026lt; content-type: application/json; charset=UTF-8 \u0026lt; Content-Length: 161 \u0026lt; X-Backend-Cluster: es2-erp \u0026lt; X-Backend-Server: 192.168.3.188:9207 \u0026lt; X-Filters: filters-\u0026gt;switch-\u0026gt;filters-\u0026gt;elasticsearch-\u0026gt;skipped \u0026lt; * Connection #0 to host localhost left intact {\u0026quot;took\u0026quot;:12,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:{\u0026quot;value\u0026quot;:0,\u0026quot;relation\u0026quot;:\u0026quot;eq\u0026quot;},\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}}% 继续测试，mall 索引的访问，如下：\n➜ ~ curl http://localhost:8000/mall-2022/_search -v * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET /mall-2022/_search HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Date: Thu, 21 Apr 2022 06:25:08 GMT \u0026lt; content-type: application/json; charset=UTF-8 \u0026lt; Content-Length: 134 \u0026lt; X-Backend-Cluster: es3-mall \u0026lt; X-Backend-Server: 192.168.3.188:9208 \u0026lt; X-Filters: filters-\u0026gt;switch-\u0026gt;filters-\u0026gt;elasticsearch-\u0026gt;skipped \u0026lt; * Connection #0 to host localhost left intact {\u0026quot;took\u0026quot;:8,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:5,\u0026quot;successful\u0026quot;:5,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:0,\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}}% 完美转发。\n其他方式 #  除了使用 switch 过滤器，使用路由本身的规则也是可以实现，具体示例配置如下：\nflow: - name: default_flow filter: - echo: message: \u0026quot;hello world\u0026quot; - name: mall_flow filter: - echo: message: \u0026quot;hello mall indices\u0026quot; - name: apm_flow filter: - echo: message: \u0026quot;hello apm indices\u0026quot; - name: erp_flow filter: - echo: message: \u0026quot;hello erp indices\u0026quot; router: - name: my_router default_flow: default_flow rules: - method: - \u0026quot;*\u0026quot; pattern: - \u0026quot;/apm-{suffix:.*}/\u0026quot; - \u0026quot;/apm-{suffix:.*}/{any:.*}\u0026quot; flow: - apm_flow - method: - \u0026quot;*\u0026quot; pattern: - \u0026quot;/erp-{suffix:.*}/\u0026quot; - \u0026quot;/erp-{suffix:.*}/{any:.*}\u0026quot; flow: - erp_flow - method: - \u0026quot;*\u0026quot; pattern: - \u0026quot;/mall-{suffix:.*}/\u0026quot; - \u0026quot;/mall-{suffix:.*}/{any:.*}\u0026quot; flow: - mall_flow 极限网关功能强大，实现一个功能的方式可以有很多种，这里暂不展开。\n修改 Kibana 配置 #  修改 Kibana 的配置文件: kibana.yml，替换 Elasticsearch 的地址为网关地址(http://192.168.3.200:8000)，如下：\nelasticsearch.hosts: [\u0026quot;http://192.168.3.200:8000\u0026quot;] 重启 Kibana 让配置生效。\n效果如下 #  可以看到，在一个 Kibana 的开发者工具里面，我们已经可以像操作一个集群一样来同时读写实际上来自三个不同集群的索引数据了。\n展望 #  通过极限网关，我们还可以非常灵活的进行在线请求的流量编辑，动态组合不同集群的操作。\n","subcategory":null,"summary":"","tags":null,"title":"在 Kibana 里统一访问来自不同集群的索引","url":"/gateway/v1.29.7/zh/docs/tutorial/routing_to_cluser_by_index/"},{"category":null,"content":"兼容不同版本的查询响应结果的 Count 结构 #  Elasticsearch 在 7.0 之后的版本中，为了优化性能，搜索结果的命中数默认不进行精确的计数统计，同时对搜索结果的响应体进行了调整， 这样势必会造成已有代码的不兼容，如何快速修复呢？\n结构对比 #  首先来对比下前后差异：\n7 之前的搜索结构如下，total 显示的具体的数值：\n{ \u0026quot;took\u0026quot;: 53, \u0026quot;timed_out\u0026quot;: false, \u0026quot;_shards\u0026quot;: { \u0026quot;total\u0026quot;: 1, \u0026quot;successful\u0026quot;: 1, \u0026quot;skipped\u0026quot;: 0, \u0026quot;failed\u0026quot;: 0 }, \u0026quot;hits\u0026quot;: { \u0026quot;total\u0026quot;: 0, \u0026quot;max_score\u0026quot;: null, \u0026quot;hits\u0026quot;: [] } } 7 之后的搜索结构如下，total 变成了一组描述范围的对象：\n{ \u0026quot;took\u0026quot;: 3, \u0026quot;timed_out\u0026quot;: false, \u0026quot;_shards\u0026quot;: { \u0026quot;total\u0026quot;: 1, \u0026quot;successful\u0026quot;: 1, \u0026quot;skipped\u0026quot;: 0, \u0026quot;failed\u0026quot;: 0 }, \u0026quot;hits\u0026quot;: { \u0026quot;total\u0026quot;: { \u0026quot;value\u0026quot;: 10000, \u0026quot;relation\u0026quot;: \u0026quot;gte\u0026quot; }, \u0026quot;max_score\u0026quot;: 1, \u0026quot;hits\u0026quot;: [] } } Elasticsearch 提供的参数 #  不过在 7 里面，Elasticsearch 也提供了一个参数来控制是否进行精确计数，通过在查询请求的 url 参数里面加上 rest_total_hits_as_int=true 即可使用旧的行为方式，默认未开启。\n文档链接：https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html\n不过需要修改程序来添加这个参数，可能需要调整后端代码和前端分页及展示的相关，改动量可能不小。\n使用极限网关来快速修复 #  如果不希望修改程序，可以使用极限网关来快速修复相应的查询，并主动为搜索查询添加相应的查询参数，同时还可以限定为哪些请求来源进行添加， 比如，只对特定的业务调用方来进行调整，这里以 curl 命令来进行举例，只对来自 curl 调试的查询进行添加，示例如下：\nentry: - name: es_entrypoint enabled: true router: default network: binding: 0.0.0.0:8000 router:\n name: default default_flow: main_flow  flow:\n name: main_flow filter:  set_request_query_args: args:  rest_total_hits_as_int -\u0026gt; true when: and:  contains: _ctx.request.path: \u0026quot;_search\u0026quot; equals: _ctx.request.header.User-Agent: \u0026quot;curl/7.54.0\u0026quot;     record: stdout: true elasticsearch: elasticsearch: es-server dump: response_body: true    elasticsearch:\n name: es-server enabled: true endpoints:  http://192.168.3.188:9206    最后效果如下：\n如图 1 表示走浏览器访问网关的搜索结果，2 表示走命令行 curl 命令返回的搜索结果，其中通过 User-Agent 头信息可以匹配到 curl 命令，同时只对搜索条件附加参数，避免影响其他的请求。\n","subcategory":null,"summary":"","tags":null,"title":"兼容不同版本的响应 Count 结构","url":"/gateway/v1.29.7/zh/docs/tutorial/fix_count_in_search_response/"},{"category":null,"content":"使用 JavaScript 脚本来进行复杂的查询改写 #  有这么一个需求：\n 网关里怎样对跨集群搜索进行支持的呢？我想实现: 输入的搜索请求是 lp:9200/index1/_search 这个索引在 3 个集群上，需要跨集群检索，也就是网关能否改成 lp:9200/cluster01:index1,cluster02,index1,cluster03:index1/_search 呢？ 索引有一百多个，名称不一定是 app, 还可能多个索引一起的。\n 极限网关自带的过滤器 content_regex_replace 虽然可以实现字符正则替换，但是这个需求是带参数的变量替换，稍微复杂一点，没有办法直接用这个正则替换实现，有什么其他办法实现么？\n使用脚本过滤器 #  当然有的，上面的这个需求，理论上我们只需要将其中的索引 index1 匹配之后，替换为 cluster01:index1,cluster02,index1,cluster03:index1 就行了。\n答案就是使用自定义脚本来做，再复杂的业务逻辑都不是问题，都能通过自定义脚本来实现，一行脚本不行，那就两行。\n使用极限网关提供的 JavaScript 过滤器可以很灵活的实现这个功能，具体继续看。\n定义脚本 #  首先创建一个脚本文件，放在网关数据目录的 scripts 子目录下面，如下：\n➜ gateway ✗ tree data data └── gateway └── nodes └── c9bpg0ai4h931o4ngs3g ├── kvdb ├── queue ├── scripts │ └── index_path_rewrite.js └── stats 这个脚本的内容如下：\nfunction process(context) { var originalPath = context.Get(\u0026quot;_ctx.request.path\u0026quot;); var matches = originalPath.match(/\\/?(.*?)\\/_search/) var indexNames = []; if(matches \u0026amp;\u0026amp; matches.length \u0026gt; 1) { indexNames = matches[1].split(\u0026quot;,\u0026quot;) } var resultNames = [] var clusterNames = [\u0026quot;cluster01\u0026quot;, \u0026quot;cluster02\u0026quot;] if(indexNames.length \u0026gt; 0) { for(var i=0; i\u0026lt;indexNames.length; i++){ if(indexNames[i].length \u0026gt; 0) { for(var j=0; j\u0026lt;clusterNames.length; j++){ resultNames.push(clusterNames[j]+\u0026quot;:\u0026quot;+indexNames[i]) } } } } if (resultNames.length\u0026amp;gt;0){ var newPath=\u0026amp;quot;/\u0026amp;quot;+resultNames.join(\u0026amp;quot;,\u0026amp;quot;)+\u0026amp;quot;/_search\u0026amp;quot;; context.Put(\u0026amp;quot;_ctx.request.path\u0026amp;quot;,newPath); }  } 和普通的 JavaScript 一样，定义一个特定的函数 process 来处理请求里面的上下文信息，_ctx.request.path 是网关内置上下文的一个变量，用来获取请求的路径，通过 context.Get(\u0026quot;_ctx.request.path\u0026quot;) 在脚本里面进行访问。\n中间我们使用了 JavaScript 的正则匹配和字符处理，做了一些字符拼接，得到新的路径 newPath 变量，最后使用 context.Put(\u0026quot;_ctx.request.path\u0026quot;,newPath) 更新网关请求的路径信息，从而实现查询条件里面的参数替换。\n有关网关内置上下文的变量列表，请访问 Request Context\n定义网关 #  接下来，创建一个网关配置，并使用 javascript 过滤器调用该脚本，如下：\nentry: - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 flow:\n name: default_flow filter:  dump: context: - _ctx.request.path javascript: file: index_path_rewrite.js dump: context:  _ctx.request.path   elasticsearch: elasticsearch: dev router:   name: my_router default_flow: default_flow  elasticsearch:\n name: dev enabled: true schema: http hosts:  192.168.3.188:9206 上面的例子中，使用了一个 javascript 过滤器，并且指定了加载的脚本文件为 index_path_rewrite.js，并使用了两个 dump 过滤器来输出脚本运行前后的路径信息，最后再使用一个 elasticsearch 过滤器来转发请求给 Elasticsearch 进行查询。\n    启动网关 #  我们启动网关测试一下，如下：\n➜ gateway ✗ ./bin/gateway ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, 2022-04-18 07:11:09, 2023-12-31 10:10:10, 8062c4bc6e57a3fefcce71c0628d2d4141e46953 [04-19 11:41:29] [INF] [app.go:174] initializing gateway. [04-19 11:41:29] [INF] [app.go:175] using config: /Users/medcl/go/src/infini.sh/gateway/gateway.yml. [04-19 11:41:29] [INF] [instance.go:72] workspace: /Users/medcl/go/src/infini.sh/gateway/data/gateway/nodes/c9bpg0ai4h931o4ngs3g [04-19 11:41:29] [INF] [app.go:283] gateway is up and running now. [04-19 11:41:30] [INF] [api.go:262] api listen at: http://0.0.0.0:2900 [04-19 11:41:30] [INF] [entry.go:312] entry [my_es_entry] listen at: http://0.0.0.0:8000 [04-19 11:41:30] [INF] [module.go:116] all modules are started [04-19 11:41:30] [INF] [actions.go:349] elasticsearch [dev] is available 执行测试 #\n 运行下面的查询来验证查询结果，如下：\ncurl localhost:8000/abc,efg/_search 可以看到网关通过 dump 过滤器输出的调试信息：\n---- DUMPING CONTEXT ---- _ctx.request.path : /abc,efg/_search ---- DUMPING CONTEXT ---- _ctx.request.path : /cluster01:abc,cluster02:abc,cluster01:efg,cluster02:efg/_search 查询条件按照我们的需求进行了改写，Nice！\n重写 DSL 查询语句 #  好吧，我们刚刚只是修改了查询的索引而已，那么查询请求的 DSL 呢？行不行？\n那自然是可以的嘛，瞧下面的例子:\nfunction process(context) { var originalDSL = context.Get(\u0026quot;_ctx.request.body\u0026quot;); if (originalDSL.length \u0026gt;0){ var jsonObj=JSON.parse(originalDSL); jsonObj.size=123; jsonObj.aggs= { \u0026quot;test1\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;abc\u0026quot;, \u0026quot;size\u0026quot;: 10 } } } context.Put(\u0026quot;_ctx.request.body\u0026quot;,JSON.stringify(jsonObj)); } } 先是获取查询请求，然后转换成 JSON 对象，之后任意修改查询对象就行了，保存回去，搞掂。\n测试一下:\n curl -XPOST localhost:8000/abc,efg/_search -d'{\u0026quot;query\u0026quot;:{}}' 输出:\n---- DUMPING CONTEXT ---- _ctx.request.path : /abc,efg/_search _ctx.request.body : {\u0026quot;query\u0026quot;:{}} [04-19 18:14:24] [INF] [reverseproxy.go:255] elasticsearch [dev] hosts: [] =\u0026gt; [192.168.3.188:9206] ---- DUMPING CONTEXT ---- _ctx.request.path : /abc,efg/_search _ctx.request.body : {\u0026quot;query\u0026quot;:{},\u0026quot;size\u0026quot;:123,\u0026quot;aggs\u0026quot;:{\u0026quot;test1\u0026quot;:{\u0026quot;terms\u0026quot;:{\u0026quot;field\u0026quot;:\u0026quot;abc\u0026quot;,\u0026quot;size\u0026quot;:10}}}} 是不是感觉解锁了新的世界？\n结论 #  通过使用 Javascript 脚本过滤器，我们可以非常灵活的进行复杂逻辑的操作来满足我们的业务需求。\n","subcategory":null,"summary":"","tags":null,"title":"使用 JavaScript 脚本来进行复杂的查询改写","url":"/gateway/v1.29.7/zh/docs/tutorial/path_rewrite_by_javascript/"},{"category":null,"content":"为 Kibana 添加代理和基础安全 #  如果你的 Kibana 版本比较多或者比较旧，或者没有设置 TLS 和身份信息，那么任何人都有可能直接访问 Kibana，而使用极限网关可以快速的进行修复。\n使用 HTTP 过滤器来转发请求 #   - http: schema: \u0026quot;http\u0026quot; #https or http host: \u0026quot;192.168.3.188:5602\u0026quot; 添加身份验证 #   - basic_auth: valid_users: medcl: passwd 在路由里面可以替换静态资源 #   - method: - GET pattern: - \u0026quot;/plugins/kibanaReact/assets/illustration_integrations_lightmode.svg\u0026quot; flow: - replace_logo_flow 开启 TLS #   - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 tls: enabled: true 完整配置如下 #  entry: - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 skip_occupied_port: true tls: enabled: true flow:\n name: logout_flow filter:  set_response: status: 401 body: \u0026quot;Success logout!\u0026quot; drop:   name: replace_logo_flow filter:  redirect: uri: https://elasticsearch.cn/uploads/event/20211120/458c74ca3169260dbb2308dd06ef930a.png   name: default_flow filter:  basic_auth: valid_users: medcl: passwd http: schema: \u0026quot;http\u0026quot; #https or http host: \u0026quot;192.168.3.188:5602\u0026quot; router:   name: my_router default_flow: default_flow rules:  method:  GET POST pattern: \u0026quot;/_logout\u0026quot; flow: logout_flow   method:  GET pattern: \u0026quot;/plugins/kibanaReact/assets/illustration_integrations_lightmode.svg\u0026quot; flow: replace_logo_flow 效果如下 #       使用网关来访问 Kibana 就需要登陆了，如下：\n登陆之后，可以看到，Kibana 里面的资源也被替换掉了，如下：\n展望 #  通过极限网关，我们还可以挖掘更多玩法，比如可以替换 Kibana 里面的 Logo， 可以替换里面的 JS，可以替换里面的 CSS 样式，通过 JS 和 css 组合可以动态添加导航、页面、可视化等等。\n","subcategory":null,"summary":"","tags":null,"title":"为 Kibana 添加代理和基础安全","url":"/gateway/v1.29.7/zh/docs/tutorial/proxy_kibana/"},{"category":null,"content":"为 Elasticsearch 无缝添加代理和基础安全 #  如果你的 Elasticsearch 版本比较多或者比较旧，或者没有设置 TLS 和身份信息，那么任何人都有可能直接访问 Elasticsearch，而使用极限网关可以快速的进行修复。\n使用 Elasticsearch 过滤器来转发请求 #  首先定义一个 Elasticsearch 的资源，如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 然后可以使用如下的过滤器来转发请求到上面定义的 Elasticsearch 资源，名称为 prod：\n - elasticsearch: elasticsearch: prod 有关该过滤器的更多详情，请参考文档： elasticsearch filter\n添加一个简单的身份验证 #  我们进行添加一个基础的身份验证，来限制目标集群的访问\n - basic_auth: valid_users: medcl: passwd 开启 TLS #  如果设置了身份，但是没有设置 TLS 也是不行的，因为 HTTP 是明文传输协议，可以非常容易泄露密码，配置如下：\n - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 tls: enabled: true 通过地址 https://localhost:8000 就可以访问到 prod 的 Elasticsearch 集群。\n注意的是，这里监听的地址是 0.0.0.0，代表本机所有网卡上的 IP 都进行了监听， 为了安全起见，你可能需要修改为只监听本地地址或者指定的网卡 IP 地址。\n兼容 HTTP 访问 #  如果存在遗留的系统没有办法切换到新集群的，可以提供一个新的端口来进行 HTTP 的访问：\n - name: my_unsecure_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8001 tls: enabled: false 通过地址 http://localhost:8001 就可以访问到 prod 的 Elasticsearch 集群。\n完整配置如下 #  elasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 entry:\n name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 tls: enabled: true name: my_unsecure_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8001 tls: enabled: false  flow:\n name: default_flow filter:  basic_auth: valid_users: medcl: passwd elasticsearch: elasticsearch: prod router:   name: my_router default_flow: default_flow 效果如下 #   现在使用网关来访问 Elasticsearch 就需要登陆了，如下：\n","subcategory":null,"summary":"","tags":null,"title":"为 Elasticsearch 无缝添加代理和基础安全","url":"/gateway/v1.29.7/zh/docs/tutorial/proxy_elasticsearch/"},{"category":null,"content":"与 Prometheus 集成 #  极限网关支持将运行指标输出为 Prometheus 格式, 方便与 Prometheus 进行集成, 具体操作如下:\n统计信息接口 #  访问网关的 2900 接口,如下:\nhttp://localhost:2900/stats?format=prometheus ➜ ~ curl http://localhost:2900/stats\\?format\\=prometheus buffer_fasthttp_resbody_buffer_acquired{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 1 buffer_stats_acquired{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 7 buffer_stats_max_count{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 0 system_cpu{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 0 buffer_bulk_request_docs_acquired{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 1 buffer_fasthttp_resbody_buffer_inuse{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 0 stats_gateway_request_bytes{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 0 system_mem{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 31473664 ... 通过增加额外的参数 format=prometheus 即可返回 Prometheus 所需数据格式.\n配置 Prometheus 进行采集 #  修改配置文件: prometheus.yml\n# my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093\nLoad rules once and periodically evaluate them according to the global \u0026lsquo;evaluation_interval\u0026rsquo;. rule_files:\n- \u0026quot;first_rules.yml\u0026quot; - \u0026quot;second_rules.yml\u0026quot; A scrape configuration containing exactly one endpoint to scrape: Here it\u0026rsquo;s Prometheus itself. scrape_configs:\n job_name: \u0026quot;prometheus\u0026quot; scrape_interval: 5s metrics_path defaults to \u0026lsquo;/metrics\u0026rsquo; metrics_path: /stats params: format: [\u0026lsquo;prometheus\u0026rsquo;]\nscheme defaults to \u0026lsquo;http\u0026rsquo;. static_configs:\n targets: [\u0026quot;localhost:2900\u0026quot;] labels: group: \u0026lsquo;infini\u0026rsquo; 启动 Prometheus #     启动之后,可以看到指标正常收集.\n然后就可以持续检测网关的运行状态了.\n","subcategory":null,"summary":"","tags":null,"title":"与 Prometheus 集成","url":"/gateway/v1.29.7/zh/docs/tutorial/prometheus_integration/"},{"category":null,"content":"与 Elasticsearch-Hadoop 集成 #  Elasticsearch-Hadoop 默认会通过某个种子节点拿到后端的所有 Elasticsearch 节点，可能存在热点和请求分配不合理的情况， 为了提高后端 Elasticsearch 节点的资源利用率，可以通过极限网关来实现后端 Elasticsearch 节点访问的精准路由。\n写入加速 #  如果是通过 Elasticsearch-Hadoop 来进行数据导入，可以通过修改 Elasticsearch-Hadoop 程序的以下参数来访问极限网关来提升写入吞吐，如下：\n   名称 类型 说明     es.nodes string 设置访问网关的地址列表，如：localhost:8000,localhost:8001   es.nodes.discovery bool 设置为 false，不采用 sniff 模式，只访问配置的后端节点列表   es.nodes.wan.only bool 设置为 true，代理模式，强制走网关地址   es.batch.size.entries int 适当调大批次文档数，提升吞吐，如 5000   es.batch.size.bytes string 适当调大批次传输大小，提升吞吐，如 20mb   es.batch.write.refresh bool 设置为 false，避免主动刷新，提升吞吐    相关链接 #    Elasticsearch-Hadoop 配置参数文档  ","subcategory":null,"summary":"","tags":null,"title":"与 Elasticsearch-Hadoop 集成","url":"/gateway/v1.29.7/zh/docs/tutorial/es-hadoop_integration/"},{"category":null,"content":"性能测试 #  推荐使用 Elasticsearch 专属压测工具 Loadgen 来对网关进行性能压测。\nLoadgen 的特点：\n 性能强劲 轻量级无依赖 支持模板化参数随机 支持高并发 支持压测端均衡流量控制 支持服务端返回值校验   下载地址：https://release.infinilabs.com/loadgen/\n Loadgen #  Loadgen 使用非常简单，下载解压之后会得到三个文件，一个可执行程序、一个配置文件 loadgen.yml 以及用于运行测试的 loadgen.dsl，配置文件样例如下：\nenv: ES_USERNAME: elastic ES_PASSWORD: elastic ES_ENDPOINT: http://localhost:8000 测试文件样例如下：\n# runner: { # // total_rounds: 1 # no_warm: false, # // Whether to log all requests # log_requests: false, # // Whether to log all requests with the specified response status # log_status_codes: [0, 500], # assert_invalid: false, # assert_error: false, # }, # variables: [ # { # name: \u0026#34;ip\u0026#34;, # type: \u0026#34;file\u0026#34;, # path: \u0026#34;dict/ip.txt\u0026#34;, # // Replace special characters in the value # replace: { # \u0026#39;\u0026#34;\u0026#39;: \u0026#39;\\\\\u0026#34;\u0026#39;, # \u0026#39;\\\\\u0026#39;: \u0026#39;\\\\\\\\\u0026#39;, # }, # }, # { # name: \u0026#34;id\u0026#34;, # type: \u0026#34;sequence\u0026#34;, # }, # { # name: \u0026#34;id64\u0026#34;, # type: \u0026#34;sequence64\u0026#34;, # }, # { # name: \u0026#34;uuid\u0026#34;, # type: \u0026#34;uuid\u0026#34;, # }, # { # name: \u0026#34;now_local\u0026#34;, # type: \u0026#34;now_local\u0026#34;, # }, # { # name: \u0026#34;now_utc\u0026#34;, # type: \u0026#34;now_utc\u0026#34;, # }, # { # name: \u0026#34;now_utc_lite\u0026#34;, # type: \u0026#34;now_utc_lite\u0026#34;, # }, # { # name: \u0026#34;now_unix\u0026#34;, # type: \u0026#34;now_unix\u0026#34;, # }, # { # name: \u0026#34;now_with_format\u0026#34;, # type: \u0026#34;now_with_format\u0026#34;, # // https://programming.guide/go/format-parse-string-time-date-example.html # format: \u0026#34;2006-01-02T15:04:05-0700\u0026#34;, # }, # { # name: \u0026#34;suffix\u0026#34;, # type: \u0026#34;range\u0026#34;, # from: 10, # to: 1000, # }, # { # name: \u0026#34;bool\u0026#34;, # type: \u0026#34;range\u0026#34;, # from: 0, # to: 1, # }, # { # name: \u0026#34;list\u0026#34;, # type: \u0026#34;list\u0026#34;, # data: [\u0026#34;medcl\u0026#34;, \u0026#34;abc\u0026#34;, \u0026#34;efg\u0026#34;, \u0026#34;xyz\u0026#34;], # }, # { # name: \u0026#34;id_list\u0026#34;, # type: \u0026#34;random_array\u0026#34;, # variable_type: \u0026#34;number\u0026#34;, // number/string # variable_key: \u0026#34;suffix\u0026#34;, // variable key to get array items # square_bracket: false, # size: 10, // how many items for array # }, # { # name: \u0026#34;str_list\u0026#34;, # type: \u0026#34;random_array\u0026#34;, # variable_type: \u0026#34;number\u0026#34;, // number/string # variable_key: \u0026#34;suffix\u0026#34;, // variable key to get array items # square_bracket: true, # size: 10, // how many items for array # replace: { # // Use \u0026#39; instead of \u0026#34; for string quotes # \u0026#39;\u0026#34;\u0026#39;: \u0026#34;\u0026#39;\u0026#34;, # // Use {} instead of [] as array brackets # \u0026#34;[\u0026#34;: \u0026#34;{\u0026#34;, # \u0026#34;]\u0026#34;: \u0026#34;}\u0026#34;, # }, # }, # ], POST $[[env.ES_ENDPOINT]]/medcl/_search { \u0026quot;track_total_hits\u0026quot;: true, \u0026quot;size\u0026quot;: 0, \u0026quot;query\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;patent_id\u0026quot;: [ $[[id_list]] ] } } }\nrequest: { runtime_variables: {batch_no: \u0026quot;uuid\u0026quot;}, runtime_body_line_variables: {routing_no: \u0026quot;uuid\u0026quot;}, basic_auth: { username: \u0026quot;$[[env.ES_USERNAME]]\u0026quot;, password: \u0026quot;$[[env.ES_PASSWORD]]\u0026quot;, }, }, 运行模式设置 #\n 默认配置下，Loadgen 会以性能测试模式运行，在指定时间（-d）内重复执行 requests 里的所有请求。如果只需要检查一次测试结果，可以通过 runner.total_rounds 来设置 requests 的执行次数。\nHTTP 响应头处理 #  默认配置下，Loadgen 会自动格式化 HTTP 的响应头（user-agent: xxx -\u0026gt; User-Agent: xxx），如果需要精确判断服务器返回的响应头，可以通过 runner.disable_header_names_normalizing 来禁用这个行为。\n变量的使用 #  上面的配置中，variables 用来定义变量参数，根据 name 来设置变量标识，在构造请求的使用 $[[变量名]] 即可访问该变量的值，变量目前支持的类型有：\n   类型 说明 变量参数     file 文件型外部变量参数 path: 数据文件路径\ndata: 数据列表，会被附加到path文件内容后读取   list 自定义枚举变量参数 data: 字符数组类型的枚举数据列表   sequence 32 位自增数字类型的变量 from: 初始值\nto: 最大值   sequence64 64 位自增数字类型的变量 from: 初始值\nto: 最大值   range 数字范围类型的变量，支持参数 from 和 to 来限制范围 from: 初始值\nto: 最大值   random_array 生成一个随机数组，数据元素来自variable_key指定的变量 variable_key: 数据源变量\nsize: 输出数组的长度\nsquare_bracket: true/false，输出值是否需要[和]\nstring_bracket: 字符串，输出元素前后会附加指定的字符串   uuid UUID 字符类型的变量    now_local 当前时间、本地时区    now_utc 当前时间、UTC 时区。输出格式:2006-01-02 15:04:05.999999999 -0700 MST    now_utc_lite 当前时间、UTC 时区。输出格式:2006-01-02T15:04:05.000    now_unix 当前时间、Unix 时间戳    now_with_format 当前时间，支持自定义 format 参数来格式化时间字符串，如：2006-01-02T15:04:05-0700 format: 输出的时间格式 ( 示例)    变量使用示例 #  file 类型变量参数加载自外部文本文件，每行一个变量参数，访问该变量时每次随机取其中一个，变量里面的定义格式举例如下：\n# test/user.txt medcl elastic 附生成固定长度的随机字符串，如 1024 个字符每行：\nLC_CTYPE=C tr -dc A-Za-z0-9_\\!\\@\\#\\$\\%\\^\\\u0026amp;\\*\\(\\)-+= \u0026lt; /dev/random | head -c 1024 \u0026gt;\u0026gt; 1k.txt 环境变量 #  Loadgen 支持自动读取环境变量，环境变量可以在运行 Loadgen 时通过命令行传入，也可以在 loadgen.dsl 里指定默认的环境变量值，Loadgen 运行时会使用命令行传入的环境变量覆盖 loadgen.dsl 里的默认值。\n配置的环境变量可以通过 $[[env.环境变量]] 来使用：\n#// 配置环境变量默认值 # env: { # ES_USERNAME: \u0026#34;elastic\u0026#34;, # ES_PASSWORD: \u0026#34;elastic\u0026#34;, # ES_ENDPOINT: \u0026#34;http://localhost:8000\u0026#34;, # }, #// 使用运行时变量 GET $[[env.ES_ENDPOINT]]/medcl/_search {\u0026quot;query\u0026quot;: {\u0026quot;match\u0026quot;: {\u0026quot;name\u0026quot;: \u0026quot;$[[user]]\u0026quot;}}}\nrequest: { // 使用运行时变量 basic_auth: { username: \u0026quot;$[[env.ES_USERNAME]]\u0026quot;, password: \u0026quot;$[[env.ES_PASSWORD]]\u0026quot;, }, }, 请求的定义 #\n 配置节点 requests 用来设置 Loadgen 将依次执行的请求，支持固定参数的请求，也可支持模板变量参数化构造请求，以下是一个普通的查询请求：\nGET http://localhost:8000/medcl/_search?q=name:$[[user]] # request: { # username: elastic, # password: pass, # }, 上面的查询对 medcl 索引进行了查询，并对 name 字段执行一个查询，每次请求的值来自随机变量 user。\n模拟批量写入 #  使用 Loadgen 来模拟 bulk 批量写入也非常简单，在请求体里面配置一条索引操作，然后使用 body_repeat_times 参数来随机参数化复制若干条请求即可完成一批请求的准备，如下：\nPOST http://localhost:8000/_bulk {\u0026#34;index\u0026#34;: {\u0026#34;_index\u0026#34;: \u0026#34;medcl-y4\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;$[[uuid]]\u0026#34;}} {\u0026#34;id\u0026#34;: \u0026#34;$[[id]]\u0026#34;, \u0026#34;field1\u0026#34;: \u0026#34;$[[user]]\u0026#34;, \u0026#34;ip\u0026#34;: \u0026#34;$[[ip]]\u0026#34;, \u0026#34;now_local\u0026#34;: \u0026#34;$[[now_local]]\u0026#34;, \u0026#34;now_unix\u0026#34;: \u0026#34;$[[now_unix]]\u0026#34;} # request: { # basic_auth: { # username: \u0026#34;test\u0026#34;, # password: \u0026#34;testtest\u0026#34;, # }, # body_repeat_times: 1000, # }, 返回值判断 #  每个 requests 配置可以通过 assert 来设置是否需要检查返回值。assert 功能支持 INFINI Gateway 的大部分 条件判断功能。\n 请阅读 《借助 DSL 来简化 Loadgen 配置》来了解更多细节。\n GET http://localhost:8000/medcl/_search?q=name:$[[user]] # request: { # basic_auth: { # username: \u0026#34;test\u0026#34;, # password: \u0026#34;testtest\u0026#34;, # }, # }, # assert: { # _ctx.response.status: 201, # }, 请求返回值可以通过 _ctx 获取，_ctx 目前包含以下信息：\n   参数 说明     _ctx.response.status HTTP 返回状态码   _ctx.response.header HTTP 返回响应头   _ctx.response.body HTTP 返回响应体   _ctx.response.body_json 如果 HTTP 返回响应体是一个有效的 JSON 字符串，可以通过 body_json 来访问 JSON 内容字段   _ctx.elapsed 当前请求发送到返回消耗的时间（毫秒）    如果请求失败（请求地址无法访问等），Loadgen 无法获取 HTTP 请求返回值，Loadgen 会在输出日志里记录 Number of Errors。如果配置了 runner.assert_error 且存在请求失败的请求，Loadgen 会返回 exit(2) 错误码。\n如果返回值不符合判断条件，Loadgen 会停止执行当前轮次后续请求，并在输出日志里记录 Number of Invalid。如果配置了 runner.assert_invalid 且存在判断失败的请求，Loadgen 会返回 exit(1) 错误码。\n动态变量注册 #  每个 requests 配置可以通过 register 来动态添加运行时参数，一个常见的使用场景是根据前序请求的返回值来动态设置后序请求的参数。\n这个示例调用 $[[env.ES_ENDPOINT]]/test 接口获取索引的 UUID，并注册到 index_id 变量。后续的请求定义可以通过 $[[index_id]] 来获取这个值。\nGET $[[env.ES_ENDPOINT]]/test # register: [ # {index_id: \u0026#34;_ctx.response.body_json.test.settings.index.uuid\u0026#34;}, # ], # assert: (200, {}), 执行压测 #  执行 Loadgen 程序即可执行压测，如下:\n$ loadgen -d 30 -c 100 -compress -run loadgen.dsl __ ___ _ ___ ___ __ __ / / /___\\/_\\ / \\/ _ \\ /__\\/\\ \\ \\ / / // ///_\\\\ / /\\ / /_\\//_\\ / \\/ / / /__/ \\_// _ \\/ /_// /_\\\\//__/ /\\ / \\____|___/\\_/ \\_/___,\u0026#39;\\____/\\__/\\_\\ \\/ [LOADGEN] A http load generator and testing suit. [LOADGEN] 1.0.0_SNAPSHOT, 83f2cb9, Sun Jul 4 13:52:42 2021 +0800, medcl, support single item in dict files [07-19 16:15:00] [INF] [instance.go:24] workspace: data/loadgen/nodes/0 [07-19 16:15:00] [INF] [loader.go:312] warmup started [07-19 16:15:00] [INF] [app.go:306] loadgen now started. [07-19 16:15:00] [INF] [loader.go:316] [GET] http://localhost:8000/medcl/_search [07-19 16:15:00] [INF] [loader.go:317] status: 200,\u0026lt;nil\u0026gt;,{\u0026quot;took\u0026quot;:1,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:{\u0026quot;value\u0026quot;:0,\u0026quot;relation\u0026quot;:\u0026quot;eq\u0026quot;},\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}} [07-19 16:15:00] [INF] [loader.go:316] [GET] http://localhost:8000/medcl/_search?q=name:medcl [07-19 16:15:00] [INF] [loader.go:317] status: 200,\u0026lt;nil\u0026gt;,{\u0026quot;took\u0026quot;:1,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:{\u0026quot;value\u0026quot;:0,\u0026quot;relation\u0026quot;:\u0026quot;eq\u0026quot;},\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}} [07-19 16:15:01] [INF] [loader.go:316] [POST] http://localhost:8000/_bulk [07-19 16:15:01] [INF] [loader.go:317] status: 200,\u0026lt;nil\u0026gt;,{\u0026quot;took\u0026quot;:120,\u0026quot;errors\u0026quot;:false,\u0026quot;items\u0026quot;:[{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;medcl-y4\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;c3qj9123r0okahraiej0\u0026quot;,\u0026quot;_version\u0026quot;:1,\u0026quot;result\u0026quot;:\u0026quot;created\u0026quot;,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:2,\u0026quot;successful\u0026quot;:1,\u0026quot;failed\u0026quot;:0},\u0026quot;_seq_no\u0026quot;:5735852,\u0026quot;_primary_term\u0026quot;:3,\u0026quot;status\u0026quot;:201}}]} [07-19 16:15:01] [INF] [loader.go:325] warmup finished\n5253 requests in 32.756483336s, 524.61KB sent, 2.49MB received\n[Loadgen Client Metrics] Requests/sec:\t175.10 Request Traffic/sec:\t17.49KB Total Transfer/sec:\t102.34KB Avg Req Time:\t5.711022ms Fastest Request:\t440.448µs Slowest Request:\t3.624302658s Number of Errors:\t0 Number of Invalid:\t0 Status 200:\t5253\n[Estimated Server Metrics] Requests/sec:\t160.37 Transfer/sec:\t93.73KB Avg Req Time:\t623.576686ms Loadgen 在正式压测之前会将所有的请求执行一次来进行预热，如果出现错误会提示是否继续，预热的请求结果也会输出到终端，执行完成之后会输出执行的摘要信息。可以通过设置 runner.no_warm 来跳过这个检查阶段。\n 因为 Loadgen 最后的结果是所有请求全部执行完成之后的累计统计，可能存在不准的问题，建议通过打开 Kibana 的监控仪表板来实时查看 Elasticsearch 的各项运行指标。\n 命令行参数 #  Loadgen 会循环执行配置文件里面定义的请求，默认 Loadgen 只会运行 5s 就自动退出了，如果希望延长运行时间或者加大并发可以通过启动的时候设置参数来控制，通过查看帮助命令如下：\n$ loadgen -help Usage of loadgen: -c int Number of concurrent threads (default 1) -compress Compress requests with gzip -config string the location of config file (default \u0026#34;loadgen.yml\u0026#34;) -cpu int the number of CPUs to use (default -1) -d int Duration of tests in seconds (default 5) -debug run in debug mode, loadgen will quit on panic immediately with full stack trace -dial-timeout int Connection dial timeout in seconds, default 3s (default 3) -gateway-log string Log level of Gateway (default \u0026#34;debug\u0026#34;) -l int Limit total requests (default -1) -log string the log level, options: trace,debug,info,warn,error,off -mem int the max size of Memory to use, soft limit in megabyte (default -1) -plugin value load additional plugins -r int Max requests per second (fixed QPS) (default -1) -read-timeout int Connection read timeout in seconds, default 0s (use -timeout) -run string DSL config to run tests (default \u0026#34;loadgen.dsl\u0026#34;) -service string service management, options: install,uninstall,start,stop -timeout int Request timeout in seconds, default 60s (default 60) -v\tversion -write-timeout int Connection write timeout in seconds, default 0s (use -timeout) 限制客户端压力 #  使用 Loadgen 并设置命令行参数 -r 可以限制客户端发送的每秒请求数，从而评估固定压力下 Elasticsearch 的响应时间和负载情况，如下：\nloadgen -d 30 -c 100 -r 100  注意，在大量并发下，此客户端吞吐限制可能不完全准确。\n 限制请求的总条数 #  通过设置参数 -l 可以控制客户端发送的请求总数，从而制造固定的文档，修改配置如下：\n#// loadgen-gw.dsl POST http://localhost:8000/medcl-test/doc2/_bulk {\u0026#34;index\u0026#34;: {\u0026#34;_index\u0026#34;: \u0026#34;medcl-test\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;$[[uuid]]\u0026#34;}} {\u0026#34;id\u0026#34;: \u0026#34;$[[id]]\u0026#34;, \u0026#34;field1\u0026#34;: \u0026#34;$[[user]]\u0026#34;, \u0026#34;ip\u0026#34;: \u0026#34;$[[ip]]\u0026#34;} # request: { # basic_auth: { # username: \u0026#34;test\u0026#34;, # password: \u0026#34;testtest\u0026#34;, # }, # body_repeat_times: 1, # }, 每次请求只有一个文档，然后执行 Loadgen\nloadgen -run loadgen-gw.dsl -d 600 -c 100 -l 50000 执行完成之后，Elasticsearch 的索引 medcl-test 将增加 50000 条记录。\n使用自增 ID 来确保文档的顺序性 #  如果希望生成的文档编号自增有规律，方便进行对比，可以使用 sequence 类型的自增 ID 来作为主键，内容也不要用随机数，如下：\nPOST http://localhost:8000/medcl-test/doc2/_bulk {\u0026#34;index\u0026#34;: {\u0026#34;_index\u0026#34;: \u0026#34;medcl-test\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;$[[id]]\u0026#34;}} {\u0026#34;id\u0026#34;: \u0026#34;$[[id]]\u0026#34;} # request: { # basic_auth: { # username: \u0026#34;test\u0026#34;, # password: \u0026#34;testtest\u0026#34;, # }, # body_repeat_times: 1, # }, 上下文复用变量 #  在一个请求中，我们可能希望有相同的参数出现，比如 routing 参数用来控制分片的路由，同时我们又希望该参数也保存在文档的 JSON 里面， 可以使用 runtime_variables 来设置请求级别的变量，或者 runtime_body_line_variables 定义请求体级别的变量，如果请求体复制 N 份，每份的参数是不同的，举例如下：\n# variables: [ # {name: \u0026#34;id\u0026#34;, type: \u0026#34;sequence\u0026#34;}, # {name: \u0026#34;uuid\u0026#34;, type: \u0026#34;uuid\u0026#34;}, # {name: \u0026#34;now_local\u0026#34;, type: \u0026#34;now_local\u0026#34;}, # {name: \u0026#34;now_utc\u0026#34;, type: \u0026#34;now_utc\u0026#34;}, # {name: \u0026#34;now_unix\u0026#34;, type: \u0026#34;now_unix\u0026#34;}, # {name: \u0026#34;suffix\u0026#34;, type: \u0026#34;range\u0026#34;, from: 10, to 15}, # ], POST http://192.168.3.188:9206/_bulk {\u0026quot;create\u0026quot;: {\u0026quot;_index\u0026quot;: \u0026quot;test-$[[suffix]]\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;doc\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;$[[uuid]]\u0026quot;, \u0026quot;routing\u0026quot;: \u0026quot;$[[routing_no]]\u0026quot;}} {\u0026quot;id\u0026quot;: \u0026quot;$[[uuid]]\u0026quot;, \u0026quot;routing_no\u0026quot;: \u0026quot;$[[routing_no]]\u0026quot;, \u0026quot;batch_number\u0026quot;: \u0026quot;$[[batch_no]]\u0026quot;, \u0026quot;random_no\u0026quot;: \u0026quot;$[[suffix]]\u0026quot;, \u0026quot;ip\u0026quot;: \u0026quot;$[[ip]]\u0026quot;, \u0026quot;now_local\u0026quot;: \u0026quot;$[[now_local]]\u0026quot;, \u0026quot;now_unix\u0026quot;: \u0026quot;$[[now_unix]]\u0026quot;}\nrequest: { runtime_variables: { batch_no: \u0026quot;id\u0026quot;, }, runtime_body_line_variables: { routing_no: \u0026quot;uuid\u0026quot;, }, basic_auth: { username: \u0026quot;ingest\u0026quot;, password: \u0026quot;password\u0026quot;, }, body_repeat_times: 10, }, 我们定义了 batch_no　变量来代表一批文档里面的相同批次号，同时又定义了　routing_no　变量来代表每个文档级别的 routing 值。\n自定义 Header #  GET http://localhost:8000/test/_search # request: { # headers: [ # {Agent: \u0026#34;Loadgen-1\u0026#34;}, # ], # disable_header_names_normalizing: false, # }, 默认配置下，Loadgen 会自动格式化配置里的 HTTP 的请求头（user-agent: xxx -\u0026gt; User-Agent: xxx），如果需要精确设置 HTTP 请求头，可以通过设置 disable_header_names_normalizing: true 来禁用这个行为。\n运行测试套件 #  Loadgen 支持批量运行测试用例，不需要重复编写测试用例，通过切换套件配置来快速测试不同的环境配置：\n# loadgen.yml env: # Set up envrionments to run test suite LR_TEST_DIR: ./testing # The path to the test cases. # If you want to start gateway dynamically and automatically: LR_GATEWAY_CMD: ./bin/gateway # The path to the executable of INFINI Gateway LR_GATEWAY_HOST: 0.0.0.0:18000 # The binding host of the INFINI Gateway LR_GATEWAY_API_HOST: 0.0.0.0:19000 # The binding host of the INFINI Gateway API server # Set up other envrionments for the gateway and loadgen LR_ELASTICSEARCH_ENDPOINT: http://localhost:19201 CUSTOM_ENV: myenv tests: # The relative path of test cases under `LR_TEST_DIR` # # - gateway.yml: (Optional) the configuration to start the INFINI Gateway dynamically. # - loadgen.dsl: the configuration to run the loadgen tool. # # The environments set in `env` section will be passed to the INFINI Gateway and loadgen. - path: cases/gateway/echo/echo_with_context 环境变量配置 #  Loadgen 通过环境变量来动态配置 INFINI Gateway，环境变量在 env 里指定。以下环境变量是必选的：\n   变量名 说明     LR_TEST_DIR 测试用例所在目录    如果你需要 loadgen 根据配置动态启动 INFINI Gateway，需要设置以下环境变量：\n   变量名 说明     LR_GATEWAY_CMD INFINI Gateway 可执行文件的路径   LR_GATEWAY_HOST INFINI Gateway 绑定的主机名:端口   LR_GATEWAY_API_HOST INFINI Gateway API 绑定的主机名:端口    测试用例配置 #  测试用例在 tests 里配置，每个路径（path）指向一个测试用例的目录，每个测试用例需要配置一份 gateway.yml（可选）和 loadgen.dsl。配置文件可以使用 env 下配置的环境变量（$[[env.ENV_KEY]]）。\ngateway.yml 参考配置：\npath.data: data path.logs: log entry:\n name: my_es_entry enabled: true router: my_router max_concurrency: 200000 network: binding: $[[env.LR_GATEWAY_HOST]]  flow:\n name: hello_world filter:  echo: message: \u0026quot;hello world\u0026quot; router:   name: my_router default_flow: hello_world loadgen.dsl 参考配置：\n  # runner: { # total_rounds: 1, # no_warm: true, # log_requests: true, # assert_invalid: true, # assert_error: true, # }, GET http://$[[env.LR_GATEWAY_HOST]]/ # assert: { # _ctx.response: { # status: 200, # body: \u0026quot;hello world\u0026quot;, # }, # }, 测试套件运行 #\n 配置好测试 loadgen.yml 后，可以通过以下命令运行 Loadgen：\nloadgen -config loadgen.yml Loadgen 会运行配置指定的所有测试用例，并输出测试结果：\n$ loadgen -config loadgen.yml __ ___ _ ___ ___ __ __ / / /___\\/_\\ / \\/ _ \\ /__\\/\\ \\ \\ / / // ///_\\\\ / /\\ / /_\\//_\\ / \\/ / / /__/ \\_// _ \\/ /_// /_\\\\//__/ /\\ / \\____|___/\\_/ \\_/___,\u0026#39;\\____/\\__/\\_\\ \\/ [LOADGEN] A http load generator and testing suit. [LOADGEN] 1.0.0_SNAPSHOT, 83f2cb9, Sun Jul 4 13:52:42 2021 +0800, medcl, support single item in dict files [02-21 10:50:05] [INF] [app.go:192] initializing loadgen [02-21 10:50:05] [INF] [app.go:193] using config: /Users/kassian/Workspace/infini/src/infini.sh/testing/suites/dev.yml [02-21 10:50:05] [INF] [instance.go:78] workspace: /Users/kassian/Workspace/infini/src/infini.sh/testing/data/loadgen/nodes/cfpihf15k34iqhpd4d00 [02-21 10:50:05] [INF] [app.go:399] loadgen is up and running now. [2023-02-21 10:50:05][TEST][SUCCESS] [setup/loadgen/cases/dummy] duration: 105(ms)\n1 requests in 68.373875ms, 0.00bytes sent, 0.00bytes received\n[Loadgen Client Metrics] Requests/sec:\t0.20 Request Traffic/sec:\t0.00bytes Total Transfer/sec:\t0.00bytes Avg Req Time:\t5s Fastest Request:\t68.373875ms Slowest Request:\t68.373875ms Number of Errors:\t0 Number of Invalid:\t0 Status 200:\t1\n[Estimated Server Metrics] Requests/sec:\t14.63 Transfer/sec:\t0.00bytes Avg Req Time:\t68.373875ms\n[2023-02-21 10:50:06][TEST][FAILED] [setup/gateway/cases/echo/echo_with_context/] duration: 1274(ms) #0 request, GET http://$[[env.LR_GATEWAY_HOST]]/any/, assertion failed, skiping subsequent requests 1 requests in 1.255678s, 0.00bytes sent, 0.00bytes received\n[Loadgen Client Metrics] Requests/sec:\t0.20 Request Traffic/sec:\t0.00bytes Total Transfer/sec:\t0.00bytes Avg Req Time:\t5s Fastest Request:\t1.255678s Slowest Request:\t1.255678s Number of Errors:\t1 Number of Invalid:\t1 Status 0:\t1\n[Estimated Server Metrics] Requests/sec:\t0.80 Transfer/sec:\t0.00bytes Avg Req Time:\t1.255678s\n\n","subcategory":null,"summary":"","tags":null,"title":"性能测试","url":"/gateway/v1.29.7/zh/docs/getting-started/benchmark/"},{"category":null,"content":"请求上下文 #  什么是上下文 #  上下文是极限网关用来访问当前运行环境下相关信息的入口，如请求的来源和配置信息等等，使用关键字 _ctx 即可访问相应的字段，如：_ctx.request.uri 表示请求的 URL 地址。\n内置请求上下文 #  HTTP 请求内置的 _ctx 上下文对象主要包括如下：\n   名称 类型 说明     id uint64 请求的唯一 ID   tls bool 表示请求是否 TLS   remote_ip string 客户端来源 IP   remote_addr string 客户端来源地址，包含端口   local_ip string 网关本地 IP   local_addr string 网关本地地址，包含端口   elapsed int64 请求已执行时间（毫秒）   request.* object 描述请求信息   response.* object 描述响应信息    request #  request 对象包含以下属性：\n   名称 类型 说明     to_string string 文本格式的 HTTP 完整请求信息   host string 访问的目标主机名/域名   method string 请求类型   uri string 请求完整地址   path string 请求路径   query_args map Url 请求参数   username string 发起请求的用户名   password string 发起请求的密码信息   header map Header 参数   body string 请求体   body_json object JSON 请求体对象   body_length int 请求体长度    如果客户端提交的请求体数据类型是 JSON 格式，可以通过 body_json 来直接访问，举例如下：\ncurl -u tesla:password -XGET \u0026quot;http://localhost:8000/medcl/_search?pretty\u0026quot; -H 'Content-Type: application/json' -d' { \u0026quot;query\u0026quot;:{ \u0026quot;bool\u0026quot;:{ \u0026quot;must\u0026quot;:[{\u0026quot;match\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;A\u0026quot;}},{\u0026quot;match\u0026quot;:{\u0026quot;age\u0026quot;:18}}] } }, \u0026quot;size\u0026quot;:900, \u0026quot;aggs\u0026quot;: { \u0026quot;total_num\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;name1\u0026quot;, \u0026quot;size\u0026quot;: 1000000 } } } }' 在 JSON 里面通过 . 来标识路径，如果是数组则使用 [下标] 来访问指定的元素，比如可以使用一个 dump 过滤器来进行调试，如下：\n - name: cache_first filter: - dump: context: - _ctx.request.body_json.size - _ctx.request.body_json.aggs.total_num.terms.field - _ctx.request.body_json.query.bool.must.[1].match.age 输出结果如下：\n_ctx.request.body_json.size : 900 _ctx.request.body_json.aggs.total_num.terms.field : name1 _ctx.request.body_json.query.bool.must.[1].match.age : 18 response #  response 对象包含以下属性：\n   名称 类型 说明     to_string string 文本格式的 HTTP 完整响应信息   status int 请求状态码   header map Header 参数   content_type string 响应请求体类型   body string 响应体   body_json object JSON 请求体对象   body_length int 响应体长度    系统上下文 #  系统上下文对象 _sys.* 有如下属性：\n   名称 类型 说明     hostname string 网关所在服务器主机名   month_of_now int 当前时间的月份，范围 [1,12]   weekday_of_now int 当前时间的周几，范围 [0,6], 0 is Sunday   day_of_now int 当前时间的自然天值   hour_of_now int 当前时间的小时值，范围 [0,23]   minute_of_now int 当前时间的分钟值，范围 [0,59]   second_of_now int 当前时间的秒值，范围 [0,59]   unix_timestamp_of_now int 当前时间的 Unix 时间戳   unix_timestamp_milli_of_now int64 当前时间的 Unix 时间戳，毫秒精度    其它 #  _util.* 主要用于获取一些特殊的变量:\n   名称 类型 说明     generate_uuid string 生成一个随机 UUID   increment_id string 生成一个自增 ID，默认桶名 default, 支持自定义, e.g., _util.increment_id.mybucket    ","subcategory":null,"summary":"","tags":null,"title":"请求上下文","url":"/gateway/v1.29.7/zh/docs/references/context/"},{"category":null,"content":"Elasticsearch #  定义资源 #  极限网关支持多集群的访问，支持不同的版本，每个集群作为一个 Elasticsearch 后端资源，可以后续被极限网关的多个地方使用，以下面的这个例子为例：\nelasticsearch: - name: local enabled: true endpoint: https://127.0.0.1:9200 - name: dev enabled: true endpoint: https://192.168.3.98:9200 basic_auth: username: elastic password: pass - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true interval: 10s basic_auth: username: elastic password: pass 上面的例子定义了一个名为 local 的本地开发测试集群，和一个名为 dev 的开发集群。开发集群开启了身份验证，这里也定义了相应的用户名和密码。 最后还定义了一个名为 prod 的生产集群，并且通过参数 discovery 开启了集群的节点拓扑自动发现和更新。\n参数说明 #     名称 类型 说明     name string Elasticsearch 集群名称   project string 项目名称   location.provider string 集群提供商   location.region string 集群所在可用区   location.dc string 集群所在数据中心   location.rack string 集群所在机架   labels map 集群自定义标签   tags array 集群自定义标签   enabled bool 是否启用   endpoint string Elasticsearch 访问地址，如: http://localhost:9200   endpoints array Elasticsearch 访问地址列表，支持多个入口地址，用于冗余   schema string 协议类型，http 或者 https   host string Elasticsearch 主机，格式：localhost:9200，host 和 endpoint 任意选择一种配置方式即可   hosts array Elasticsearch 主机列表，支持多个入口地址，用于冗余   request_timeout int 请求超时时间，单位秒，默认 30   request_compress bool 是否开启 Gzip 压缩   basic_auth object 身份认证信息   basic_auth.username string 用户名   basic_auth.password string 密码   discovery object 集群发现设置   discovery.enabled bool 是否启用集群拓扑发现   discovery.refresh object 集群拓扑更新设置   discovery.refresh.enabled bool 是否启用集群拓扑自动更新   discovery.refresh.interval string 集群拓扑自动更新时间间隔   traffic_control object 集群按节点级别的总体流量控制   traffic_control.enabled bool 是否启用限速   traffic_control.max_bytes_per_node int 最大允许的每秒请求字节数   traffic_control.max_qps_per_node int 最大允许的每秒请求次数，不区分读写   traffic_control.max_connection_per_node int 最大允许的主机连接数   traffic_control.max_wait_time_in_ms int 如遇限速, 最大允许的等待时间,默认 10000   allow_access_when_master_not_found bool 当集群出现 master_not_discovered_exception 异常后，任然允许转发请求到该集群，默认为 false    ","subcategory":null,"summary":"","tags":null,"title":"Elasticsearch","url":"/gateway/v1.29.7/zh/docs/references/elasticsearch/"},{"category":null,"content":"处理流程 #  流程定义 #  每一个网关接收到的请求都会通过一系列的流程处理，最后才返回给客户端，流程的定义在极限网关里面叫做 flow，以下面的这个例子为例：\nflow: - name: hello_world filter: - echo: message: \u0026quot;hello gateway\\n\u0026quot; repeat: 1 - name: not_found filter: - echo: message: '404 not found\\n' repeat: 1 上面的例子定义了两个 flow hello_world 和 not_found， 每个 flow 都使用了一个名为 echo 的过滤器，用来输出一段字符串，每个 flow 下面可以定义一系列 filter，他们按照定义的顺序依次执行。\n语法说明 #  极限网关采用约定的格式来定义流程，并且支持灵活的条件参数来进行逻辑判断，具体的格式定义如下：\nflow: - name: \u0026lt;flow_name\u0026gt; filter: - \u0026lt;filter_name\u0026gt;: when: \u0026lt;condition\u0026gt; \u0026lt;parameters\u0026gt; - \u0026lt;filter_name\u0026gt;: when: \u0026lt;condition\u0026gt; \u0026lt;parameters\u0026gt; ... 上面的 filter_name 代表具体的某个过滤器名称，用来执行特定的任务，when 下面的 condition 用来定义特定的满足执行该任务的条件参数，不满足条件的情况下会跳过该过滤器任务的执行，parameters 里面设置的该过滤器相关的参数，如果多个参数依次换行即可。\n条件判断 #  极限网关的流程定义支持复杂的逻辑判断，可以让特定的过滤器只有在满足某种条件下才会执行，举例如下：\nfilter: - if: \u0026lt;condition\u0026gt; then: - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; ... else: - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; ... 参数说明 #     名称 类型 说明     then array 表示满足 condition 条件定义后才会执行的一系列过滤器定义   else array 不满足条件才会执行的一系列过滤器定义，可不设置    使用 if 可以对多个 filter 来进行条件判断进行逻辑选择，使用 when 来对单个过滤器进行判断是否执行。\n条件类型 #  在流程里面定义的各种 condition 条件可以使用当前 请求上下文 来判断是否满足特定条件，从而实现逻辑处理，支持布尔表达式（AND、NOT、OR）来进行组合，完整的条件类型如下：\n equals contains prefix suffix regexp range network exists in queue_has_lag consumer_has_lag cluster_available or and not  equals #  使用 equals 条件来判断字段的内容是否为指定的值，用于字符和数字类型的精确匹配。\n如下面的例子判断是否请求的方法是否为 GET 类型，_ctx 是访问请求上下文的特定关键字：\nequals: _ctx.request.method: GET contains #  使用 contains 条件来判断字段的内容是否包含特定的字符值，仅支持字符字段类型。\n如下面的例子为判断返回的请求体里面是否包含错误关键字：\ncontains: _ctx.response.body: \u0026quot;error\u0026quot; prefix #  使用 prefix 条件来判断字段的内容是否由特定的字符值开头，仅支持字符字段类型。\n如下面的例子为判断返回的请求路径为特定索引名称开头：\nprefix: _ctx.request.path: \u0026quot;/filebeat\u0026quot; suffix #  使用 suffix 条件来判断字段的内容是否由特定的字符值结尾，仅支持字符字段类型。\n如下面的例子为判断返回的请求是否为搜索请求：\nsuffix: _ctx.request.path: \u0026quot;/_search\u0026quot; regexp #  使用 regexp 条件可以用来判断某个字段的内容是否满足正则表达式的匹配规则，仅支持字符字段类型。\n如下面的例子判断请求的 uri 是否为查询请求：\nregexp: _ctx.request.uri: \u0026quot;.*/_search\u0026quot; range #  使用 range 条件用来判断字段的值是否满足特定的范围，支持 lt、lte、gt 和 gte 几种类型，仅支持数字字段类型。\n如下面判断状态码范围的例子：\nrange: _ctx.response.code: gte: 400 以及如下组合来判断响应字节大小范围的例子：\nrange: _ctx.request.body_length.gte: 100 _ctx.request.body_length.lt: 5000 network #  如果某个字段的值为 IP 字段类型，可以使用 network 条件可以判断该字段是否满足某个特定的网络范围，支持标准的 IPv4 和 IPv6，支持 CIDR 的表达方式，或者是以下范围别名：\n   名称 说明     loopback 匹配本地回环网络地址，范围：127.0.0.0/8 或者 ::1/128。   unicast 匹配 RFC 1122、RFC 4632 和 RFC 4291 中定义的全球单播地址，但 IPv4 广播地址 (255.255.255.255) 除外。包括私有地址范围。   multicast 匹配广播地址。   interface_local_multicast 匹配 IPv6 接口本地组播地址。   link_local_unicast 匹配链路本地单播地址。   link_local_multicast 匹配链路本地广播地址。   private 匹配 RFC 1918 (IPv4) 和 RFC 4193 (IPv6) 中定义的私有地址范围。   public 匹配除了本机、未指定、IPv4 广播、链路本地单播、链路本地多播、接口本地多播或私有地址以外的公网地址。   unspecified 匹配未指定的地址（IPv4 地址 0.0.0.0 或 IPv6 地址 :: ）。    如下面的例子匹配本机网络地址：\nnetwork: _ctx.request.client_ip: private 或者指定一个子网：\nnetwork: _ctx.request.client_ip: '192.168.3.0/24' 支持数组，任意满足即可：\nnetwork: _ctx.request.client_ip: ['192.168.3.0/24', '10.1.0.0/8', loopback] exists #  如果要判断某个字段是否存在，可以使用 exists，支持一个或者多个字符字段，如下：\nexists: ['_ctx.request.user'] in #  如果要判断某个字段是否存在指定数组的任意值，可以使用 in，支持单个字段的判断，仅支持字符和数值类型。\n如下判断返回状态码：\nin: _ctx.response.status: [ 403,404,200,201 ] queue_has_lag #  使用 queue_has_lag 可以来判断某个或多个本地磁盘队列是否存在堆积的情况，如下：\nqueue_has_lag: [ \u0026quot;prod\u0026quot;, \u0026quot;prod-500\u0026quot; ] 当队列类型为 FIFO 时，如果希望设置队列大于指定深度可以在队列的名称后面加上 \u0026gt;队列深度，如：\nqueue_has_lag: [ \u0026quot;prod\u0026gt;10\u0026quot;, \u0026quot;prod-500\u0026gt;10\u0026quot; ] 上面的例子表示，只有当队列深度超过 10 的情况下才满足条件。\nconsumer_has_lag #  使用 consumer_has_lag 可以来判断某个队列的消费者是否存在延迟堆积的情况，如下：\nconsumer_has_lag: queue: \u0026quot;primary-partial-success_bulk_requests\u0026quot; group: \u0026quot;my-group\u0026quot; name: \u0026quot;my-consumer-1\u0026quot; cluster_available #  使用 cluster_available 可以判断某个或多个 Elasticsearch 集群的服务可用性，如下：\ncluster_available: [\u0026quot;prod\u0026quot;] or #  使用 or 来组合多个任意可选条件，格式如下：\nor: - \u0026lt;condition1\u0026gt; - \u0026lt;condition2\u0026gt; - \u0026lt;condition3\u0026gt; ... 举例如下：\nor: - equals: _ctx.response.code: 304 - equals: _ctx.response.code: 404 and #  使用 and 来组合多个必要条件，格式如下：\nand: - \u0026lt;condition1\u0026gt; - \u0026lt;condition2\u0026gt; - \u0026lt;condition3\u0026gt; ... 举例如下：\nand: - equals: _ctx.response.code: 200 - equals: _ctx.status: OK 还可以对 and 和 or 条件进行灵活组合，如下：\nor: - \u0026lt;condition1\u0026gt; - and: - \u0026lt;condition2\u0026gt; - \u0026lt;condition3\u0026gt; not #  如果要对某个条件取反，使用 not 即可，格式如下：\nnot: \u0026lt;condition\u0026gt; 举例如下：\nnot: equals: _ctx.status: OK ","subcategory":null,"summary":"","tags":null,"title":"处理流程","url":"/gateway/v1.29.7/zh/docs/references/flow/"},{"category":null,"content":"系统调优 #  要保证极限网关运行在最佳状态，其所在服务器的操作系统也需要进行相应的调优，以 Linux 为例。\n系统参数 #  sudo tee /etc/security/limits.d/21-infini.conf \u0026lt;\u0026lt;-'EOF' * soft nofile 1048576 * hard nofile 1048576 * soft memlock unlimited * hard memlock unlimited root soft nofile 1048576 root hard nofile 1048576 root soft memlock unlimited root hard memlock unlimited EOF 内核调优 #  cat \u0026lt;\u0026lt; SETTINGS | sudo tee /etc/sysctl.d/70-infini.conf fs.file-max=10485760 fs.nr_open=10485760 vm.max_map_count=262144 net.core.somaxconn=65535 net.core.netdev_max_backlog=65535 net.core.rmem_default = 262144 net.core.wmem_default = 262144 net.core.rmem_max=4194304 net.core.wmem_max=4194304\nnet.ipv4.ip_forward = 1 net.ipv4.ip_nonlocal_bind=1 net.ipv4.ip_local_port_range = 1024 65535 net.ipv4.conf.default.accept_redirects = 0 net.ipv4.conf.default.rp_filter = 1 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.all.send_redirects = 0 net.ipv4.tcp_tw_reuse=1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_max_tw_buckets = 300000 net.ipv4.tcp_timestamps=1 net.ipv4.tcp_syncookies=1 net.ipv4.tcp_max_syn_backlog=65535 net.ipv4.tcp_synack_retries=0 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_time = 900 net.ipv4.tcp_keepalive_probes = 3 net.ipv4.tcp_fin_timeout = 10 net.ipv4.tcp_max_orphans = 131072 net.ipv4.tcp_rmem = 4096 4096 16777216 net.ipv4.tcp_wmem = 4096 4096 16777216 net.ipv4.tcp_mem = 786432 3145728 4194304 SETTINGS 执行下面的命令验证配置参数是否合法。\nsysctl -p 最后重启操作系统让配置生效。\n","subcategory":null,"summary":"","tags":null,"title":"系统调优","url":"/gateway/v1.29.7/zh/docs/getting-started/optimization/"},{"category":null,"content":"Easysearch 生产环境硬件配置推荐 #  在生产环境部署 Easysearch 时，高可用性 (HA) 是必须满足的核心要求。为实现完整的 HA 保障，您至少需要部署 3 个节点组成 Easysearch 集群。为获得最佳运维体验，建议配合使用 INFINI Console 和 Gateway，它们提供集群监控、告警和运维管理等完整功能，可大幅提升日常运维工作效率。\n   Product CPU MEM JVM Disk High Availability     Easysearch 16 64 31 SSD 3   Console 8 16 - \u0026gt;=50 GB, HDD or SSD -   Gateway 8 16 - \u0026gt;=50 GB, HDD or SSD 2    针对存储配置，建议优先选用本地磁盘部署，Easysearch 容量规划应基于实际数据规模及业务场景进行合理配置。对于低负载集群或测试环境，可适当降低硬件资源配置标准，但需确保满足基础性能需求。生产环境推荐采用 SSD 存储，测试环境可选用性能较低的磁盘类型。\n","subcategory":null,"summary":"","tags":null,"title":"硬件规格","url":"/gateway/v1.29.7/zh/docs/overview/hardware/"},{"category":null,"content":"Helm 部署 #  INFINI Gateway 支持 Helm 方式部署。\n添加仓库 #  Chart 仓库地址在这里 https://helm.infinilabs.com。\n使用下面的命令添加仓库：\nhelm repo add infinilabs https://helm.infinilabs.com 前提 #   K8S StorageClass  Chart 包中默认配置的 StorageClass 是 local-path，可参考 这里安装。\n如果想使用其他已安装的 StorageClass, 可以创建一个 YAML 文件（例如：values.yaml），添加如下配置：\nstorageClassName: \u0026lt;storageClassName\u0026gt; 创建的时候使用 -f 参数指定，替换默认值。\n 存储集群  Chart 包中配置的默认存储集群是 Easysearch，可参考 这里安装。\n注：Chart 包中配置的用户名和密码也是默认的，如有变动，可参照下面修改集群连接地址方法进行调整。 Gateway 也支持其他集群（如 Elasticsearch、Opensearch）连接，需手动创建一个 YAML 文件（例如：values.yaml），添加如下配置：\nenv: # 请求记录存储集群 loggingEsEndpoint: ****** # 请求记录存储集群用户 loggingEsUser: ****** # 请求记录存储集群用户密码 loggingEsPass: ****** # 业务存储集群 prodEsEndpoint: ****** # 业务存储集群用户 prodEsUser: ****** # 业务存储集群用户密码 prodEsPass: ****** 创建的时候使用 -f 参数指定，替换默认值。\n安装 #  helm install gateway infinilabs/gateway -n \u0026lt;namespace\u0026gt; 卸载 #  helm uninstall gateway -n \u0026lt;namespace\u0026gt; kubectl delete pvc gateway-data-gateway-0 -n \u0026lt;namespace\u0026gt; ","subcategory":null,"summary":"","tags":null,"title":"Helm 部署","url":"/gateway/v1.29.7/zh/docs/getting-started/helm/"},{"category":null,"content":"容器部署 #  极限网关支持容器方式部署。\n安装演示 #    start-at=\u0026quot;49\u0026quot; speed=\u0026quot;1\u0026quot; \u0026gt;\u0026lt;/asciinema-player\u0026gt;  下载镜像 #  极限网关的镜像发布在 Docker 的官方仓库，地址如下：\n https://hub.docker.com/r/infinilabs/gateway\n使用下面的命令即可获取最新的容器镜像：\ndocker pull infinilabs/gateway:1.29.6 验证镜像 #  将镜像下载到本地之后，可以看到极限网关的容器镜像非常小，只有不到 25MB，所以下载的速度应该是非常快的。\n✗ docker images |grep \u0026quot;gateway\u0026quot; |grep \u0026quot;1.29.6\u0026quot; REPOSITORY TAG IMAGE ID CREATED SIZE infinilabs/gateway 1.29.6 fdae74b64e1a 47 minutes ago 23.5MB 创建配置 #  现在需要创建一个配置文件 gateway.yml，来进行基本的配置，如下：\npath.data: data path.logs: log entry:\n name: my_es_entry enabled: true router: my_router max_concurrency: 200000 network: binding: 0.0.0.0:8000  flow:\n name: simple_flow filter:  elasticsearch: elasticsearch: dev    router:\n name: my_router default_flow: simple_flow  elasticsearch:\n name: dev enabled: true endpoint: http://localhost:9200 basic_auth: username: test password: testtest Note: 上面配置里面的 Elasticsearch 的相关配置，请改成实际的服务器连接地址和认证信息。\n  启动网关 #  使用如下命令启动极限网关容器：\ndocker run -p 2900:2900 -p 8000:8000 -v=`pwd`/gateway.yml:/gateway.yml infinilabs/gateway:1.29.6 验证网关 #  如果都运行正常的话，应该可以看到如下的信息：\n➜ /tmp docker run -p 2900:2900 -p 8000:8000 -v=`pwd`/gateway.yml:/gateway.yml infinilabs/gateway:1.29.6 ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.26.0, b61758c, Mon Dec 28 14:32:02 2024 +0800, medcl, no panic by default [12-30 05:26:41] [INF] [instance.go:24] workspace: data/gateway/nodes/0 [12-30 05:26:41] [INF] [runner.go:59] pipeline: primary started with 1 instances [12-30 05:26:41] [INF] [entry.go:257] entry [es_gateway] listen at: http://0.0.0.0:8000 [12-30 05:26:41] [INF] [app.go:247] gateway now started. [12-30 05:26:45] [INF] [reverseproxy.go:196] elasticsearch [prod] endpoints: [] =\u0026gt; [192.168.3.201:9200] 如果希望容器运行在后台，加上 -d 参数，如下：\ndocker run -d -p 2900:2900 -p 8000:8000 -v=`pwd`/gateway.yml:/gateway.yml infinilabs/gateway:1.29.6 使用命令行或者浏览器访问地址： http://localhost:8000/ 应该就能正常访问 Elasticsearch 了，如下：\n➜ /tmp curl -v http://localhost:8000/ * Trying ::1... * TCP_NODELAY set * Connected to localhost (::1) port 8000 (#0) \u0026gt; GET / HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.64.1 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Wed, 30 Dec 2020 05:12:39 GMT \u0026lt; Content-Type: application/json; charset=UTF-8 \u0026lt; Content-Length: 480 \u0026lt; UPSTREAM: 192.168.3.201:9200 \u0026lt; { \u0026quot;name\u0026quot; : \u0026quot;node1\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;pi\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;Z_HcN_6ESKWicV-eLsyU4g\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;6.4.2\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;tar\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;04711c2\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2018-09-26T13:34:09.098244Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;7.4.0\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;5.6.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;5.0.0\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } * Connection #0 to host localhost left intact * Closing connection 0 Docker Compose #\n 还可以使用 Docker Compose 来管理容器实例，新建一个 docker-compose.yml 文件如下：\nversion: \u0026quot;3.5\u0026quot; services: infini-gateway: image: infinilabs/gateway:1.29.6 ports: - 2900:2900 - 8000:8000 container_name: \u0026quot;infini-gateway\u0026quot; volumes: - ../gateway.yml:/gateway.yml\nvolumes: dist: 在配置文件所在目录，执行如下命令即可启动，如下：\n➜ docker-compose up Starting infini-gateway ... done Attaching to infini-gateway infini-gateway | ___ _ _____ __ __ __ _ infini-gateway | / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ infini-gateway | / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ infini-gateway | / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ infini-gateway | \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ infini-gateway | infini-gateway | [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. infini-gateway | [GATEWAY] 1.0.0_SNAPSHOT, b61758c, Mon Dec 28 14:32:02 2020 +0800, medcl, no panic by default infini-gateway | [12-30 13:24:16] [INF] [instance.go:24] workspace: data/gateway/nodes/0 infini-gateway | [12-30 13:24:16] [INF] [api.go:244] api server listen at: http://0.0.0.0:2900 infini-gateway | [12-30 13:24:16] [INF] [runner.go:59] pipeline: primary started with 1 instances infini-gateway | [12-30 13:24:16] [INF] [entry.go:257] entry [es_gateway] listen at: http://0.0.0.0:8000 infini-gateway | [12-30 13:24:16] [INF] [app.go:247] gateway now started.   ","subcategory":null,"summary":"","tags":null,"title":"容器部署","url":"/gateway/v1.29.7/zh/docs/getting-started/docker/"},{"category":null,"content":"配置 #  极限网关支持多种方式来修改配置。\n命令行参数 #  极限网关提供了命令行参数如下：\n✗ ./bin/gateway --help Usage of ./bin/gateway: -config string the location of config file, default: gateway.yml (default \u0026quot;gateway.yml\u0026quot;) -debug run in debug mode, gateway will quit with panic error -log string the log level,options:trace,debug,info,warn,error (default \u0026quot;info\u0026quot;) -v version 常用的说明如下：\n config，指定配置文件名，默认的配置文件名为当前执行命令所在目录的 gateway.yml，如果你的配置文件放置在其他地方，可以通过指定参数来进行选择。 daemon，将网关切换到后台执行，一般还需要结合 pidfile 来保存进程号，方便后续的进程操作。  配置文件 #  极限网关的大部分配置都可以通过 gateway.yml 来进行配置，配置修改完成之后，需要重启网关程序才能生效。\n定义入口 #  每一个网关都至少要对外暴露一个服务的入口，用来接收业务的操作请求，这个在极限网关里面叫做 entry，通过下面的参数即可定义：\nentry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 这里定义了一个名为 es_gateway 的服务入口，监听的地址是 0.0.0.0:8000，使用了一个名为 default 的路由来处理请求。\n定义路由 #  极限网关通过路由来判断流量的去向，一个典型的路由配置示例如下：\nrouter: - name: default default_flow: cache_first 这里定义了一个名为 default 的路由，也就是业务处理的主流程，请求转发、过滤、缓存等操作都在这里面进行。\n定义流程 #  一个请求流程定义了一系列请求处理的工作单元，是一个典型的管道式工作方式，一个典型的配置示例如下：\nflow: - name: cache_first filter: - get_cache: - elasticsearch: elasticsearch: prod - set_cache: 上面的配置定义了一个名为 cache_first 的处理流，使用了三个不同的 filter，分别是 get_cache、elasticsearch 和 set_cache，这些 filter 会依据配置的先后顺序依次执行，注意每个 filter 名称后面要带上一个 :。 各个 filter 的处理结果分别如下：\n get_cache，这个 filter 主要用来从缓存里面拿数据，如果之前发生过相同的请求，并且缓存还存在且有效的情况下，这个 filter 可以直接拿到缓存然后立即返回，不用继续往下处理； elasticsearch，这个 filter 主要用来将请求转发给后端的 Elasticsearch 集群，并且将 Elasticsearch 返回的响应内容继续往下传递； set_cache，这个 filter 会将执行结果缓存到本地内存，有一些参数限制，比如状态码，请求大小等，并设置一定的过期时间，以方便下次重复请求可以直接使用缓存，一般要和 get_cache 组合使用。  定义资源 #  这里的资源主要是指 Elasticsearch 后端服务器资源，极限网关支持多个 Elasticsearch 集群，可以实现将请求转发到多个不同集群，也可以支持请求的蓝绿发布、灰度切换等，定义一个 Elasticsearch 后端资源的方式示例如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true basic_auth: username: elastic password: pass 通过参数 endpoint 来设置 Elasticsearch 的访问地址，如果 Elasticsearch 开启了身份认证，可以通过 basic_auth 来指定用户名和密码信息，该用户需要有能够获取集群状态信息的权限。 通过参数 discover 可以开启自动的后端节点的自动发现，用于自动检测后端节点的情况，能够自动识别新增和离线的节点。\n通过这些基本的配置，我们就可以正常的代理 Elasticsearch 的请求了，关于每个组件更详细完整的参数，请参考 功能手册。\n","subcategory":null,"summary":"","tags":null,"title":"配置网关","url":"/gateway/v1.29.7/zh/docs/getting-started/configuration/"},{"category":null,"content":"主动合并索引分段 #  极限网关内置一个索引分段合并服务，可以主动对索引段文件进行合并，从而提升查询速度，段合并服务支持多个索引的依次顺序处理，并对合并任务状态进行了跟踪处理，避免大量段合并任务并行操作拖慢集群。\n如何开启 #  修改配置文件 gateway.yml，增加如下配置：\nforce_merge: enabled: false elasticsearch: dev min_num_segments: 20 max_num_segments: 1 indices: - index_name 各参数说明如下：\n   名称 类型 说明     enabled bool 是否启用该模块，默认是 false   elasticsearch string 操作的 Elasticsearch 集群 ID   min_num_segments int 超过多少分片的索引才会执行主动分片合并，以索引为单位的统计数目   max_num_segments int 将分片下的段文件合并之后，最多生成的段文件个数   indices array 需要进行分片合并的索引列表   discovery object 自动发现索引的相关设置   discovery.min_idle_time string 满足段合并条件的最小时间跨度，默认 1d   discovery.interval string 重新检测需要进行段合并的时间间隔   discovery.rules array 自动进行索引检测的索引匹配规则   discovery.rules.index_pattern string 要进行索引段文件合并的索引通配符   discovery.rules.timestamp_fields array 代表索引时间戳的字段列表    ","subcategory":null,"summary":"","tags":null,"title":"索引段合并","url":"/gateway/v1.29.7/zh/docs/references/modules/force_merge/"},{"category":null,"content":"索引差异对比 #  通过极限网关可以进行索引的文档差异对比，可以对同集群或者跨集群的两个不同的索引进行 diff 比较，对于使用应用双写、CCR 或者其他数据复制方案的场景，可以进行定期 diff 比较来确保数据是否真的一致。\n功能演示 #    start-at=\u0026quot;0\u0026quot; speed=\u0026quot;2\u0026quot; \u0026gt;\u0026lt;/asciinema-player\u0026gt;  如何配置 #  设置目标集群 #  修改配置文件 gateway.yml，设置两个集群资源 source 和 target，增加如下配置：\nelasticsearch: - name: source enabled: true endpoint: http://localhost:9200 basic_auth: username: test password: testtest - name: target enabled: true endpoint: http://localhost:9201 basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions username: test password: testtest 配置对比任务 #  增加一个服务管道配置，用来处理两个集群的索引文档拉取和对比，如下：\npipeline: - name: index_diff_service auto_start: true keep_running: true processor: - dag: parallel: - dump_hash: #dump es1's doc indices: \u0026quot;medcl-test\u0026quot; scroll_time: \u0026quot;10m\u0026quot; elasticsearch: \u0026quot;source\u0026quot; output_queue: \u0026quot;source_docs\u0026quot; batch_size: 10000 slice_size: 5 - dump_hash: #dump es2's doc indices: \u0026quot;medcl-test\u0026quot; scroll_time: \u0026quot;10m\u0026quot; batch_size: 10000 slice_size: 5 elasticsearch: \u0026quot;target\u0026quot; output_queue: \u0026quot;target_docs\u0026quot; end: - index_diff: diff_queue: \u0026quot;diff_result\u0026quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 上面的配置中，并行使用了 dump_hash 来拉取集群 source 的 medcl-a 索引和取集群 target 的 medcl-b 索引，并以文本结果的方式输出到终端。\n输出结果到 Elasticsearch #  如果 diff 结果比较多，可以选择保存到 Elasticsearch 集群，将上面的 index_diff 处理单元的参数 text_report 设置为 false，并增加如下配置：\npipeline: - name: diff_result_ingest auto_start: true keep_running: true processor: - json_indexing: index_name: \u0026quot;diff_result\u0026quot; elasticsearch: \u0026quot;source\u0026quot; input_queue: \u0026quot;diff_result\u0026quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 #in MB 最后导入 仪表板 到 Kibana 即可看到如下效果：\n","subcategory":null,"summary":"","tags":null,"title":"索引文档级别差异对比","url":"/gateway/v1.29.7/zh/docs/tutorial/index_diff/"},{"category":null,"content":"某保险集团业务的索引速度百倍提升之旅 #  业务挑战 #  某大型保险集团的保单查询业务，通过将数据库的常用字段放到 Elasticsearch 里面，用来提升查询性能，集群部署在 14 台物理机上面，每个物理机上面部署了 4 个 Elasticsearch 实例， 整个集群约有 90 多亿条数据，索引主分片存储接近 5 TB，每天的增量更新数据大概在 6 亿条左右，由于业务上的特殊性，全国的所有的业务数据都存放在一个索引里面， 造成了单个索引达到了 210 个分片，批量重建的任务采用 Spark 任务来并行执行，平均的写入速度在 2000~3000 条/s 左右，一次增量重建时间可能需要 2~3 天， 业务数据的更新延迟较大，长时间的重建也会影响正常时间段的业务访问。该技术团队也尝试过直接对 Elasticsearch 层面和 Spark 写入端多轮的测试和调优，发现对整体的写入速度没有太大的提升。\n应用场景 #  通过分析，集群性能应该没有问题，不过由于单个批次写入请求到达 Elasticsearch 之后需要重新再次按照主分片所在节点进行封装转发，而某保的业务索引分片个数太多，每个数据节点最终拿到的请求文档数太小， 客户端一次批次写入要拆分成几百次的小批次请求，并且由于短板原理，最慢的节点处理速度会拖慢整个批次写入的速度，从而造成集群总体吞吐的低下。\n通过评估极限网关，发现极限网关具备提前拆分请求和合并请求的能力，通过提前拆分合并请求到以节点为单位的本地队列，然后通过队列消费程序写入到目标 Elasticsearch 集群，将随机的批次请求转换为顺序的精准投放，如下图：\n极限网关在收到 Spark 请求之后先落地到本地磁盘确保数据不丢失，同时极限网关能够本地计算每个文档与目标数据节点的对应关系，新的数据写入架构如下图所示：\n通过采用极限网关来接收 Spark 的写入请求，整个集群的写入吞吐显著提升，Spark 写数据只花了不到 15 分钟即任务运行结束，网关从收到请求到写完 Elasticsearch 也只花了 20 分钟，服务器的 CPU 资源也充分利用起来了， 各个节点的 CPU 利用率均达到 100%。\n用户收益 #   索引速度提升 20000%\n 通过采用极限网关来作为中间加速层，该集团保单业务的索引重建速度由原来的 2-3 天都重建不完缩减到 20 分钟左右，每日增量 6 亿条数据的全部重建终于也可以快速完成， 索引写入 QPS 峰值也达到了 30 万+，大大缩短了索引重建周期，降低了数据延迟，增强了线上数据的一致性，确保了查询业务的正常使用。\n","subcategory":null,"summary":"","tags":null,"title":"某保险业务索引速度百倍提升","url":"/gateway/v1.29.7/zh/docs/user-cases/stories/indexing_speedup_for_big_index_rebuild/"},{"category":null,"content":"服务路由 #  极限网关通过路由来判断流量的去向，一个典型的路由配置示例如下：\nrouter: - name: my_router default_flow: default_flow tracing_flow: request_logging rules: - method: - PUT - POST pattern: - \u0026quot;/_bulk\u0026quot; - \u0026quot;/{index_name}/_bulk\u0026quot; flow: - bulk_process_flow 路由有几个非常重要的概念：\n flow：请求的处理流程，一个路由里面有三个地方定义 flow default_flow: 默认的处理流，也就是业务处理的主流程，请求转发、过滤、缓存等操作都在这里面进行 tracing_flow：用于追踪请求状态的流，不受 default_flow 的影响，用于记录请求日志、统计等 rules：根据匹配规则将请求分发到特定的处理流中去，支持请求的 Method、Path 的正则匹配  参数说明 #     名称 类型 说明     name string 路由名称   default_flow string 默认的请求的处理流程名称   tracing_flow string 用于追踪请求的处理流程名称   rules array 路由规则列表，按照数组的先后顺序依次应用   rules.method string 请求的 Method 类型，支持 GET、HEAD、POST、PUT、PATCH、DELETE、CONNECT、OPTIONS、TRACE， * 表示任意类型   rules.pattern string 请求的 URL Path 匹配规则，支持通配符，不允许有重叠匹配   rules.flow string 规则匹配之后执行的处理流程，支持多个 flow 组合，依次顺序执行   permitted_client_ip_list string array 指定一组允许访客 IP 的白名单   denied_client_ip_list string array 指定一组拒绝访客 IP 的黑名单    Pattern 语法 #     语法 说明 示例     {变量名} 带名称的变量 /{name}   {变量名:regexp} 通过正则来限制变量的匹配规则 /{name:[a-zA-Z]}   {变量名:*} 匹配之后的任意路径，只允许应用在 Pattern 末尾 /{any:*}    更多示例：\nPattern: /user/{user} /user/gordon match /user/you match /user/gordon/profile no match /user/ no match\nPattern with suffix: /user/{user}_admin\n/user/gordon_admin match /user/you_admin match /user/you no match /user/gordon/profile no match /user/gordon_admin/profile no match /user/ no match\nPattern: /src/{filepath:*}\n/src/ match /src/somefile.go match /src/subdir/somefile.go match 其他注意事项：\n Pattern 必须是 / 开头 任意匹配只能作为最后的一个规则  IP 访问控制 #  如果希望对访问网关服务的来源 IP 进行访问控制，可以通过 ip_access_control 配置节点来进行管理。\nrouter: - name: my_router default_flow: async_bulk ip_access_control: enabled: true 白名单 #  如果只希望某些特定指定 IP 的访客才能访问网关服务，可以在路由里面配置来实现访问准入，该请求会在链接建立的过程中直接拒绝。 如下例子，133.37.55.22 会被允许网关的服务访问，其余的 IP 都会拒绝。\nrouter: - name: my_router default_flow: async_bulk ip_access_control: enabled: true client_ip: permitted: - 133.37.55.22 黑名单 #  如果希望拒绝某些特定指定 IP 的访客来访问网关服务，可以在路由里面配置来实现访问拒绝，该请求会在链接建立的过程中直接拒绝。 如下例子，133.37.55.22 就会被阻止网关的服务访问。\nrouter: - name: my_router default_flow: async_bulk ip_access_control: enabled: true client_ip: denied: - 133.37.55.22 ","subcategory":null,"summary":"","tags":null,"title":"服务路由","url":"/gateway/v1.29.7/zh/docs/references/router/"},{"category":null,"content":"跨云集群的就近本地访问 #  业务需求 #  作业帮为了确保某个业务 Elasticsearch 集群的高可用，在百度云和华为云上面采取了双云部署，即将单个 Elasticsearch 集群跨云进行部署，并且要求业务请求优先访问本地云。\nElasticsearch 单集群双云实现 #  Elasticsearch 集群采用 Master 与 Data 节点分离的架构。 目前主力云放 2 个 Master，另外一个云放一个 Master。 主要考虑就是基础设施故障中，专线故障问题是大多数，某个云厂商整体挂的情况基本没有。 所以设置了主力云，当专线故障时，主力云的 Elasticsearch 是可以读写的，业务把流量切到主力云就行了。\n具体配置方式如下。\n首先，在 Master 节点上设置：\ncluster.routing.allocation.awareness.attributes: zone_id cluster.routing.allocation.awareness.force.zone_id.values: zone_baidu,zone_huawei 然后分别在百度云上数据节点上设置：\nnode.attr.zone_id: zone_baidu 和华为云上数据节点上设置：\nnode.attr.zone_id: zone_huawei 创建索引采用 1 副本，可以保证百度云与华为云上都有一份相同的数据。\n业务访问方式如下图：\n 百度云业务 -\u0026gt; 百度 lb -\u0026gt; INFINI Gateway (百度) -\u0026gt; Elasticsearch （百度云 data 节点） 华为云业务 -\u0026gt; 华为 lb -\u0026gt; INFINI Gateway (华为) -\u0026gt; Elasticsearch （华为云 data 节点）  极限网关配置 #  Elasticsearch 支持一个 Preference 参数来设置请求的优先访问，通过在两个云内部的极限网关分别设置各自请求默认的 Preference 参数，让各个云内部的请求优先发往本云内的数据节点，即可实现请求的就近访问。\n具体的百度云的 INFINI Gateway 配置如下（华为云大体相同，就不重复贴了）：\npath.data: data path.logs: log entry:\n name: es-test enabled: true router: default network: binding: 0.0.0.0:9200 reuse_port: true  router:\n name: default default_flow: es-test  flow:\n name: es-test filter:  set_request_query_args: args: - preference -\u0026gt; _prefer_nodes:node-id-of-data-baidu01,node-id-of-data-baidu02 #通过配置preference的_prefer_nodes为所有的百度data节点的node_id，来实现百度云的业务优先访问百度云的节点，最大程度避免跨云访问，对业务更友好。 when: contains: _ctx.request.path: /_search elasticsearch: elasticsearch: default refresh: enabled: true interval: 10s roles: include: - data #配置为data，请求只发送到data节点 tags: include: - zone_id: zone_baidu #只转发给百度云里面的节点    elasticsearch:\n name: default enabled: true endpoint: http://10.10.10.10:9200 allow_access_when_master_not_found: true discovery: enabled: true refresh: enabled: true interval: 10s basic_auth: username: elastic password: elastic 总结与收益 #   引入极限网关前故障回顾 #  百度云业务访问 Elasticsearch 集群，拉取每天的增量数据同步到 Hive 集群，其中有几个任务失败后，又重新同步。结果是部分数据从华为云的 Elasticsearch 节点拉取到百度云的 Hive 集群中，数据量巨大导致跨云专线流量监控告警。由于线上业务、MySQL、Redis、Elasticsearch 等使用同一根专线， 此次故障影响面较大。临时解决方案是业务修改语句加入 Preference 参数来实现业务只拉取本地云数据，减少对专线的占用。但是一方面业务改造及维护成本较高；另一方面作为 DBA 会担心业务改造有疏漏、新增业务遗忘 Preference 参数、以及后期调整成本较高，这始终是一个风险点。\n引入极限网关的收益 #  在原有架构上加入极限网关，可以在业务不修改代码的情况下做到优先访问本地云，提升访问速度的同时，最大限度减少对专线的压力。\n 作者：赵青，前网易 DBA，工作主要涉及 Oracle、MySQL、Redis、Elasticsearch、Tidb、OB 等组件的运维以及运维自动化、平台化、智能化等工作。现就职于作业帮。\n ","subcategory":null,"summary":"","tags":null,"title":"作业帮跨云集群的就近本地访问","url":"/gateway/v1.29.7/zh/docs/user-cases/stories/a_cross_region_cluster_access_locality/"},{"category":null,"content":"浮动 IP #  极限网关内置浮动 IP 功能，可以实现双机热备、故障转移的能力，极限网关天然提供四层网络流量的高可用，无需再额外考虑增加额外的软件和设备来保障因为停机、网络故障等造成的代理服务中断。\n注意:\n 该特性目前仅支持 Mac OS、Linux 操作系统。且需要网关以 root 身份运行。 此特性依赖目标系统的 ping 和 ifconfig 命令，请确保相关包默认已安装。 一组启用浮动 IP 的网关所在网卡地址应该在一个子网，且内网广播互通（网关实际 IP 和浮动 IP 要求只最后一位地址不一样，如：192.168.3.x）。   功能演示 #    Youtube  Bilibili  什么是浮动 IP #  极限网关基于浮动 IP 来实现高可用，浮动 IP 也叫虚拟 IP 或者动态 IP，我们知道每台服务器之间都必须要有 IP 才能进行通信，一台服务器的 IP 一般是固定的并且一般要提前分配好， 如果这台服务器因为故障挂了的话，这个 IP 以及上面部署的业务也就不能访问了。 而一个浮动 IP 通常是一个公开的、可以路由到的 IP 地址，并且不会自动分配给实体设备。项目管理者临时分配这个动态 IP 到一个或者多个实体设备。 这个实体设备有自动分配的静态 IP 用于内部网间设备的通讯。这个内部网使用私有地址，这些私有地址不能被路由到。通过浮动 IP 内网实体的服务才能被外网识别和访问。\n为什么需要浮动 IP #  在一个配置好浮动 IP 的典型切换场景是，当出现当前绑定浮动 IP 的机器出现故障的时候，浮动 IP 地址会飘到网络中的另一台设备。新设备无延迟的接替当掉的设备，并对外提供服务。 从而实现网络服务的高可用，对应业务的消费方来说，只需要指定浮动 IP 就可以了。 浮动 IP 非常有用，在某些特定的场景，比如客户端或者 SDK 只允许配置一个服务 IP 地址，所以这个 IP 一定要是高可用的，而极限网关正好解决了这个问题。 使用两个独立的极限网关服务器，最好部署在独立的物理服务器上，两台极限网关构成一组双机热备的状态，任意网关出现故障都能保障前端业务的正常访问。\n如何开启浮动 IP #  极限网关开启浮动 IP 的操作非常简单，通过修改配置文件 gateway.yml，增加如下配置：\nfloating_ip: enabled: true 极限网关能够自动检测网络网卡设备信息，自动绑定虚拟 IP 到内网通信的端口，非常智能，对于使用起来非常简单，默认监听的 IP 为当前机器所在网段的 *.*.*.234。 假设你当前机器所在的物理 IP 是 192.168.3.35，那么默认的浮动 IP 是 192.168.3.234，这个默认处理只是为了方便配置和快速启动，如果你需要使用自定义的浮动 IP 的话，也可以通过补充完整的参数来设置。\n相关参数设置 #  有关浮动 IP 更多完整的配置参数样例如下：\nfloating_ip: enabled: true ip: 192.168.3.234 netmask: 255.255.255.0 interface: en1 各参数说明如下：\n   名称 类型 说明     enabled bool 是否开启浮动 IP，默认是 false   interface string 网卡设备名称，如果不指定，会选择第一个监听非本机地址的设备名称，如果服务器有多张网卡，建议手动设置   ip string 监听的浮动 IP 地址，默认是当前物理网卡所在网段的 *.*.*.234地址，建议手动设置浮动 IP 地址，浮动 IP 地址不能和已有 IP 冲突   netmask string 浮动 IP 的子网掩码，默认是网卡所在子网掩码，或者 255.255.255.0   echo.port int 网关节点之间用于心跳检测的端口，请确定双向端口放行，默认 61111   echo.dial_timeout_in_ms int 网关节点之间心跳检测的拨号超时时间，默认 10000   echo.timeout_in_ms int 网关节点之间心跳检测的超时时间，默认 10000    ","subcategory":null,"summary":"","tags":null,"title":"浮动 IP","url":"/gateway/v1.29.7/zh/docs/references/modules/floating_ip/"},{"category":null,"content":"查询请求流量日志分析 #  极限网关能够跟踪记录经过网关的所有请求，可用来分析发送给 Elasticsearch 的请求情况，用于分析请求性能和了解业务运行情况。\n网关配置修改 #  极限网关安装包解压后，会有一个默认配置gateway.yml。只需对其进行简单的修改，就可实现流量分析目的。 通常我们只需修改此部分内容。后面的配置项会通过变量方式引用在此定义的内容。\nenv: LOGGING_ES_ENDPOINT: http://localhost:9200 LOGGING_ES_USER: elastic LOGGING_ES_PASS: password PROD_ES_ENDPOINT: http://localhost:9200 PROD_ES_USER: elastic PROD_ES_PASS: password GW_BINDING: \u0026quot;0.0.0.0:8000\u0026quot; API_BINDING: \u0026quot;0.0.0.0:2900\u0026quot; 上面的配置定义了两个 ES 集群和网关的监听信息。\n LOGGING_ES_ENDPOINT 定义日志集群的访问信息，所有请求记录将写入该集群。 PROD_ES_ENDPOINT 定义生产集群的访问信息，网关将代理此集群。 *_ES_USER 和*_ES_PASS 定义集群的认证信息。 API_BINDING 定义网关 API 服务监听的地址和端口。 GW_BINDING 定义网关代理服务监听的地址和端口。  在测试环境中，日志集群和生产集群可以是同一个。\n请确保将访问 ES 集群的请求发往网关代理服务监听的地址和端口。\n网关自带cache功能，如果需要启用该功能，请修改default_flow配置如下\n - name: default_flow filter: - get_cache: - elasticsearch: elasticsearch: prod max_connection_per_node: 1000 - set_cache: INFINI Easysearch #\n INFINI easysearch支持更高的 压缩率，更利于节省磁盘空间。\n如果logging集群使用的是INFINI easysearch，注意要安装index-management插件。\n点此查看插件安装文档\nbin/easysearch-plugin install index-management 插件安装完后重启生效。\n配置索引模板 #  如果你已经在使用 INFINI Console了，可跳过配置索引生命周期和索引模板，因为这些都已经自动建好了。\n在 logging 集群上执行下面的命令创建日志索引的模板。\n 请注意，您可能需要在执行之前修改上面的模板设置，例如增加 routing.allocation.require 参数，指定索引创建时存放的节点属性。\n   展开查看 Elasticsearch 的模板定义 ...  PUT _template/.infini_requests_logging-rollover { \u0026quot;order\u0026quot;: 100000, \u0026quot;index_patterns\u0026quot;: [ \u0026quot;.infini_requests_logging*\u0026quot; ], \u0026quot;settings\u0026quot;: { \u0026quot;index\u0026quot;: { \u0026quot;format\u0026quot;: \u0026quot;7\u0026quot;, \u0026quot;lifecycle\u0026quot;: { \u0026quot;name\u0026quot; : \u0026quot;ilm_.infini_metrics-30days-retention\u0026quot;, \u0026quot;rollover_alias\u0026quot; : \u0026quot;.infini_requests_logging\u0026quot; }, \u0026quot;codec\u0026quot;: \u0026quot;best_compression\u0026quot;, \u0026quot;number_of_shards\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;translog\u0026quot;: { \u0026quot;durability\u0026quot;: \u0026quot;async\u0026quot; } } }, \u0026quot;mappings\u0026quot;: { \u0026quot;dynamic_templates\u0026quot;: [ { \u0026quot;strings\u0026quot;: { \u0026quot;mapping\u0026quot;: { \u0026quot;ignore_above\u0026quot;: 256, \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot; } } ], \u0026quot;properties\u0026quot;: { \u0026quot;request\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;body\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } }, \u0026quot;response\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;body\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } }, \u0026quot;timestamp\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot; } } }, \u0026quot;aliases\u0026quot;: {} } DELETE .infini_requests_logging-00001 PUT .infini_requests_logging-00001 { \u0026quot;settings\u0026quot;: { \u0026quot;index.lifecycle.rollover_alias\u0026quot;:\u0026quot;.infini_requests_logging\u0026quot; , \u0026quot;refresh_interval\u0026quot;: \u0026quot;5s\u0026quot; }, \u0026quot;aliases\u0026quot;:{ \u0026quot;.infini_requests_logging\u0026quot;:{ \u0026quot;is_write_index\u0026quot;:true } } }\n  \n  展开查看 INFINI Easysearch 的模板定义 存储减50% ...  PUT _template/.infini_requests_logging-rollover { \u0026quot;order\u0026quot;: 100000, \u0026quot;index_patterns\u0026quot;: [ \u0026quot;.infini_requests_logging*\u0026quot; ], \u0026quot;settings\u0026quot;: { \u0026quot;index\u0026quot;: { \u0026quot;format\u0026quot;: \u0026quot;7\u0026quot;, \u0026quot;lifecycle\u0026quot;: { \u0026quot;name\u0026quot; : \u0026quot;ilm_.infini_metrics-30days-retention\u0026quot;, \u0026quot;rollover_alias\u0026quot; : \u0026quot;.infini_requests_logging\u0026quot; }, \u0026quot;codec\u0026quot;: \u0026quot;ZSTD\u0026quot;, \u0026quot;source_reuse\u0026quot;: true， \u0026quot;number_of_shards\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;translog\u0026quot;: { \u0026quot;durability\u0026quot;: \u0026quot;async\u0026quot; } } }, \u0026quot;mappings\u0026quot;: { \u0026quot;dynamic_templates\u0026quot;: [ { \u0026quot;strings\u0026quot;: { \u0026quot;mapping\u0026quot;: { \u0026quot;ignore_above\u0026quot;: 256, \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot; } } ], \u0026quot;properties\u0026quot;: { \u0026quot;request\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;body\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } }, \u0026quot;response\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;body\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } }, \u0026quot;timestamp\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot; } } }, \u0026quot;aliases\u0026quot;: {} } DELETE .infini_requests_logging-00001 PUT .infini_requests_logging-00001 { \u0026quot;settings\u0026quot;: { \u0026quot;index.lifecycle.rollover_alias\u0026quot;:\u0026quot;.infini_requests_logging\u0026quot; , \u0026quot;refresh_interval\u0026quot;: \u0026quot;5s\u0026quot; }, \u0026quot;aliases\u0026quot;:{ \u0026quot;.infini_requests_logging\u0026quot;:{ \u0026quot;is_write_index\u0026quot;:true } } }\n  \n 配置索引生命周期 #   展开查看索引生命周期的定义 ...  PUT _ilm/policy/ilm_.infini_metrics-30days-retention { \u0026quot;policy\u0026quot;: { \u0026quot;phases\u0026quot;: { \u0026quot;hot\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;0ms\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;rollover\u0026quot;: { \u0026quot;max_age\u0026quot;: \u0026quot;30d\u0026quot;, \u0026quot;max_size\u0026quot;: \u0026quot;50gb\u0026quot; }, \u0026quot;set_priority\u0026quot;: { \u0026quot;priority\u0026quot;: 100 } } }, \u0026quot;delete\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;30d\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;delete\u0026quot;: { } } } } } }     导入仪表板 #  下载面向 Kibana 7.9 的最新的仪表板 INFINI-Gateway-7.9.2-2021-01-15.ndjson.zip，在 dev 集群的 Kibana 里面导入，如下：\n启动网关 #  接下来，就可以启动网关，。\n➜ ./bin/gateway ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, a17be4c, Wed Feb 3 00:12:02 2021 +0800, medcl, add extra retry for bulk_indexing [02-03 13:51:35] [INF] [instance.go:24] workspace: data/gateway/nodes/0 [02-03 13:51:35] [INF] [api.go:255] api server listen at: http://0.0.0.0:2900 [02-03 13:51:35] [INF] [runner.go:59] pipeline: request_logging_index started with 1 instances [02-03 13:51:35] [INF] [entry.go:267] entry [es_gateway] listen at: http://0.0.0.0:8000 [02-03 13:51:35] [INF] [app.go:297] gateway now started. 修改应用配置 #\n 将之前指向 Elasticsearch 地址的应用（如 Beats、Logstash、Kibana 等）换成网关的地址。 假设网关 IP 是 192.168.3.98，则修改 Kibana 配置如下：\n# The Kibana server's name. This is used for display purposes. #server.name: \u0026quot;your-hostname\u0026quot; The URLs of the Elasticsearch instances to use for all your queries. elasticsearch.hosts: [\u0026quot;https://192.168.3.98:8000\u0026quot;] elasticsearch.customHeaders: { \u0026quot;app\u0026quot;: \u0026quot;kibana\u0026quot; }\nWhen this setting\u0026rsquo;s value is true Kibana uses the hostname specified in the server.host setting. When the value of this setting is false, Kibana uses the hostname of the host that connects to this Kibana instance. #elasticsearch.preserveHost: true\nKibana uses an index in Elasticsearch to store saved searches, visualizations and dashboards. Kibana creates a new index if the index doesn\u0026rsquo;t already exist. #kibana.index: \u0026quot;.kibana\u0026quot;\nThe default application to load. #kibana.defaultAppId: \u0026quot;home\u0026quot; 保存配置并重启 Kibana。\n查看效果 #  现在任何通过网关访问 Elasticsearch 的请求都能被监控到了。\n","subcategory":null,"summary":"","tags":null,"title":"查询请求流量日志分析","url":"/gateway/v1.29.7/zh/docs/tutorial/request-logging/"},{"category":null,"content":"服务入口 #  定义入口 #  每一个网关都至少要对外暴露一个服务的入口，用来接收业务的操作请求，这个在极限网关里面叫做 entry，通过下面的参数即可定义：\nentry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 reuse_port: true tls: enabled: false 通过参数 network.binding 可以指定服务监听的 IP 和地址，极限网关支持端口重用，也就是多个极限网关共享一个相同的 IP 和端口，这样可以充分利用服务器的资源， 也能做到不同网关进程的动态配置修改（通过开启多个进程，修改配置之后，依次重启各个进程）而不会中断客户端的正常请求。\n每个发送到 entry 的请求都会通过 router 来进行流量的路由处理，router 在单独的地方定义规则，以方便在不同的 entry 间复用，entry 只需要通过 router 参数指定要使用的 router 规则即可，这里定义的是 default。\nTLS 配置 #  极限网关支持无缝开启 TLS 传输加密，只需要将 tls.enabled 设置成 true，即可直接切换为 HTTPS 的通信模式，极限网关能自动生成自签证书。\n极限网关也支持自定义证书路径，配置方式如下：\nentry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 reuse_port: true tls: enabled: true cert_file: /etc/ssl.crt key_file: /etc/ssl.key skip_insecure_verify: false 多个服务 #  极限网关支持一个网关监听多个不同的服务入口，各个服务入口的监听地址、协议和路由都可以分别定义，用来满足不同的业务需求，配置示例如下：\nentry: - name: es_ingest enabled: true router: ingest_router network: binding: 0.0.0.0:8000 - name: es_search enabled: true router: search_router network: binding: 0.0.0.0:9000 上面的例子，定义了一个名为 es_ingest 的服务入口，监听的地址是 0.0.0.0:8000，所有请求都通过 ingest_router 来进行处理。 另外一个 es_search 服务，监听端口是 9000，使用 search_router 来进行请求处理，可以实现业务的读写分离。 另外，对于不同的后端 Elasticsearch 集群也可以定义不同的服务入口，通过网关来进行请求的代理转发。\nIPv6 支持 #  极限网关支持绑定到 IPv6 地址，示例如下：\nentry: - name: es_ingest enabled: true router: ingest_router network: # binding: \u0026quot;[ff80::4e2:7fb6:7db6:a839%en0]:8000\u0026quot; binding: \u0026quot;[::]:8000\u0026quot; 参数说明 #     名称 类型 说明     name string 服务入口名称   enabled bool 是否启用该入口   max_concurrency int 最大的并发连接数，默认 10000   router string 路由名称   network object 网络的相关配置   tls object TLS 安全传输相关配置   network.host string 服务监听的网络地址，如：192.168.3.10   network.port int 服务监听的端口地址，如：8000   network.binding string 服务监听的网络绑定地址，如：0.0.0.0:8000   network.publish string 服务监听的对外访问地址，如：192.168.3.10:8000   network.reuse_port bool 是否重用网络端口，用于多进程端口共享   network.skip_occupied_port bool 是否自动跳过已占用端口   tls.enabled bool 是否启用 TLS 安全传输   tls.cert_file string TLS 安全证书公钥路径   tls.key_file string TLS 安全证书秘钥路径   tls.skip_insecure_verify bool 是否忽略 TLS 的证书校验    ","subcategory":null,"summary":"","tags":null,"title":"服务入口","url":"/gateway/v1.29.7/zh/docs/references/entry/"},{"category":null,"content":"安装网关 #  极限网关支持主流的操作系统和平台，程序包很小，没有任何额外的外部依赖，安装起来应该是很快的 ：）\n安装演示 #    autoplay=\u0026quot;1\u0026quot; preload=\u0026quot;1\u0026quot; start-at=\u0026quot;0\u0026quot; speed=\u0026quot;2\u0026quot; \u0026gt;\u0026lt;/asciinema-player\u0026gt;  下载安装 #  自动安装\ncurl -sSL http://get.infini.cloud | bash -s -- -p gateway  通过以上脚本可自动下载相应平台的 gateway 最新版本并解压到/opt/gateway\n  脚本的可选参数如下：\n   -v [版本号]（默认采用最新版本号）\n   -d [安装目录]（默认安装到/opt/gateway）\n 手动安装\n根据您所在的操作系统和平台选择下面相应的下载地址：\n https://release.infinilabs.com/\n容器部署 #  极限网关也支持 Docker 容器方式部署。\n了解更多  验证安装 #  极限网关下载解压之后，我们可以执行这个命令来验证安装包是否有效，如下：\n✗ ./bin/gateway -v gateway 1.0.0_SNAPSHOT 2021-01-03 22:45:28 6a54bb2 如果能够正常看到上面的版本信息，说明网关程序本身一切正常。\n启动网关 #  以管理员身份直接运行网关程序即可启动极限网关了，如下：\n➜ sudo ./bin/gateway ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, 4daf6e9, Mon Jan 11 11:40:44 2021 +0800, medcl, add response_header_filter [01-11 16:43:31] [INF] [instance.go:24] workspace: data/gateway/nodes/0 [01-11 16:43:31] [INF] [api.go:255] api server listen at: http://0.0.0.0:2900 [01-11 16:43:31] [INF] [runner.go:59] pipeline: primary started with 1 instances [01-11 16:43:31] [INF] [runner.go:59] pipeline: nodes_index started with 1 instances [01-11 16:43:31] [INF] [entry.go:262] entry [es_gateway] listen at: https://0.0.0.0:8000 [01-11 16:43:32] [INF] [floating_ip.go:170] floating_ip listen at: 192.168.3.234, echo port: 61111 [01-11 16:43:32] [INF] [app.go:254] gateway now started. 看到上面的启动信息，说明网关已经成功运行了，并且监听了相应的端口。\n访问网关 #  使用浏览器或者其它客户端即可正常访问由网关代理的后端 Elasticsearch 服务了，如下：\n停止网关 #  如果需要停止网关，按 Ctrl+C 即可停止极限网关，如下：\n^C [GATEWAY] got signal: interrupt, start shutting down [01-11 16:44:41] [INF] [app.go:303] gateway now terminated. [GATEWAY] 1.0.0_SNAPSHOT, uptime: 1m10.550336s Thanks for using GATEWAY, have a good day! 系统服务 #\n 如果希望将极限网关以后台任务的方式运行，如下：\n➜ ./gateway -service install Success ➜ ./gateway -service start Success 卸载服务也很简单，如下：\n➜ ./gateway -service stop Success ➜ ./gateway -service uninstall Success 也支持自定义服务名称（如果有多个实例安装在一台机器上面）:\nsudo SERVICE_NAME=mygw ./bin/gateway -service install sudo SERVICE_NAME=mygw ./bin/gateway -service start sudo SERVICE_NAME=mygw ./bin/gateway -service stop sudo SERVICE_NAME=mygw ./bin/gateway -service uninstall 到这里极限网关就已经安装好了，下一步我们来看如何配置极限网关。\n配置网关  ","subcategory":null,"summary":"","tags":null,"title":"安装网关","url":"/gateway/v1.29.7/zh/docs/getting-started/install/"},{"category":null,"content":"","subcategory":null,"summary":"","tags":null,"title":"同类对比","url":"/gateway/v1.29.7/zh/docs/overview/-comparison/"},{"category":null,"content":"在线查询修复的实现 #  在某些情况下，您可能会碰到业务代码生成的 QueryDSL 存在不合理的情况，一般做法是需要修改业务代码并发布上线， 如果上线新版本需要很长的时间，比如没有到投产窗口，或者封网，又或者需要和其他的代码提交一起上线，往往意味着需要大量的测试， 而生产环境的故障要立马解决，客户不能等啊，怎么办？\n别着急，您可以使用极限网关来对查询进行动态修复。\n举个例子 #  比如下面的这个查询：\nGET _search { \u0026quot;size\u0026quot;: 1000000 , \u0026quot;explain\u0026quot;: true } 参数 size 设置的太大了，刚开始没有发现问题，随着数据越来越多，返回的数据太多势必会造成性能的急剧下降， 另外参数 explain 的开启也会造成不必要的性能开销，一般只在开发调试的时候才会用到这个功能。\n通过在网关里面增加一个 request_body_json_set 过滤器，可以动态替换指定请求体 JSON PATH 的值，上面的例子对应的配置如下：\nflow: - name: rewrite_query filter: - request_body_json_set: path: - explain -\u0026gt; false - size -\u0026gt; 10 - dump_request_body: - elasticsearch: elasticsearch: dev 通过重新设置 explain 和 size 参数，现在我们查询发给 Elasticsearch 前会被改写成如下格式：\n{ \u0026quot;size\u0026quot;: 10, \u0026quot;explain\u0026quot;: false } 成功修复线上问题。\n再举个例子 #  看下面的这个查询，编写代码的程序员写错了需要查询的字段名，应该是 name，但是写成了 name1，参数 size 也设置的特别大，如下：\nGET medcl/_search { \u0026quot;aggs\u0026quot;: { \u0026quot;total_num\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;name1\u0026quot;, \u0026quot;size\u0026quot;: 1000000 } } } } 然后，系统居然上线了，这不查询就出问题了嘛。 哎，别着急，在网关请求流程里面增加如下过滤器配置就行了：\nflow: - name: rewrite_query filter: - request_body_json_set: path: - aggs.total_num.terms.field -\u0026gt; \u0026quot;name\u0026quot; - aggs.total_num.terms.size -\u0026gt; 10 - size -\u0026gt; 0 - dump_request_body: - elasticsearch: elasticsearch: dev 上面的配置，我们通过请求体 JSON 的路径直接替换了其数据，并且新增了一个参数来不返回查询文档，因为只需要聚合结果就行了。\n再举个例子 #  用户的查询为：\n{ \u0026quot;query\u0026quot;:{ \u0026quot;bool\u0026quot;:{ \u0026quot;should\u0026quot;:[{\u0026quot;term\u0026quot;:{\u0026quot;isDel\u0026quot;:0}},{\u0026quot;match\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;order\u0026quot;}}] } } } 现在希望将其中的 term 查询换成等价的 range 查询，即如下：\n{ \u0026quot;query\u0026quot;:{ \u0026quot;bool\u0026quot;:{ \u0026quot;should\u0026quot;:[{ \u0026quot;range\u0026quot;: { \u0026quot;isDel\u0026quot;: {\u0026quot;gte\u0026quot;: 0,\u0026quot;lte\u0026quot;: 0 }}},{\u0026quot;match\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;order\u0026quot;}}] } } } 使用下面的配置即可：\nflow: - name: rewrite_query filter: - request_body_json_del: path: - query.bool.should.[0] - request_body_json_set: path: - query.bool.should.[1].range.isDel.gte -\u0026gt; 0 - query.bool.should.[1].range.isDel.lte -\u0026gt; 0 - dump_request_body: - elasticsearch: elasticsearch: dev 上面的配置，首先使用了一个 request_body_json_del 来删除查询 should 里面的第一个元素，也就是要替换掉的 Term 子查询， 然后现在只剩一个 Match 查询了，现在增加一个 Should 的子查询，新增下标的注意应该为 1，分别设置 Range 查询的各个属性即可。\n进一步完善 #  上面的例子都是直接替换查询，不过一般情况下，你可能还需要进行一个判断来决定是否进行替换，比如当 _ctx.request.body_json.query.bool.should.[0].term.isDel JSON 字段存在才进行替换，网关的 条件判断非常灵活如下，配置如下：\nflow: - name: cache_first filter: - if: and: - exists: ['_ctx.request.body_json.query.bool.should.[0].term.isDel'] then: - request_body_json_del: path: - query.bool.should.[0] - request_body_json_set: path: - query.bool.should.[1].range.isDel.gte -\u0026gt; 0 - query.bool.should.[1].range.isDel.lte -\u0026gt; 0 - dump_request_body: - elasticsearch: elasticsearch: dev 完美！\n","subcategory":null,"summary":"","tags":null,"title":"在线查询修复的实现","url":"/gateway/v1.29.7/zh/docs/tutorial/online_query_rewrite/"},{"category":null,"content":"Apache Log4j 漏洞处置 #  【CVE 地址】\n https://github.com/advisories/GHSA-jfh8-c2jp-5v3q\n【漏洞描述】\nApache Log4j 是一款非常流行的开源的用于 Java 运行环境的日志记录工具包，大量的 Java 框架包括 Elasticsearch 的最新版本都使用了该组件，故影响范围非常之大。\n近日, 随着 Apache Log4j 的远程代码执行最新漏洞细节被公开，攻击者可通过构造恶意请求利用该漏洞实现在目标服务器上执行任意代码。可导致服务器被黑客控制，从而进行页面篡改、数据窃取、挖矿、勒索等行为。建议使用该组件的用户第一时间启动应急响应进行修复。\n简单总结一下就是，在使用 Log4j 打印输出的日志中，如果发现日志内容中包含关键词 ${，那么这个里面包含的内容会当做变量来进行替换和执行，导致攻击者可以通过恶意构造日志内容来让 Java 进程来执行任意命令，达到攻击的效果。\n【漏洞等级】：非常紧急\n此次漏洞是用于 Log4j2 提供的 lookup 功能造成的，该功能允许开发者通过一些协议去读取相应环境中的配置。但在实现的过程中，并未对输入进行严格的判断，从而造成漏洞的发生。\n【影响范围】：Java 类产品：Apache Log4j 2.x \u0026lt; 2.15.0-rc2\n【攻击检测】\n可以通过检查日志中是否存在 jndi:ldap://、jndi:rmi 等字符来发现可能的攻击行为。\n处理办法 #  如果 Elasticsearch 不能修改配置、或者替换 Log4j 的 jar 包和重启集群的，可以使用极限网关来进行拦截或者参数替换甚至是直接阻断请求。 通过在网关层对发往 Elasticsearch 的请求统一进行参数检测，将包含的敏感关键词 ${ 进行替换或者直接拒绝， 可以防止带攻击的请求到达 Elasticsearch 服务端而被 Log4j 打印相关日志的时候执行恶意攻击命令，从而避免被攻击。\n参考配置 #  下载最新的 1.29.6 版本 https://release.infinilabs.com/gateway/stable/\n使用极限网关的 context_filter 过滤器，对请求上下文 _ctx.request.to_string 进行关键字检测，过滤掉恶意流量，从而阻断攻击。\npath.data: data path.logs: log entry:\n name: es_entrypoint enabled: true router: default max_concurrency: 20000 network: binding: 0.0.0.0:8000  router:\n name: default default_flow: main_flow  flow:\n name: main_flow filter:  context_filter: context: _ctx.request.to_string action: redirect_flow status: 403 flow: log4j_matched_flow must_not: # any match will be filtered regex: - ${.?} - \u0026quot;%24%7B.?%7D\u0026quot; #urlencode contain: - \u0026quot;jndi:\u0026quot; - \u0026quot;jndi:ldap:\u0026quot; - \u0026quot;jndi:rmi:\u0026quot; - \u0026quot;jndi%3A\u0026quot; #urlencode - \u0026quot;jndi%3Aldap%3A\u0026quot; #urlencode - \u0026quot;jndi%3Armi%3A\u0026quot; #urlencode elasticsearch: elasticsearch: es-server   name: log4j_matched_flow filter:  echo: message: \u0026lsquo;Apache Log4j 2, Boom!\u0026rsquo;    elasticsearch:\n name: es-server enabled: true endpoints:  http://localhost:9200 将测试命令 ${java:os} 使用 urlencode 转码为 %24%7Bjava%3Aos%7D\n    不走网关：\n~% curl 'http://localhost:9200/index1/_search?q=%24%7Bjava%3Aos%7D' {\u0026quot;error\u0026quot;:{\u0026quot;root_cause\u0026quot;:[{\u0026quot;type\u0026quot;:\u0026quot;index_not_found_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;no such index\u0026quot;,\u0026quot;resource.type\u0026quot;:\u0026quot;index_or_alias\u0026quot;,\u0026quot;resource.id\u0026quot;:\u0026quot;index1\u0026quot;,\u0026quot;index_uuid\u0026quot;:\u0026quot;_na_\u0026quot;,\u0026quot;index\u0026quot;:\u0026quot;index1\u0026quot;}],\u0026quot;type\u0026quot;:\u0026quot;index_not_found_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;no such index\u0026quot;,\u0026quot;resource.type\u0026quot;:\u0026quot;index_or_alias\u0026quot;,\u0026quot;resource.id\u0026quot;:\u0026quot;index1\u0026quot;,\u0026quot;index_uuid\u0026quot;:\u0026quot;_na_\u0026quot;,\u0026quot;index\u0026quot;:\u0026quot;index1\u0026quot;},\u0026quot;status\u0026quot;:404}% 查看 Elasticsearch 端日志为：\n[2021-12-11T01:49:50,303][DEBUG][r.suppressed ] path: /index1/_search, params: {q=Mac OS X 10.13.4 unknown, architecture: x86_64-64, index=index1} org.elasticsearch.index.IndexNotFoundException: no such index at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.infe(IndexNameExpressionResolver.java:678) ~[elasticsearch-5.6.15.jar:5.6.15] at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.innerResolve(IndexNameExpressionResolver.java:632) ~[elasticsearch-5.6.15.jar:5.6.15] at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:580) ~[elasticsearch-5.6.15.jar:5.6.15] 可以看到查询条件里面的 q=${java:os} 被执行了，变成了 q=Mac OS X 10.13.4 unknown, architecture: x86_64-64, index=index1\n走网关：\nmedcl@Medcl:~% curl 'http://localhost:8000/index1/_search?q=%24%7Bjava%3Aos%7D' Apache Log4j 2, Boom!% 可以看到请求被过滤到了。\n其他命令可以试试：\n#{java:vm} ~% curl 'http://localhost:9200/index/_search?q=%24%7Bjava%3Avm%7D' [2021-12-11T02:36:04,764][DEBUG][r.suppressed ] [Medcl-2.local] path: /index/_search, params: {q=OpenJDK 64-Bit Server VM (build 25.72-b15, mixed mode), index=index} ~% curl \u0026lsquo;http://localhost:8000/index/_search?q=%24%7Bjava%3Avm%7D\u0026rsquo; Apache Log4j 2, Boom!%\n#{jndi:rmi://localhost:1099/api} ~% curl \u0026lsquo;http://localhost:9200/index/_search?q=%24%7Bjndi%3Armi%3A%2F%2Flocalhost%3A1099%2Fapi%7D\u0026rsquo; 2021-12-11 03:35:06,493 elasticsearch[YOmFJsW][search][T#3] ERROR An exception occurred processing Appender console java.lang.SecurityException: attempt to add a Permission to a readonly Permissions object\n~% curl \u0026lsquo;http://localhost:8000/index/_search?q=%24%7Bjndi%3Armi%3A%2F%2Flocalhost%3A1099%2Fapi%7D\u0026rsquo; Apache Log4j 2, Boom!% \n使用极限网关处置类似安全事件的好处是，Elasticsearch 服务器不用做任何变动，尤其是大规模集群的场景，可以节省大量的工作，提升效率，非常灵活，缩短安全处置的时间，降低企业风险。\n ","subcategory":null,"summary":"","tags":null,"title":"Apache Log4j 漏洞处置","url":"/gateway/v1.29.7/zh/docs/tutorial/log4j2_filtering/"},{"category":null,"content":"echo #  描述 #  echo 过滤器是一个用于在返回结果里面输出指定字符信息的过滤器，常用于调试。\n功能演示 #    autoplay=\u0026quot;1\u0026quot; preload=\u0026quot;1\u0026quot; start-at=\u0026quot;0\u0026quot; speed=\u0026quot;2\u0026quot; \u0026gt;\u0026lt;/asciinema-player\u0026gt;  配置示例 #  一个简单的示例如下：\nflow: - name: hello_world filter: - echo: message: \u0026quot;hello infini\\n\u0026quot; echo 过滤器可以设置重复输出相同的字符的次数，示例如下：\n... - echo: message: \u0026quot;hello gateway\\n\u0026quot; repeat: 3 ... 参数说明 #     名称 类型 说明     message string 需要输出的字符内容，默认 .   messages []string 需要输出的字符内容列表   status int HTTP 状态码，默认 200   repeat int 重复次数   continue bool 是否继续后续流程，默认为 true   response bool 是否在 HTTP 返回输出，默认为 true   stdout bool 是否在终端也打印输出，默认为 false   logging bool 是否输出为日志数据，默认为 false   logging_level string 输出为日志数据的日志级别，默认为 info    ","subcategory":null,"summary":"","tags":null,"title":"echo","url":"/gateway/v1.29.7/zh/docs/references/filters/echo/"}]
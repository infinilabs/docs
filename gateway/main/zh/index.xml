<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>INFINI Gateway</title><link>/gateway/main/zh/</link><description>Recent content on INFINI Gateway</description><generator>Hugo -- gohugo.io</generator><atom:link href="/gateway/main/zh/index.xml" rel="self" type="application/rss+xml"/><item><title>echo</title><link>/gateway/main/zh/docs/references/filters/echo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/echo/</guid><description>echo # 描述 # echo 过滤器是一个用于在返回结果里面输出指定字符信息的过滤器，常用于调试。
功能演示 # 配置示例 # 一个简单的示例如下：
flow: - name: hello_world filter: - echo: message: &amp;quot;hello infini\n&amp;quot; echo 过滤器可以设置重复输出相同的字符的次数，示例如下：
... - echo: message: &amp;quot;hello gateway\n&amp;quot; repeat: 3 ... 参数说明 # 名称 类型 说明 message string 需要输出的字符内容，默认 . messages []string 需要输出的字符内容列表 status int HTTP 状态码，默认 200 repeat int 重复次数 continue bool 是否继续后续流程，默认为 true response bool 是否在 HTTP 返回输出，默认为 true stdout bool 是否在终端也打印输出，默认为 false logging bool 是否输出为日志数据，默认为 false logging_level string 输出为日志数据的日志级别，默认为 info</description></item><item><title>Apache Log4j 漏洞处置</title><link>/gateway/main/zh/docs/tutorial/log4j2_filtering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/log4j2_filtering/</guid><description>Apache Log4j 漏洞处置 # 【CVE 地址】
https://github.com/advisories/GHSA-jfh8-c2jp-5v3q
【漏洞描述】
Apache Log4j 是一款非常流行的开源的用于 Java 运行环境的日志记录工具包，大量的 Java 框架包括 Elasticsearch 的最新版本都使用了该组件，故影响范围非常之大。
近日, 随着 Apache Log4j 的远程代码执行最新漏洞细节被公开，攻击者可通过构造恶意请求利用该漏洞实现在目标服务器上执行任意代码。可导致服务器被黑客控制，从而进行页面篡改、数据窃取、挖矿、勒索等行为。建议使用该组件的用户第一时间启动应急响应进行修复。
简单总结一下就是，在使用 Log4j 打印输出的日志中，如果发现日志内容中包含关键词 ${，那么这个里面包含的内容会当做变量来进行替换和执行，导致攻击者可以通过恶意构造日志内容来让 Java 进程来执行任意命令，达到攻击的效果。
【漏洞等级】：非常紧急
此次漏洞是用于 Log4j2 提供的 lookup 功能造成的，该功能允许开发者通过一些协议去读取相应环境中的配置。但在实现的过程中，并未对输入进行严格的判断，从而造成漏洞的发生。
【影响范围】：Java 类产品：Apache Log4j 2.x &amp;lt; 2.15.0-rc2
【攻击检测】
可以通过检查日志中是否存在 jndi:ldap://、jndi:rmi 等字符来发现可能的攻击行为。
处理办法 # 如果 Elasticsearch 不能修改配置、或者替换 Log4j 的 jar 包和重启集群的，可以使用极限网关来进行拦截或者参数替换甚至是直接阻断请求。 通过在网关层对发往 Elasticsearch 的请求统一进行参数检测，将包含的敏感关键词 ${ 进行替换或者直接拒绝， 可以防止带攻击的请求到达 Elasticsearch 服务端而被 Log4j 打印相关日志的时候执行恶意攻击命令，从而避免被攻击。
参考配置 # 下载最新的 1.</description></item><item><title>在线查询修复的实现</title><link>/gateway/main/zh/docs/tutorial/online_query_rewrite/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/online_query_rewrite/</guid><description>在线查询修复的实现 # 在某些情况下，您可能会碰到业务代码生成的 QueryDSL 存在不合理的情况，一般做法是需要修改业务代码并发布上线， 如果上线新版本需要很长的时间，比如没有到投产窗口，或者封网，又或者需要和其他的代码提交一起上线，往往意味着需要大量的测试， 而生产环境的故障要立马解决，客户不能等啊，怎么办？
别着急，您可以使用极限网关来对查询进行动态修复。
举个例子 # 比如下面的这个查询：
GET _search { &amp;quot;size&amp;quot;: 1000000 , &amp;quot;explain&amp;quot;: true } 参数 size 设置的太大了，刚开始没有发现问题，随着数据越来越多，返回的数据太多势必会造成性能的急剧下降， 另外参数 explain 的开启也会造成不必要的性能开销，一般只在开发调试的时候才会用到这个功能。
通过在网关里面增加一个 request_body_json_set 过滤器，可以动态替换指定请求体 JSON PATH 的值，上面的例子对应的配置如下：
flow: - name: rewrite_query filter: - request_body_json_set: path: - explain -&amp;gt; false - size -&amp;gt; 10 - dump_request_body: - elasticsearch: elasticsearch: dev 通过重新设置 explain 和 size 参数，现在我们查询发给 Elasticsearch 前会被改写成如下格式：
{ &amp;quot;size&amp;quot;: 10, &amp;quot;explain&amp;quot;: false } 成功修复线上问题。</description></item><item><title>同类对比</title><link>/gateway/main/zh/docs/overview/-comparison/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/overview/-comparison/</guid><description/></item><item><title>安装网关</title><link>/gateway/main/zh/docs/getting-started/install/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/getting-started/install/</guid><description>安装网关 # 极限网关支持主流的操作系统和平台，程序包很小，没有任何额外的外部依赖，安装起来应该是很快的 ：）
安装演示 # 下载安装 # 自动安装
curl -sSL http://get.infini.cloud | bash -s -- -p gateway 通过以上脚本可自动下载相应平台的 gateway 最新版本并解压到/opt/gateway
脚本的可选参数如下：
 -v [版本号]（默认采用最新版本号）
 -d [安装目录]（默认安装到/opt/gateway）
手动安装
根据您所在的操作系统和平台选择下面相应的下载地址：
https://release.infinilabs.com/
容器部署 # 极限网关也支持 Docker 容器方式部署。
了解更多 验证安装 # 极限网关下载解压之后，我们可以执行这个命令来验证安装包是否有效，如下：
✗ ./bin/gateway -v gateway 1.0.0_SNAPSHOT 2021-01-03 22:45:28 6a54bb2 如果能够正常看到上面的版本信息，说明网关程序本身一切正常。
启动网关 # 以管理员身份直接运行网关程序即可启动极限网关了，如下：</description></item><item><title>服务入口</title><link>/gateway/main/zh/docs/references/entry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/entry/</guid><description>服务入口 # 定义入口 # 每一个网关都至少要对外暴露一个服务的入口，用来接收业务的操作请求，这个在极限网关里面叫做 entry，通过下面的参数即可定义：
entry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 reuse_port: true tls: enabled: false 通过参数 network.binding 可以指定服务监听的 IP 和地址，极限网关支持端口重用，也就是多个极限网关共享一个相同的 IP 和端口，这样可以充分利用服务器的资源， 也能做到不同网关进程的动态配置修改（通过开启多个进程，修改配置之后，依次重启各个进程）而不会中断客户端的正常请求。
每个发送到 entry 的请求都会通过 router 来进行流量的路由处理，router 在单独的地方定义规则，以方便在不同的 entry 间复用，entry 只需要通过 router 参数指定要使用的 router 规则即可，这里定义的是 default。
TLS 配置 # 极限网关支持无缝开启 TLS 传输加密，只需要将 tls.enabled 设置成 true，即可直接切换为 HTTPS 的通信模式，极限网关能自动生成自签证书。
极限网关也支持自定义证书路径，配置方式如下：
entry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 reuse_port: true tls: enabled: true cert_file: /etc/ssl.</description></item><item><title>查询请求流量日志分析</title><link>/gateway/main/zh/docs/tutorial/request-logging/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/request-logging/</guid><description>查询请求流量日志分析 # 极限网关能够跟踪记录经过网关的所有请求，可用来分析发送给 Elasticsearch 的请求情况，用于分析请求性能和了解业务运行情况。
网关配置修改 # 极限网关安装包解压后，会有一个默认配置gateway.yml。只需对其进行简单的修改，就可实现流量分析目的。 通常我们只需修改此部分内容。后面的配置项会通过变量方式引用在此定义的内容。
env: LOGGING_ES_ENDPOINT: http://localhost:9200 LOGGING_ES_USER: elastic LOGGING_ES_PASS: password PROD_ES_ENDPOINT: http://localhost:9200 PROD_ES_USER: elastic PROD_ES_PASS: password GW_BINDING: &amp;quot;0.0.0.0:8000&amp;quot; API_BINDING: &amp;quot;0.0.0.0:2900&amp;quot; 上面的配置定义了两个 ES 集群和网关的监听信息。
LOGGING_ES_ENDPOINT 定义日志集群的访问信息，所有请求记录将写入该集群。 PROD_ES_ENDPOINT 定义生产集群的访问信息，网关将代理此集群。 *_ES_USER 和*_ES_PASS 定义集群的认证信息。 API_BINDING 定义网关 API 服务监听的地址和端口。 GW_BINDING 定义网关代理服务监听的地址和端口。 在测试环境中，日志集群和生产集群可以是同一个。
请确保将访问 ES 集群的请求发往网关代理服务监听的地址和端口。
网关自带cache功能，如果需要启用该功能，请修改default_flow配置如下
- name: default_flow filter: - get_cache: - elasticsearch: elasticsearch: prod max_connection_per_node: 1000 - set_cache: INFINI Easysearch # INFINI easysearch支持更高的 压缩率，更利于节省磁盘空间。</description></item><item><title>浮动 IP</title><link>/gateway/main/zh/docs/references/modules/floating_ip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/modules/floating_ip/</guid><description>浮动 IP # 极限网关内置浮动 IP 功能，可以实现双机热备、故障转移的能力，极限网关天然提供四层网络流量的高可用，无需再额外考虑增加额外的软件和设备来保障因为停机、网络故障等造成的代理服务中断。
注意:
该特性目前仅支持 Mac OS、Linux 操作系统。且需要网关以 root 身份运行。 此特性依赖目标系统的 ping 和 ifconfig 命令，请确保相关包默认已安装。 一组启用浮动 IP 的网关所在网卡地址应该在一个子网，且内网广播互通（网关实际 IP 和浮动 IP 要求只最后一位地址不一样，如：192.168.3.x）。 功能演示 # Youtube Bilibili 什么是浮动 IP # 极限网关基于浮动 IP 来实现高可用，浮动 IP 也叫虚拟 IP 或者动态 IP，我们知道每台服务器之间都必须要有 IP 才能进行通信，一台服务器的 IP 一般是固定的并且一般要提前分配好， 如果这台服务器因为故障挂了的话，这个 IP 以及上面部署的业务也就不能访问了。 而一个浮动 IP 通常是一个公开的、可以路由到的 IP 地址，并且不会自动分配给实体设备。项目管理者临时分配这个动态 IP 到一个或者多个实体设备。 这个实体设备有自动分配的静态 IP 用于内部网间设备的通讯。这个内部网使用私有地址，这些私有地址不能被路由到。通过浮动 IP 内网实体的服务才能被外网识别和访问。
为什么需要浮动 IP # 在一个配置好浮动 IP 的典型切换场景是，当出现当前绑定浮动 IP 的机器出现故障的时候，浮动 IP 地址会飘到网络中的另一台设备。新设备无延迟的接替当掉的设备，并对外提供服务。 从而实现网络服务的高可用，对应业务的消费方来说，只需要指定浮动 IP 就可以了。 浮动 IP 非常有用，在某些特定的场景，比如客户端或者 SDK 只允许配置一个服务 IP 地址，所以这个 IP 一定要是高可用的，而极限网关正好解决了这个问题。 使用两个独立的极限网关服务器，最好部署在独立的物理服务器上，两台极限网关构成一组双机热备的状态，任意网关出现故障都能保障前端业务的正常访问。</description></item><item><title>作业帮跨云集群的就近本地访问</title><link>/gateway/main/zh/docs/user-cases/stories/a_cross_region_cluster_access_locality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/user-cases/stories/a_cross_region_cluster_access_locality/</guid><description>跨云集群的就近本地访问 # 业务需求 # 作业帮为了确保某个业务 Elasticsearch 集群的高可用，在百度云和华为云上面采取了双云部署，即将单个 Elasticsearch 集群跨云进行部署，并且要求业务请求优先访问本地云。
Elasticsearch 单集群双云实现 # Elasticsearch 集群采用 Master 与 Data 节点分离的架构。 目前主力云放 2 个 Master，另外一个云放一个 Master。 主要考虑就是基础设施故障中，专线故障问题是大多数，某个云厂商整体挂的情况基本没有。 所以设置了主力云，当专线故障时，主力云的 Elasticsearch 是可以读写的，业务把流量切到主力云就行了。
具体配置方式如下。
首先，在 Master 节点上设置：
cluster.routing.allocation.awareness.attributes: zone_id cluster.routing.allocation.awareness.force.zone_id.values: zone_baidu,zone_huawei 然后分别在百度云上数据节点上设置：
node.attr.zone_id: zone_baidu 和华为云上数据节点上设置：
node.attr.zone_id: zone_huawei 创建索引采用 1 副本，可以保证百度云与华为云上都有一份相同的数据。
业务访问方式如下图：
百度云业务 -&amp;gt; 百度 lb -&amp;gt; INFINI Gateway (百度) -&amp;gt; Elasticsearch （百度云 data 节点） 华为云业务 -&amp;gt; 华为 lb -&amp;gt; INFINI Gateway (华为) -&amp;gt; Elasticsearch （华为云 data 节点） 极限网关配置 # Elasticsearch 支持一个 Preference 参数来设置请求的优先访问，通过在两个云内部的极限网关分别设置各自请求默认的 Preference 参数，让各个云内部的请求优先发往本云内的数据节点，即可实现请求的就近访问。</description></item><item><title>服务路由</title><link>/gateway/main/zh/docs/references/router/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/router/</guid><description>服务路由 # 极限网关通过路由来判断流量的去向，一个典型的路由配置示例如下：
router: - name: my_router default_flow: default_flow tracing_flow: request_logging rules: - method: - PUT - POST pattern: - &amp;quot;/_bulk&amp;quot; - &amp;quot;/{index_name}/_bulk&amp;quot; flow: - bulk_process_flow 路由有几个非常重要的概念：
flow：请求的处理流程，一个路由里面有三个地方定义 flow default_flow: 默认的处理流，也就是业务处理的主流程，请求转发、过滤、缓存等操作都在这里面进行 tracing_flow：用于追踪请求状态的流，不受 default_flow 的影响，用于记录请求日志、统计等 rules：根据匹配规则将请求分发到特定的处理流中去，支持请求的 Method、Path 的正则匹配 参数说明 # 名称 类型 说明 name string 路由名称 default_flow string 默认的请求的处理流程名称 tracing_flow string 用于追踪请求的处理流程名称 rules array 路由规则列表，按照数组的先后顺序依次应用 rules.</description></item><item><title>某保险业务索引速度百倍提升</title><link>/gateway/main/zh/docs/user-cases/stories/indexing_speedup_for_big_index_rebuild/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/user-cases/stories/indexing_speedup_for_big_index_rebuild/</guid><description>某保险集团业务的索引速度百倍提升之旅 # 业务挑战 # 某大型保险集团的保单查询业务，通过将数据库的常用字段放到 Elasticsearch 里面，用来提升查询性能，集群部署在 14 台物理机上面，每个物理机上面部署了 4 个 Elasticsearch 实例， 整个集群约有 90 多亿条数据，索引主分片存储接近 5 TB，每天的增量更新数据大概在 6 亿条左右，由于业务上的特殊性，全国的所有的业务数据都存放在一个索引里面， 造成了单个索引达到了 210 个分片，批量重建的任务采用 Spark 任务来并行执行，平均的写入速度在 2000~3000 条/s 左右，一次增量重建时间可能需要 2~3 天， 业务数据的更新延迟较大，长时间的重建也会影响正常时间段的业务访问。该技术团队也尝试过直接对 Elasticsearch 层面和 Spark 写入端多轮的测试和调优，发现对整体的写入速度没有太大的提升。
应用场景 # 通过分析，集群性能应该没有问题，不过由于单个批次写入请求到达 Elasticsearch 之后需要重新再次按照主分片所在节点进行封装转发，而某保的业务索引分片个数太多，每个数据节点最终拿到的请求文档数太小， 客户端一次批次写入要拆分成几百次的小批次请求，并且由于短板原理，最慢的节点处理速度会拖慢整个批次写入的速度，从而造成集群总体吞吐的低下。
通过评估极限网关，发现极限网关具备提前拆分请求和合并请求的能力，通过提前拆分合并请求到以节点为单位的本地队列，然后通过队列消费程序写入到目标 Elasticsearch 集群，将随机的批次请求转换为顺序的精准投放，如下图：
极限网关在收到 Spark 请求之后先落地到本地磁盘确保数据不丢失，同时极限网关能够本地计算每个文档与目标数据节点的对应关系，新的数据写入架构如下图所示：
通过采用极限网关来接收 Spark 的写入请求，整个集群的写入吞吐显著提升，Spark 写数据只花了不到 15 分钟即任务运行结束，网关从收到请求到写完 Elasticsearch 也只花了 20 分钟，服务器的 CPU 资源也充分利用起来了， 各个节点的 CPU 利用率均达到 100%。
用户收益 # 索引速度提升 20000%</description></item><item><title>索引文档级别差异对比</title><link>/gateway/main/zh/docs/tutorial/index_diff/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/index_diff/</guid><description>索引差异对比 # 通过极限网关可以进行索引的文档差异对比，可以对同集群或者跨集群的两个不同的索引进行 diff 比较，对于使用应用双写、CCR 或者其他数据复制方案的场景，可以进行定期 diff 比较来确保数据是否真的一致。
功能演示 # 如何配置 # 设置目标集群 # 修改配置文件 gateway.yml，设置两个集群资源 source 和 target，增加如下配置：
elasticsearch: - name: source enabled: true endpoint: http://localhost:9200 basic_auth: username: test password: testtest - name: target enabled: true endpoint: http://localhost:9201 basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions username: test password: testtest 配置对比任务 # 增加一个服务管道配置，用来处理两个集群的索引文档拉取和对比，如下：
pipeline: - name: index_diff_service auto_start: true keep_running: true processor: - dag: parallel: - dump_hash: #dump es1's doc indices: &amp;quot;medcl-test&amp;quot; scroll_time: &amp;quot;10m&amp;quot; elasticsearch: &amp;quot;source&amp;quot; output_queue: &amp;quot;source_docs&amp;quot; batch_size: 10000 slice_size: 5 - dump_hash: #dump es2's doc indices: &amp;quot;medcl-test&amp;quot; scroll_time: &amp;quot;10m&amp;quot; batch_size: 10000 slice_size: 5 elasticsearch: &amp;quot;target&amp;quot; output_queue: &amp;quot;target_docs&amp;quot; end: - index_diff: diff_queue: &amp;quot;diff_result&amp;quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 上面的配置中，并行使用了 dump_hash 来拉取集群 source 的 medcl-a 索引和取集群 target 的 medcl-b 索引，并以文本结果的方式输出到终端。</description></item><item><title>索引段合并</title><link>/gateway/main/zh/docs/references/modules/force_merge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/modules/force_merge/</guid><description>主动合并索引分段 # 极限网关内置一个索引分段合并服务，可以主动对索引段文件进行合并，从而提升查询速度，段合并服务支持多个索引的依次顺序处理，并对合并任务状态进行了跟踪处理，避免大量段合并任务并行操作拖慢集群。
如何开启 # 修改配置文件 gateway.yml，增加如下配置：
force_merge: enabled: false elasticsearch: dev min_num_segments: 20 max_num_segments: 1 indices: - index_name 各参数说明如下：
名称 类型 说明 enabled bool 是否启用该模块，默认是 false elasticsearch string 操作的 Elasticsearch 集群 ID min_num_segments int 超过多少分片的索引才会执行主动分片合并，以索引为单位的统计数目 max_num_segments int 将分片下的段文件合并之后，最多生成的段文件个数 indices array 需要进行分片合并的索引列表 discovery object 自动发现索引的相关设置 discovery.min_idle_time string 满足段合并条件的最小时间跨度，默认 1d discovery.</description></item><item><title>配置网关</title><link>/gateway/main/zh/docs/getting-started/configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/getting-started/configuration/</guid><description>配置 # 极限网关支持多种方式来修改配置。
命令行参数 # 极限网关提供了命令行参数如下：
✗ ./bin/gateway --help Usage of ./bin/gateway: -config string the location of config file, default: gateway.yml (default &amp;quot;gateway.yml&amp;quot;) -debug run in debug mode, gateway will quit with panic error -log string the log level,options:trace,debug,info,warn,error (default &amp;quot;info&amp;quot;) -v version 常用的说明如下：
config，指定配置文件名，默认的配置文件名为当前执行命令所在目录的 gateway.yml，如果你的配置文件放置在其他地方，可以通过指定参数来进行选择。 daemon，将网关切换到后台执行，一般还需要结合 pidfile 来保存进程号，方便后续的进程操作。 配置文件 # 极限网关的大部分配置都可以通过 gateway.yml 来进行配置，配置修改完成之后，需要重启网关程序才能生效。
定义入口 # 每一个网关都至少要对外暴露一个服务的入口，用来接收业务的操作请求，这个在极限网关里面叫做 entry，通过下面的参数即可定义：
entry: - name: es_gateway enabled: true router: default network: binding: 0.</description></item><item><title>容器部署</title><link>/gateway/main/zh/docs/getting-started/docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/getting-started/docker/</guid><description>容器部署 # 极限网关支持容器方式部署。
安装演示 # 下载镜像 # 极限网关的镜像发布在 Docker 的官方仓库，地址如下：
https://hub.docker.com/r/infinilabs/gateway
使用下面的命令即可获取最新的容器镜像：
docker pull infinilabs/gateway:1.29.1-2000 验证镜像 # 将镜像下载到本地之后，可以看到极限网关的容器镜像非常小，只有不到 25MB，所以下载的速度应该是非常快的。
✗ docker images |grep &amp;quot;gateway&amp;quot; |grep &amp;quot;1.29.1-2000&amp;quot; REPOSITORY TAG IMAGE ID CREATED SIZE infinilabs/gateway 1.29.1-2000 fdae74b64e1a 47 minutes ago 23.5MB 创建配置 # 现在需要创建一个配置文件 gateway.yml，来进行基本的配置，如下：
path.data: data path.logs: log entry: - name: my_es_entry enabled: true router: my_router max_concurrency: 200000 network: binding: 0.0.0.0:8000 flow: - name: simple_flow filter: - elasticsearch: elasticsearch: dev router: - name: my_router default_flow: simple_flow elasticsearch: - name: dev enabled: true endpoint: http://localhost:9200 basic_auth: username: test password: testtest Note: 上面配置里面的 Elasticsearch 的相关配置，请改成实际的服务器连接地址和认证信息。</description></item><item><title>Helm 部署</title><link>/gateway/main/zh/docs/getting-started/helm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/getting-started/helm/</guid><description>Helm 部署 # INFINI Gateway 支持 Helm 方式部署。
添加仓库 # Chart 仓库地址在这里 https://helm.infinilabs.com。
使用下面的命令添加仓库：
helm repo add infinilabs https://helm.infinilabs.com 前提 # K8S StorageClass Chart 包中默认配置的 StorageClass 是 local-path，可参考 这里安装。
如果想使用其他已安装的 StorageClass, 可以创建一个 YAML 文件（例如：values.yaml），添加如下配置：
storageClassName: &amp;lt;storageClassName&amp;gt; 创建的时候使用 -f 参数指定，替换默认值。
存储集群 Chart 包中配置的默认存储集群是 Easysearch，可参考 这里安装。
注：Chart 包中配置的用户名和密码也是默认的，如有变动，可参照下面修改集群连接地址方法进行调整。 Gateway 也支持其他集群（如 Elasticsearch、Opensearch）连接，需手动创建一个 YAML 文件（例如：values.yaml），添加如下配置：
env: # 请求记录存储集群 loggingEsEndpoint: ****** # 请求记录存储集群用户 loggingEsUser: ****** # 请求记录存储集群用户密码 loggingEsPass: ****** # 业务存储集群 prodEsEndpoint: ****** # 业务存储集群用户 prodEsUser: ****** # 业务存储集群用户密码 prodEsPass: ****** 创建的时候使用 -f 参数指定，替换默认值。</description></item><item><title>硬件规格</title><link>/gateway/main/zh/docs/overview/hardware/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/overview/hardware/</guid><description/></item><item><title>系统调优</title><link>/gateway/main/zh/docs/getting-started/optimization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/getting-started/optimization/</guid><description>系统调优 # 要保证极限网关运行在最佳状态，其所在服务器的操作系统也需要进行相应的调优，以 Linux 为例。
系统参数 # sudo tee /etc/security/limits.d/21-infini.conf &amp;lt;&amp;lt;-'EOF' * soft nofile 1048576 * hard nofile 1048576 * soft memlock unlimited * hard memlock unlimited root soft nofile 1048576 root hard nofile 1048576 root soft memlock unlimited root hard memlock unlimited EOF 内核调优 # cat &amp;lt;&amp;lt; SETTINGS | sudo tee /etc/sysctl.d/70-infini.conf fs.file-max=10485760 fs.nr_open=10485760 vm.max_map_count=262144 net.core.somaxconn=65535 net.core.netdev_max_backlog=65535 net.core.rmem_default = 262144 net.core.wmem_default = 262144 net.core.rmem_max=4194304 net.core.wmem_max=4194304 net.ipv4.ip_forward = 1 net.</description></item><item><title>处理流程</title><link>/gateway/main/zh/docs/references/flow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/flow/</guid><description>处理流程 # 流程定义 # 每一个网关接收到的请求都会通过一系列的流程处理，最后才返回给客户端，流程的定义在极限网关里面叫做 flow，以下面的这个例子为例：
flow: - name: hello_world filter: - echo: message: &amp;quot;hello gateway\n&amp;quot; repeat: 1 - name: not_found filter: - echo: message: '404 not found\n' repeat: 1 上面的例子定义了两个 flow hello_world 和 not_found， 每个 flow 都使用了一个名为 echo 的过滤器，用来输出一段字符串，每个 flow 下面可以定义一系列 filter，他们按照定义的顺序依次执行。
语法说明 # 极限网关采用约定的格式来定义流程，并且支持灵活的条件参数来进行逻辑判断，具体的格式定义如下：
flow: - name: &amp;lt;flow_name&amp;gt; filter: - &amp;lt;filter_name&amp;gt;: when: &amp;lt;condition&amp;gt; &amp;lt;parameters&amp;gt; - &amp;lt;filter_name&amp;gt;: when: &amp;lt;condition&amp;gt; &amp;lt;parameters&amp;gt; ... 上面的 filter_name 代表具体的某个过滤器名称，用来执行特定的任务，when 下面的 condition 用来定义特定的满足执行该任务的条件参数，不满足条件的情况下会跳过该过滤器任务的执行，parameters 里面设置的该过滤器相关的参数，如果多个参数依次换行即可。</description></item><item><title>Elasticsearch</title><link>/gateway/main/zh/docs/references/elasticsearch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/elasticsearch/</guid><description>Elasticsearch # 定义资源 # 极限网关支持多集群的访问，支持不同的版本，每个集群作为一个 Elasticsearch 后端资源，可以后续被极限网关的多个地方使用，以下面的这个例子为例：
elasticsearch: - name: local enabled: true endpoint: https://127.0.0.1:9200 - name: dev enabled: true endpoint: https://192.168.3.98:9200 basic_auth: username: elastic password: pass - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true interval: 10s basic_auth: username: elastic password: pass 上面的例子定义了一个名为 local 的本地开发测试集群，和一个名为 dev 的开发集群。开发集群开启了身份验证，这里也定义了相应的用户名和密码。 最后还定义了一个名为 prod 的生产集群，并且通过参数 discovery 开启了集群的节点拓扑自动发现和更新。
参数说明 # 名称 类型 说明 name string Elasticsearch 集群名称 project string 项目名称 location.</description></item><item><title>请求上下文</title><link>/gateway/main/zh/docs/references/context/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/context/</guid><description>请求上下文 # 什么是上下文 # 上下文是极限网关用来访问当前运行环境下相关信息的入口，如请求的来源和配置信息等等，使用关键字 _ctx 即可访问相应的字段，如：_ctx.request.uri 表示请求的 URL 地址。
内置请求上下文 # HTTP 请求内置的 _ctx 上下文对象主要包括如下：
名称 类型 说明 id uint64 请求的唯一 ID tls bool 表示请求是否 TLS remote_ip string 客户端来源 IP remote_addr string 客户端来源地址，包含端口 local_ip string 网关本地 IP local_addr string 网关本地地址，包含端口 elapsed int64 请求已执行时间（毫秒） request.* object 描述请求信息 response.</description></item><item><title>性能测试</title><link>/gateway/main/zh/docs/getting-started/benchmark/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/getting-started/benchmark/</guid><description>性能测试 # 推荐使用 Elasticsearch 专属压测工具 Loadgen 来对网关进行性能压测。
Loadgen 的特点：
性能强劲 轻量级无依赖 支持模板化参数随机 支持高并发 支持压测端均衡流量控制 支持服务端返回值校验 下载地址：https://release.infinilabs.com/loadgen/
Loadgen # Loadgen 使用非常简单，下载解压之后会得到三个文件，一个可执行程序、一个配置文件 loadgen.yml 以及用于运行测试的 loadgen.dsl，配置文件样例如下：
env: ES_USERNAME: elastic ES_PASSWORD: elastic ES_ENDPOINT: http://localhost:8000 测试文件样例如下：
# runner: { # // total_rounds: 1 # no_warm: false, # // Whether to log all requests # log_requests: false, # // Whether to log all requests with the specified response status # log_status_codes: [0, 500], # assert_invalid: false, # assert_error: false, # }, # variables: [ # { # name: &amp;#34;ip&amp;#34;, # type: &amp;#34;file&amp;#34;, # path: &amp;#34;dict/ip.</description></item><item><title>与 Elasticsearch-Hadoop 集成</title><link>/gateway/main/zh/docs/tutorial/es-hadoop_integration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/es-hadoop_integration/</guid><description>与 Elasticsearch-Hadoop 集成 # Elasticsearch-Hadoop 默认会通过某个种子节点拿到后端的所有 Elasticsearch 节点，可能存在热点和请求分配不合理的情况， 为了提高后端 Elasticsearch 节点的资源利用率，可以通过极限网关来实现后端 Elasticsearch 节点访问的精准路由。
写入加速 # 如果是通过 Elasticsearch-Hadoop 来进行数据导入，可以通过修改 Elasticsearch-Hadoop 程序的以下参数来访问极限网关来提升写入吞吐，如下：
名称 类型 说明 es.nodes string 设置访问网关的地址列表，如：localhost:8000,localhost:8001 es.nodes.discovery bool 设置为 false，不采用 sniff 模式，只访问配置的后端节点列表 es.nodes.wan.only bool 设置为 true，代理模式，强制走网关地址 es.batch.size.entries int 适当调大批次文档数，提升吞吐，如 5000 es.batch.size.bytes string 适当调大批次传输大小，提升吞吐，如 20mb es.batch.write.refresh bool 设置为 false，避免主动刷新，提升吞吐 相关链接 # Elasticsearch-Hadoop 配置参数文档</description></item><item><title>与 Prometheus 集成</title><link>/gateway/main/zh/docs/tutorial/prometheus_integration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/prometheus_integration/</guid><description>与 Prometheus 集成 # 极限网关支持将运行指标输出为 Prometheus 格式, 方便与 Prometheus 进行集成, 具体操作如下:
统计信息接口 # 访问网关的 2900 接口,如下:
http://localhost:2900/stats?format=prometheus ➜ ~ curl http://localhost:2900/stats\?format\=prometheus buffer_fasthttp_resbody_buffer_acquired{type=&amp;quot;gateway&amp;quot;, ip=&amp;quot;192.168.3.23&amp;quot;, name=&amp;quot;Orchid&amp;quot;, id=&amp;quot;cbvjphrq50kcnsu2a8v0&amp;quot;} 1 buffer_stats_acquired{type=&amp;quot;gateway&amp;quot;, ip=&amp;quot;192.168.3.23&amp;quot;, name=&amp;quot;Orchid&amp;quot;, id=&amp;quot;cbvjphrq50kcnsu2a8v0&amp;quot;} 7 buffer_stats_max_count{type=&amp;quot;gateway&amp;quot;, ip=&amp;quot;192.168.3.23&amp;quot;, name=&amp;quot;Orchid&amp;quot;, id=&amp;quot;cbvjphrq50kcnsu2a8v0&amp;quot;} 0 system_cpu{type=&amp;quot;gateway&amp;quot;, ip=&amp;quot;192.168.3.23&amp;quot;, name=&amp;quot;Orchid&amp;quot;, id=&amp;quot;cbvjphrq50kcnsu2a8v0&amp;quot;} 0 buffer_bulk_request_docs_acquired{type=&amp;quot;gateway&amp;quot;, ip=&amp;quot;192.168.3.23&amp;quot;, name=&amp;quot;Orchid&amp;quot;, id=&amp;quot;cbvjphrq50kcnsu2a8v0&amp;quot;} 1 buffer_fasthttp_resbody_buffer_inuse{type=&amp;quot;gateway&amp;quot;, ip=&amp;quot;192.168.3.23&amp;quot;, name=&amp;quot;Orchid&amp;quot;, id=&amp;quot;cbvjphrq50kcnsu2a8v0&amp;quot;} 0 stats_gateway_request_bytes{type=&amp;quot;gateway&amp;quot;, ip=&amp;quot;192.168.3.23&amp;quot;, name=&amp;quot;Orchid&amp;quot;, id=&amp;quot;cbvjphrq50kcnsu2a8v0&amp;quot;} 0 system_mem{type=&amp;quot;gateway&amp;quot;, ip=&amp;quot;192.168.3.23&amp;quot;, name=&amp;quot;Orchid&amp;quot;, id=&amp;quot;cbvjphrq50kcnsu2a8v0&amp;quot;} 31473664 ... 通过增加额外的参数 format=prometheus 即可返回 Prometheus 所需数据格式.
配置 Prometheus 进行采集 # 修改配置文件: prometheus.</description></item><item><title>为 Elasticsearch 无缝添加代理和基础安全</title><link>/gateway/main/zh/docs/tutorial/proxy_elasticsearch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/proxy_elasticsearch/</guid><description>为 Elasticsearch 无缝添加代理和基础安全 # 如果你的 Elasticsearch 版本比较多或者比较旧，或者没有设置 TLS 和身份信息，那么任何人都有可能直接访问 Elasticsearch，而使用极限网关可以快速的进行修复。
使用 Elasticsearch 过滤器来转发请求 # 首先定义一个 Elasticsearch 的资源，如下：
elasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 然后可以使用如下的过滤器来转发请求到上面定义的 Elasticsearch 资源，名称为 prod：
- elasticsearch: elasticsearch: prod 有关该过滤器的更多详情，请参考文档： elasticsearch filter
添加一个简单的身份验证 # 我们进行添加一个基础的身份验证，来限制目标集群的访问
- basic_auth: valid_users: medcl: passwd 开启 TLS # 如果设置了身份，但是没有设置 TLS 也是不行的，因为 HTTP 是明文传输协议，可以非常容易泄露密码，配置如下：
- name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.</description></item><item><title>为 Kibana 添加代理和基础安全</title><link>/gateway/main/zh/docs/tutorial/proxy_kibana/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/proxy_kibana/</guid><description>为 Kibana 添加代理和基础安全 # 如果你的 Kibana 版本比较多或者比较旧，或者没有设置 TLS 和身份信息，那么任何人都有可能直接访问 Kibana，而使用极限网关可以快速的进行修复。
使用 HTTP 过滤器来转发请求 # - http: schema: &amp;quot;http&amp;quot; #https or http host: &amp;quot;192.168.3.188:5602&amp;quot; 添加身份验证 # - basic_auth: valid_users: medcl: passwd 在路由里面可以替换静态资源 # - method: - GET pattern: - &amp;quot;/plugins/kibanaReact/assets/illustration_integrations_lightmode.svg&amp;quot; flow: - replace_logo_flow 开启 TLS # - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 tls: enabled: true 完整配置如下 # entry: - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.</description></item><item><title>使用 JavaScript 脚本来进行复杂的查询改写</title><link>/gateway/main/zh/docs/tutorial/path_rewrite_by_javascript/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/path_rewrite_by_javascript/</guid><description>使用 JavaScript 脚本来进行复杂的查询改写 # 有这么一个需求：
网关里怎样对跨集群搜索进行支持的呢？我想实现: 输入的搜索请求是 lp:9200/index1/_search 这个索引在 3 个集群上，需要跨集群检索，也就是网关能否改成 lp:9200/cluster01:index1,cluster02,index1,cluster03:index1/_search 呢？ 索引有一百多个，名称不一定是 app, 还可能多个索引一起的。
极限网关自带的过滤器 content_regex_replace 虽然可以实现字符正则替换，但是这个需求是带参数的变量替换，稍微复杂一点，没有办法直接用这个正则替换实现，有什么其他办法实现么？
使用脚本过滤器 # 当然有的，上面的这个需求，理论上我们只需要将其中的索引 index1 匹配之后，替换为 cluster01:index1,cluster02,index1,cluster03:index1 就行了。
答案就是使用自定义脚本来做，再复杂的业务逻辑都不是问题，都能通过自定义脚本来实现，一行脚本不行，那就两行。
使用极限网关提供的 JavaScript 过滤器可以很灵活的实现这个功能，具体继续看。
定义脚本 # 首先创建一个脚本文件，放在网关数据目录的 scripts 子目录下面，如下：
➜ gateway ✗ tree data data └── gateway └── nodes └── c9bpg0ai4h931o4ngs3g ├── kvdb ├── queue ├── scripts │ └── index_path_rewrite.js └── stats 这个脚本的内容如下：
function process(context) { var originalPath = context.</description></item><item><title>兼容不同版本的响应 Count 结构</title><link>/gateway/main/zh/docs/tutorial/fix_count_in_search_response/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/fix_count_in_search_response/</guid><description>兼容不同版本的查询响应结果的 Count 结构 # Elasticsearch 在 7.0 之后的版本中，为了优化性能，搜索结果的命中数默认不进行精确的计数统计，同时对搜索结果的响应体进行了调整， 这样势必会造成已有代码的不兼容，如何快速修复呢？
结构对比 # 首先来对比下前后差异：
7 之前的搜索结构如下，total 显示的具体的数值：
{ &amp;quot;took&amp;quot;: 53, &amp;quot;timed_out&amp;quot;: false, &amp;quot;_shards&amp;quot;: { &amp;quot;total&amp;quot;: 1, &amp;quot;successful&amp;quot;: 1, &amp;quot;skipped&amp;quot;: 0, &amp;quot;failed&amp;quot;: 0 }, &amp;quot;hits&amp;quot;: { &amp;quot;total&amp;quot;: 0, &amp;quot;max_score&amp;quot;: null, &amp;quot;hits&amp;quot;: [] } } 7 之后的搜索结构如下，total 变成了一组描述范围的对象：
{ &amp;quot;took&amp;quot;: 3, &amp;quot;timed_out&amp;quot;: false, &amp;quot;_shards&amp;quot;: { &amp;quot;total&amp;quot;: 1, &amp;quot;successful&amp;quot;: 1, &amp;quot;skipped&amp;quot;: 0, &amp;quot;failed&amp;quot;: 0 }, &amp;quot;hits&amp;quot;: { &amp;quot;total&amp;quot;: { &amp;quot;value&amp;quot;: 10000, &amp;quot;relation&amp;quot;: &amp;quot;gte&amp;quot; }, &amp;quot;max_score&amp;quot;: 1, &amp;quot;hits&amp;quot;: [] } } Elasticsearch 提供的参数 # 不过在 7 里面，Elasticsearch 也提供了一个参数来控制是否进行精确计数，通过在查询请求的 url 参数里面加上 rest_total_hits_as_int=true 即可使用旧的行为方式，默认未开启。</description></item><item><title>在 Kibana 里统一访问来自不同集群的索引</title><link>/gateway/main/zh/docs/tutorial/routing_to_cluser_by_index/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/tutorial/routing_to_cluser_by_index/</guid><description>在 Kibana 里统一访问来自不同集群的索引 # 现在有这么一个需求，客户根据需要将数据按照业务维度划分，将索引分别存放在了不同的三个集群， 将一个大集群拆分成多个小集群有很多好处，比如降低了耦合，带来了集群可用性和稳定性方面的好处，也避免了单个业务的热点访问造成其他业务的影响， 尽管拆分集群是很常见的玩法，但是管理起来不是那么方便了，尤其是在查询的时候，可能要分别访问三套集群各自的 API，甚至要切换三套不同的 Kibana 来访问集群的数据， 那么有没有办法将他们无缝的联合在一起呢？
极限网关! # 答案自然是有的，通过将 Kibana 访问 Elasticsearch 的地址切换为极限网关的地址，我们可以将请求按照索引来进行智能的路由， 也就是当访问不同的业务索引时会智能的路由到不同的集群，如下图：
上图，我们分别有 3 个不同的索引：
apm-* erp-* mall-* 分别对应不同的三套 Elasticsearch 集群:
ES1-APM ES2-ERP ES3-MALL 接下来我们来看如何在极限网关里面进行相应的配置来满足这个业务需求。
配置集群信息 # 首先配置 3 个集群的连接信息。
elasticsearch: - name: es1-apm enabled: true endpoints: - http://192.168.3.188:9206 - name: es2-erp enabled: true endpoints: - http://192.168.3.188:9207 - name: es3-mall enabled: true endpoints: - http://192.168.3.188:9208 配置服务 Flow # 然后，我们定义 3 个 Flow，分别对应用来访问 3 个不同的 Elasticsearch 集群，如下：</description></item><item><title>其它配置</title><link>/gateway/main/zh/docs/references/config/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/config/</guid><description>其它配置 # 高级用法 # 配置模板 # 示例：
configs.template: - name: &amp;quot;es_gw1&amp;quot; path: ./sample-configs/config_template.tpl variable: name: &amp;quot;es_gw1&amp;quot; binding_host: &amp;quot;0.0.0.0:8000&amp;quot; tls_on_entry: true elasticsearch_endpoint: &amp;quot;http://localhost:9200&amp;quot; 名称 类型 说明 configs.template array 配置模板，可以指定多个模板和对应的参数 configs.template[].name string 配置的名称 configs.template[].path string 模板配置路径 configs.template[].variable map 模板的参数设置，变量在模板里面的用法：$[[变量名]] 使用环境变量 # 极限网关支持在配置里面使用环境变量来进行灵活的参数控制。
首先在配置里面定义环境变量的默认值，如下：
env: PROD_ES_ENDPOINT: http://localhost:9200 PROD_ES_USER: elastic PROD_ES_PASS: password 然后就可以在配置里面通过如下语法来使用环境变量了：
elasticsearch: - name: prod enabled: true endpoints: - $[[env.</description></item><item><title>auto_generate_doc_id</title><link>/gateway/main/zh/docs/references/filters/auto_generate_doc_id/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/auto_generate_doc_id/</guid><description>auto_generate_doc_id # 描述 # 过滤器 auto_generate_doc_id 用于在创建文档时为其添加 UUID（通用唯一标识符），当创建文档时没有显式指定 UUID 时使用该过滤器。通常情况下，这适用于不希望后端系统自动生成 ID 的情况。例如，如果您想在集群之间复制文档，最好为文档分配一个已知的 ID，而不是让每个集群为文档生成自己的 ID。否则，这可能导致集群之间的不一致性。
配置示例 # A simple example is as follows:
flow: - name: test_auto_generate_doc_id filter: - auto_generate_doc_id: 参数说明 # 名称 类型 说明 prefix string 给 UUID 增加一个固定前缀</description></item><item><title>basic_auth</title><link>/gateway/main/zh/docs/references/filters/basic_auth/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/basic_auth/</guid><description>basic_auth # 描述 # basic_auth 过滤器用来验证请求的身份认证信息，适用于简单的身份认证。
配置示例 # 一个简单的示例如下：
flow: - name: basic_auth filter: - basic_auth: valid_users: medcl: passwd medcl1: abc ... 参数说明 # 名称 类型 说明 valid_users map 用户名和密码</description></item><item><title>bulk_indexing</title><link>/gateway/main/zh/docs/references/processors/bulk_indexing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/bulk_indexing/</guid><description>bulk_indexing # 描述 # bulk_indexing 处理器用来异步消费队列里面的 bulk 请求。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - bulk_indexing: queue_selector.labels: type: bulk_reshuffle level: cluster 参数说明 # 名称 类型 说明 elasticsearch string 默认的 Elasticsearch 集群 ID,如果队列 Labels 里面没有指定 elasticsearch 的话会使用这个参数 max_connection_per_node int 目标节点允许的最大连接数，默认 1 max_worker_size int 最大允许同时运行的 worker 大小,默认 10 num_of_slices int 并行消费单个队列的线程, 运行时最大的 slice 大小 slices array 允许的 slice 编号, int 数组 queue_selector.</description></item><item><title>bulk_request_mutate</title><link>/gateway/main/zh/docs/references/filters/bulk_request_mutate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/bulk_request_mutate/</guid><description>bulk_request_mutate # 描述 # bulk_request_mutate 过滤器用来干预 Elasticsearch 的 Bulk 请求。
配置示例 # 一个简单的示例如下：
flow: - name: bulk_request_mutate filter: - bulk_request_mutate: fix_null_id: true generate_enhanced_id: true # fix_null_type: true # default_type: m-type # default_index: m-index # index_rename: # &amp;quot;*&amp;quot;: index-new # index1: index-new # index2: index-new # index3: index3-new # index4: index3-new # medcl-dr3: index3-new # type_rename: # &amp;quot;*&amp;quot;: type-new # type1: type-new # type2: type-new # doc: type-new # doc1: type-new .</description></item><item><title>bulk_request_throttle</title><link>/gateway/main/zh/docs/references/filters/bulk_request_throttle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/bulk_request_throttle/</guid><description>bulk_request_throttle # 描述 # bulk_request_throttle 过滤器用来对 Elasticsearch 的 Bulk 请求进行限速。
配置示例 # 一个简单的示例如下：
flow: - name: bulk_request_mutate filter: - bulk_request_throttle: indices: test: max_requests: 5 action: drop message: &amp;quot;test writing too fast。&amp;quot; log_warn_message: true filebeat-*: max_bytes: 512 action: drop message: &amp;quot;filebeat indices writing too fast。&amp;quot; log_warn_message: true 参数说明 # 名称 类型 说明 indices map 用于限速的索引，可以分别设置限速规则 indices.[NAME].interval string 评估限速的单位时间间隔，默认为 1s indices.</description></item><item><title>bulk_reshuffle</title><link>/gateway/main/zh/docs/references/filters/bulk_reshuffle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/bulk_reshuffle/</guid><description>bulk_reshuffle # 描述 # bulk_reshuffle 可以分析 Elasticsearch 的批次请求，并按照文档进行解析，可以根据需要将文档分门别类，归档存储在队列中，通过先落地存储，业务端请求可以快速返回，从而解耦前端写入和后端 Elasticsearch 集群。bulk_reshuffle 需要离线管道消费任务来配合使用。
通过 bulk_reshuffle 过滤器生成的队列，元数据会默认带上 &amp;quot;type&amp;quot;: &amp;quot;bulk_reshuffle&amp;quot; 以及 Elasticsearch 的集群信息，如：&amp;quot;elasticsearch&amp;quot;: &amp;quot;dev&amp;quot;，通过网关查看队列的 API 也可以查看，如下：
curl http://localhost:2900/queue/stats { &amp;quot;queue&amp;quot;: { &amp;quot;disk&amp;quot;: { &amp;quot;async_bulk-cluster##dev&amp;quot;: { &amp;quot;depth&amp;quot;: 0, &amp;quot;metadata&amp;quot;: { &amp;quot;source&amp;quot;: &amp;quot;dynamic&amp;quot;, &amp;quot;id&amp;quot;: &amp;quot;c71f7pqi4h92kki4qrvg&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;async_bulk-cluster##dev&amp;quot;, &amp;quot;label&amp;quot;: { &amp;quot;elasticsearch&amp;quot;: &amp;quot;dev&amp;quot;, &amp;quot;level&amp;quot;: &amp;quot;cluster&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;bulk_reshuffle&amp;quot; } } } } } } 节点级别的异步提交 # 极限网关可以本地计算每个索引文档对应后端 Elasticsearch 集群的目标存放位置，从而能够精准的进行请求定位，在一批 bulk 请求中，可能存在多个后端节点的数据，bulk_reshuffle 过滤器用来将正常的 bulk 请求打散，按照目标节点或者分片进行拆分重新组装，避免 Elasticsearch 节点收到请求之后再次进行请求分发， 从而降低 Elasticsearch 集群间的流量和负载，也能避免单个节点成为热点瓶颈，确保各个数据节点的处理均衡，从而提升集群总体的索引吞吐能力。</description></item><item><title>bulk_response_process</title><link>/gateway/main/zh/docs/references/filters/bulk_response_process/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/bulk_response_process/</guid><description>bulk_response_process # 描述 # bulk_response_process 过滤器用来处理 Elasticsearch 的 Bulk 请求。
配置示例 # 一个简单的示例如下：
flow: - name: bulk_response_process filter: - bulk_response_process: success_queue: &amp;quot;success_queue&amp;quot; tag_on_success: [&amp;quot;commit_message_allowed&amp;quot;] 参数说明 # 名称 类型 说明 invalid_queue string 保存非法请求的队列名称，必填。 failure_queue string 保存失败请求的队列名称，必填。 save_partial_success_requests bool 是否保存 bulk 请求里面部分执行成功的请求，默认 false。 success_queue string 保存 bulk 请求里面部分执行成功的请求的队列。 continue_on_error bool bulk 请求出错之后是否继续执行后面的 filter，默认 false message_truncate_size int bulk 请求出错日志截断长度，默认 1024 safety_parse bool 是否采用安全的 bulk 元数据解析方法，默认 true doc_buffer_size int 当采用不安全的 bulk 元数据解析方法时，使用的 buffer 大小，默认 256 * 1024 tag_on_success array 将所有 bulk 请求处理完成之后，请求上下文打上指定标记 tag_on_error array 请求出现错误的情况下，请求上下文打上指定标记 tag_on_partial array 部分请求执行成功的情况下，请求上下文打上指定标记 tag_on_failure array 部分请求出现失败（可重试）的情况下，请求上下文打上指定标记 tag_on_invalid array 出现不合法请求错误的情况下，请求上下文打上指定标记 success_flow string 请求成功执行的 Flow invalid_flow string 非法请求执行的 Flow failure_flow string 失败请求执行的 Flow</description></item><item><title>cache</title><link>/gateway/main/zh/docs/references/filters/cache/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/cache/</guid><description>cache # 描述 # cache 过滤器由 get_cache 和 set_cache 两组过滤器组成，一般需要组合使用，可用于缓存加速查询，抵挡重复请求，降低后端集群查询压力。
get_cache 过滤器 # 过滤器 get_cache 用来从缓存里面获取之前出现的消息，直接返回给客户端，避免访问后端 Elasticsearch，用于缓存热点数据。
配置示例如下：
flow: - name: get_cache filter: - get_cache: pass_patterns: [&amp;quot;_cat&amp;quot;,&amp;quot;scroll&amp;quot;, &amp;quot;scroll_id&amp;quot;,&amp;quot;_refresh&amp;quot;,&amp;quot;_cluster&amp;quot;,&amp;quot;_ccr&amp;quot;,&amp;quot;_count&amp;quot;,&amp;quot;_flush&amp;quot;,&amp;quot;_ilm&amp;quot;,&amp;quot;_ingest&amp;quot;,&amp;quot;_license&amp;quot;,&amp;quot;_migration&amp;quot;,&amp;quot;_ml&amp;quot;,&amp;quot;_rollup&amp;quot;,&amp;quot;_data_stream&amp;quot;,&amp;quot;_open&amp;quot;, &amp;quot;_close&amp;quot;] 参数说明 # 名称 类型 说明 pass_patterns string 设置忽略缓存的请求规则，URL 包含其中的任意关键字将跳过缓存 set_cache 过滤器 # 过滤器 set_cache 用来将后端查询拿到的返回结果存到缓存里面，可以设置过期时间。
配置示例如下：
flow: - name: get_cache filter: - set_cache: min_response_size: 100 max_response_size: 1024000 cache_ttl: 30s max_cache_items: 100000 参数说明 # 名称 类型 说明 cache_type string 缓存类型，支持 ristretto，ccache 和 redis，默认 ristretto cache_ttl string 缓存的过期时间，默认 10s async_search_cache_ttl string 异步请求结果的缓存过期时间，默认 10m min_response_size int 最小符合缓存要求的消息体大小，默认 -1 表示不限制 max_response_size int 最大符合缓存要求的消息体大小，默认为 int 的最大值 max_cached_item int 最大的缓存消息总数，默认 1000000，当类型为 ccache有效 max_cached_size int 最大的缓存内存开销，默认 1000000000 即 1GB，当类型为 ristretto 有效 validated_status_code array 允许被缓存的请求状态码，默认 200,201,404,403,413,400,301 其它参数 # 如果希望主动忽略缓存，可以在 URL 的参数里面传递一个 no_cache 来让网关忽略缓存。如：</description></item><item><title>clone</title><link>/gateway/main/zh/docs/references/filters/clone/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/clone/</guid><description>clone # 描述 # clone 过滤器用来将流量克隆转发到另外的一个处理流程，可以实现双写、多写、多数据中心同步、集群升级、版本切换等需求。
配置示例 # 一个简单的示例如下：
flow: - name: double_write filter: - clone: flows: - write_to_region_a - write_to_region_b #last one's response will be output to client - name: write_to_region_a filter: - elasticsearch: elasticsearch: es1 - name: write_to_region_b filter: - elasticsearch: elasticsearch: es2 上面的例子可以将 Elasticsearch 的请求复制到两个不同的异地集群。
参数说明 # 名称 类型 说明 flows array 指定多个流量处理的流程，依次同步执行，将最后一个流程处理的结果输出给客户端 continue bool 流量迁移出去之后，是否还继续执行之前的既定流程，设置成 false 则立即返回，默认 false。</description></item><item><title>consumer</title><link>/gateway/main/zh/docs/references/processors/consumer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/consumer/</guid><description>consumer # 描述 # consumer 处理器用来消费 queue 记录的消息请求，但是不处理，目标是提供数据消费管道的入口，由后续的 processor 进行数据加工。
配置示例 # 一个简单的示例如下：
pipeline: - name: consume_queue_messages auto_start: true keep_running: true retry_delay_in_ms: 5000 processor: - consumer: consumer: fetch_max_messages: 1 max_worker_size: 200 num_of_slices: 1 idle_timeout_in_seconds: 30 queue_selector: keys: - email_messages processor: - xxx1: - xxx2: 上面的例子，订阅并消费队列 email_messages，队列消息保存在当前 Pipeline 管道的上下文里面，Consumer 提供了一个 processor 参数，这个参数里面是一系列 Processor，依次执行，任何一个 Processor 如果执行返回出错，consumer 则退出切不会 commit 这批数据。
参数说明 # 名称 类型 说明 message_field string 从队列获取到的消息，存放到上下文的字段名称, 默认 messages max_worker_size int 最大允许同时运行的 worker 大小,默认 10 num_of_slices int 并行消费单个队列的线程, 运行时最大的 slice 大小 slices array 允许的 slice 编号, int 数组 queue_selector.</description></item><item><title>context_filter</title><link>/gateway/main/zh/docs/references/filters/context_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/context_filter/</guid><description>context_filter # 描述 # context_filter 过滤器用来按请求上下文来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - context_filter: context: _ctx.request.path message: &amp;quot;request not allowed.&amp;quot; status: 403 must: #must match all rules to continue prefix: - /medcl contain: - _search suffix: - _search wildcard: - /*/_search regex: - ^/m[\w]+dcl must_not: # any match will be filtered prefix: - /.kibana - /_security - /_security - /gateway_requests* - /.reporting - /_monitoring/bulk contain: - _refresh suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/\.</description></item><item><title>context_limiter</title><link>/gateway/main/zh/docs/references/filters/context_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/context_limiter/</guid><description>context_limiter # 描述 # context_limiter 过滤器用来按照请求上下文来进行限速。
配置示例 # 配置示例如下：
flow: - name: default_flow filter: - context_limiter: max_requests: 1 action: drop context: - _ctx.request.path - _ctx.request.header.Host - _ctx.request.header.Env 上面的配置中，对 _ctx.request.path 、 _ctx.request.header.Host 和 _ctx.request.header.Env 这三个上下文变量来组成一个 bucket 进行限速。 允许的最大 qps 为 1每秒，达到限速直接拒绝范围外的后续请求。
参数说明 # 名称 类型 说明 context array 设置上下文变量，依次组合成一个 bucket key interval string 评估限速的单位时间间隔，默认为 1s max_requests int 单位间隔内最大的请求次数限额 burst_requests int 单位间隔内极限允许的请求次数 max_bytes int 单位间隔内最大的请求流量限额 burst_bytes int 单位间隔内极限允许的流量限额 action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry status string 设置达到限速条件的返回状态码，默认 429 message string 设置达到限速条件的请求的拒绝返回消息 retry_delay_in_ms int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒 max_retry_times int 限速重试的最大重试次数，默认 1000 failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息 log_warn_message bool 是否输出警告消息到日志</description></item><item><title>context_parse</title><link>/gateway/main/zh/docs/references/filters/context_parse/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/context_parse/</guid><description>context_parse # 描述 # context_parse 过滤器用来对上下文变量进行字段的提取，并存放到上下文中。
配置示例 # 一个简单的示例如下：
flow: - name: context_parse filter: - context_parse: context: _ctx.request.path pattern: ^\/.*?\d{4}\.(?P&amp;lt;month&amp;gt;\d{2})\.(?P&amp;lt;day&amp;gt;\d{2}).*? group: &amp;quot;parsed_index&amp;quot; 通过 context_parse 可以提取请求如：/abd-2023.02.06-abc/_search，得到新的上下文变量 parsed_index.month 和 parsed_index.day。
参数说明 # 名称 类型 说明 context string 上下文变量名称 pattern string 用来提取字段的正则表达式 skip_error bool 是否忽略错误直接返回，如上下文变量不存在 group string 提取的字段是否存放到一个单独的分组下面</description></item><item><title>context_regex_replace</title><link>/gateway/main/zh/docs/references/filters/context_regex_replace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/context_regex_replace/</guid><description>context_regex_replace # 描述 # context_regex_replace 过滤器用来通过正则表达式来替换修改请求上下文的相关信息。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - context_regex_replace: context: &amp;quot;_ctx.request.path&amp;quot; pattern: &amp;quot;^/&amp;quot; to: &amp;quot;/cluster:&amp;quot; when: contains: _ctx.request.path: /_search - dump: request: true 这个例子可以将请求 curl localhost:8000/abc/_search 替换为 curl localhost:8000/cluster:abc/_search
参数说明 # 名称 类型 说明 context string 请求的上下文及对应的 Key pattern string 用于匹配替换的正则表达式 to string 替换为目标的字符串内容 支持修改的上下文变量列表如下：</description></item><item><title>context_switch</title><link>/gateway/main/zh/docs/references/filters/context_switch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/context_switch/</guid><description>context_switch # 描述 # context_switch 过滤器用来使用上下文变量来进行条件判断实现灵活跳转。
配置示例 # 一个简单的示例如下：
flow: - name: context_switch filter: - context_switch: context: logging.month default_flow: echo_message_not_found switch: - case: [&amp;quot;02&amp;quot;,&amp;quot;01&amp;quot;] action: redirect_flow flow: echo_message_01_02 - case: [&amp;quot;03&amp;quot;] action: redirect_flow flow: echo_message_03 参数说明 # 名称 类型 说明 context string 上下文变量名称 skip_error bool 是否忽略错误直接返回，如上下文变量不存在 default_action string 默认的执行动作，支持 redirect_flow 和 drop，默认 redirect_flow default_flow string 默认的 flow 名称 stringify_value bool 是否将参数都统一成字符来进行处理，默认 true。 continue bool 匹配跳转之后，是否还继续执行后面的流程，设置成 false 则立即返回，默认 false。 switch array 条件判断枚举数组 switch[i].</description></item><item><title>dag</title><link>/gateway/main/zh/docs/references/processors/dag/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/dag/</guid><description>dag # 描述 # dag 处理器用来管理任务的并行调度。
配置示例 # 下面的这个例子，定义了一个名为 racing_example 的服务，auto_start 设置为自动启动，processor 设置依次执行的每个处理单元，其中 dag 处理器支持多个任务并行执行，支持 wait_all 和 first_win 两种聚合模式，如下：
pipeline: - name: racing_example auto_start: true processor: - echo: #ready, set, go message: read,set,go - dag: mode: wait_all #first_win, wait_all parallel: - echo: #player1 message: player1 - echo: #player2 message: player2 - echo: #player3 message: player3 end: - echo: #checking score message: checking score - echo: #announce champion message: 'announce champion' - echo: #done message: racing finished 上面的 echo 处理器非常简单，用来输出一个指定的消息，这个管道模拟的是一个赛跑的场景，palyer1、2、3 并行赛跑，全部跑完之后再进行算分和宣布比赛冠军，最后输出结束信息，程序运行输出如下：</description></item><item><title>date_range_precision_tuning</title><link>/gateway/main/zh/docs/references/filters/date_range_precision_tuning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/date_range_precision_tuning/</guid><description>date_range_precision_tuning # 描述 # date_range_precision_tuning 过滤器用来重设时间范围查询的时间精度，通过调整精度，可以让短时间内邻近的重复请求更容易被缓存，对于有一些对于时间精度不那么高但是数据量非常大的场景，比如使用 Kibana 来做报表分析，通过缩减精度来缓存重复的查询请求，从而降低后端服务器压力，前端报表展现的提速非常明显。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - date_range_precision_tuning: time_precision: 4 - get_cache: - elasticsearch: elasticsearch: dev - set_cache: 精度说明 # Kibana 默认发往 Elasticsearch 的查询，使用的是当前时间 Now，精度到毫秒，通过设置不同的精度来改写查询，以下面的查询为例：
{&amp;quot;range&amp;quot;:{&amp;quot;@timestamp&amp;quot;:{&amp;quot;gte&amp;quot;:&amp;quot;2019-09-26T08:21:12.152Z&amp;quot;,&amp;quot;lte&amp;quot;:&amp;quot;2020-09-26T08:21:12.152Z&amp;quot;,&amp;quot;format&amp;quot;:&amp;quot;strict_date_optional_time&amp;quot;} 分别设置不同的精度，改写之后的查询结果如下：
精度 新的查询 0 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T00:00:00.000Z&amp;rdquo;,&amp;ldquo;lte&amp;rdquo;:&amp;ldquo;2020-09-26T23:59:59.999Z&amp;rdquo;,&amp;ldquo;format&amp;rdquo;:&amp;ldquo;strict_date_optional_time&amp;rdquo;} 1 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T00:00:00.000Z&amp;rdquo;,&amp;ldquo;lte&amp;rdquo;:&amp;ldquo;2020-09-26T09:59:59.999Z&amp;rdquo;,&amp;ldquo;format&amp;rdquo;:&amp;ldquo;strict_date_optional_time&amp;rdquo;} 2 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T08:00:00.000Z&amp;rdquo;,&amp;ldquo;lte&amp;rdquo;:&amp;ldquo;2020-09-26T08:59:59.999Z&amp;rdquo;,&amp;ldquo;format&amp;rdquo;:&amp;ldquo;strict_date_optional_time&amp;rdquo;} 3 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T08:20:00.000Z&amp;rdquo;,&amp;ldquo;lte&amp;rdquo;:&amp;ldquo;2020-09-26T08:29:59.999Z&amp;rdquo;,&amp;ldquo;format&amp;rdquo;:&amp;ldquo;strict_date_optional_time&amp;rdquo;} 4 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T08:21:00.000Z&amp;rdquo;,&amp;ldquo;lte&amp;rdquo;:&amp;ldquo;2020-09-26T08:21:59.999Z&amp;rdquo;,&amp;ldquo;format&amp;rdquo;:&amp;ldquo;strict_date_optional_time&amp;rdquo;} 5 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T08:21:10.</description></item><item><title>drop</title><link>/gateway/main/zh/docs/references/filters/drop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/drop/</guid><description>drop # 描述 # drop 过滤器用来丢弃某个消息，提前结束请求的处理。
配置示例 # 一个简单的示例如下：
flow: - name: drop filter: - drop:</description></item><item><title>dump</title><link>/gateway/main/zh/docs/references/filters/dump/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/dump/</guid><description>dump # 描述 # dump 过滤器是一个用于在终端打印 Dump 输出相关请求信息的过滤器，主要用于调试。
配置示例 # 一个简单的示例如下：
flow: - name: hello_world filter: - dump: request: true response: true 参数说明 # dump 过滤器比较简单，在需要的流程处理阶段插入 dump 过滤器，即可在终端输出相应阶段的请求信息，方便调试。
名称 类型 说明 request bool 是否输出全部完整的请求信息 response bool 是否输出全部完整的返回信息 uri bool 是否输出请求的 URI 信息 query_args bool 是否输出请求的参数信息 user bool 是否输出请求的用户信息 api_key bool 是否输出请求的 APIKey 信息 request_header bool 是否输出请求的头信息 response_header bool 是否输出响应的头信息 status_code bool 是否输出响应的状态码 context array 输出自定义的上下文信息 输出上下文 # 可以使用 context 参数来调试请求上下文信息，示例配置文件：</description></item><item><title>dump_hash</title><link>/gateway/main/zh/docs/references/processors/dump_hash/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/dump_hash/</guid><description>dump_hash # 描述 # dump_hash 处理器用来导出集群的索引文档并计算 Hash。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - dump_hash: #dump es1's doc indices: &amp;quot;medcl-dr3&amp;quot; scroll_time: &amp;quot;10m&amp;quot; elasticsearch: &amp;quot;source&amp;quot; query: &amp;quot;field1:elastic&amp;quot; fields: &amp;quot;doc_hash&amp;quot; output_queue: &amp;quot;source_docs&amp;quot; batch_size: 10000 slice_size: 5 参数说明 # 名称 类型 说明 elasticsearch string 目标集群的名称 scroll_time string Scroll 回话超时时间 batch_size int Scroll 批次大小，默认 5000 slice_size int Slice 大小，默认 1 sort_type string 文档排序类型，默认 asc sort_field string 文档排序字段 indices string 索引 level string 请求处理级别，可以设置为 cluster 则表示请求不进行节点和分片级别的拆分，适用于 Elasticsearch 前有代理的情况 query string 查询过滤条件 fields string 要返回的字段列表 sort_document_fields bool hash 计算之前是否对 _source 里面的字段进行排序，默认 false hash_func string hash 函数，可选 xxhash32、xxhash64、fnv1a，默认 xxhash32 output_queue string 输出结果的队列名称</description></item><item><title>elasticsearch</title><link>/gateway/main/zh/docs/references/filters/elasticsearch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/elasticsearch/</guid><description>elasticsearch # 描述 # elasticsearch 过滤器是一个用于请求转发给后端 Elasticsearch 集群的过滤器。
配置示例 # 使用 elasticsearch 过滤器之前，需要提前定义一个 Elasticsearch 的集群配置节点，如下：
elasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 流程的配置示例如下：
flow: - name: cache_first filter: - elasticsearch: elasticsearch: prod 上面的例子即将请求转发给 prod 集群。
自动更新 # 对于一个大规模的集群，可能存在很多的节点，不可能一一配置后端的所有节点，只需要先指定 Elasticsearch 模块允许自动发现后端节点，如下：
elasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true basic_auth: username: elastic password: pass 然后过滤器这边的配置也开启刷新，即可访问后端所有节点，且节点上下线也会自动更新，示例如下：
flow: - name: cache_first filter: - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 设置权重 # 如果后端集群很多，极限网关支持对不同的节点设置不同的访问权重，配置示例如下：</description></item><item><title>elasticsearch_health_check</title><link>/gateway/main/zh/docs/references/filters/elasticsearch_health_check/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/elasticsearch_health_check/</guid><description>elasticsearch_health_check # 描述 # elasticsearch_health_check 过滤器用来以限速模式下主动探测 Elasticsearch 的健康情况， 当出现后端故障的情况下，可以触发一次主动的集群健康检查，而不用等待 Elasticsearch 默认的轮询检查结果，限速设置为最多每秒发送一次检查请求给后端 Elasticsearch。
配置示例 # 一个简单的示例如下：
flow: - name: elasticsearch_health_check filter: - elasticsearch_health_check: elasticsearch: dev 参数说明 # 名称 类型 说明 elasticsearch string 集群 ID interval int 设置最少执行请求的时间间隔，单位秒，默认 1</description></item><item><title>flow</title><link>/gateway/main/zh/docs/references/filters/flow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/flow/</guid><description>flow # 描述 # flow 过滤器用来跳转或执行某个或一系列其他流程。
配置示例 # 一个简单的示例如下：
flow: - name: flow filter: - flow: flows: - request_logging 使用上下文的动态 Flow:
flow: - name: dns-flow filter: - flow: ignore_undefined_flow: true context_flow: context: _ctx.request.host context_parse_pattern: (?P&amp;lt;uuid&amp;gt;^[0-9a-z_\-]+)\. flow_id_template: flow_$[[uuid]] - set_response: status: 503 content_type: application/json body: '{&amp;quot;message&amp;quot;:&amp;quot;invalid HOST&amp;quot;}' 支持的上下文变量，请访问 上下文 .
参数说明 # 名称 类型 说明 flow string 流程 ID，支持指定单个 flow 执行 flows array 流程 ID，数组格式，可以指定多个，依次执行 ignore_undefined_flow bool 是否忽略未知的 flow，继续执行 context_flow.</description></item><item><title>flow_replay</title><link>/gateway/main/zh/docs/references/processors/flow_replay/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/flow_replay/</guid><description>flow_replay # 描述 # flow_replay 处理器用来异步消费队列里面的请求并使用异步用于在线请求的处理流程来进行消费处理。
配置示例 # 一个简单的示例如下：
pipeline: - name: backup-flow-request-reshuffle auto_start: true keep_running: true singleton: true retry_delay_in_ms: 10 processor: - consumer: max_worker_size: 100 queue_selector: labels: type: &amp;quot;primary_write_ahead_log&amp;quot; consumer: group: request-reshuffle fetch_max_messages: 10000 fetch_max_bytes: 20485760 fetch_max_wait_ms: 10000 processor: - flow_replay: flow: backup-flow-request-reshuffle commit_on_tag: &amp;quot;commit_message_allowed&amp;quot; 参数说明 # 名称 类型 说明 message_field string 从队列获取到的消息，存放到上下文的字段名称, 默认 messages flow string 以什么样的流程来消费队列里面的请求消息 commit_on_tag string 只有当前请求的上下文里面出现指定 tag 才会 commit 消息，默认为空表示执行完就 commit</description></item><item><title>flow_runner</title><link>/gateway/main/zh/docs/references/processors/flow_runner/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/flow_runner/</guid><description>flow_runner # 描述 # flow_runner 处理器用来异步消费队列里面的请求并使用异步用于在线请求的处理流程来进行消费处理。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - flow_runner: input_queue: &amp;quot;primary_deadletter_requests&amp;quot; flow: primary-flow-post-processing when: cluster_available: [ &amp;quot;primary&amp;quot; ] 参数说明 # 名称 类型 说明 input_queue string 订阅的队列名称 flow string 以什么样的流程来消费队列里面的请求消息 commit_on_tag string 只有当前请求的上下文里面出现指定 tag 才会 commit 消息，默认为空表示执行完就 commit</description></item><item><title>hash_mod</title><link>/gateway/main/zh/docs/references/filters/hash_mod/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/hash_mod/</guid><description>hash_mod # 描述 # hash_mod 过滤器用来使用请求的上下文通过哈希取模得到一个唯一的分区编号，一般用于后续的请求转发。
配置示例 # 一个简单的示例如下：
flow: - name: default_flow filter: - hash_mod: #hash requests to different queues source: &amp;quot;$[[_ctx.remote_ip]]_$[[_ctx.request.username]]_$[[_ctx.request.path]]&amp;quot; target_context_name: &amp;quot;partition_id&amp;quot; mod: 10 #hash to 10 partitions add_to_header: true - set_context: context: _ctx.request.header.X-Replicated-ID: $[[_util.increment_id.request_number_id]]_$[[_util.generate_uuid]] _ctx.request.header.X-Replicated-Timestamp: $[[_sys.unix_timestamp_of_now]] _ctx.request.header.X-Replicated: &amp;quot;true&amp;quot; 参数说明 # 名称 类型 说明 source string 哈希的输入输入，支持变量参数 target_context_name string 将分区编号保持到上下文的主键名称 mod int 最大分区数 add_to_request_header bool 是否添加到请求头，默认 true，分别为：X-Partition-ID 和 X-Partition-Size add_to_response_header bool 是否添加到响应头，默认 false</description></item><item><title>http</title><link>/gateway/main/zh/docs/references/filters/http/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/http/</guid><description>http # 描述 # http 过滤器用来将请求代理转发到指定的 http 服务器。
配置示例 # 一个简单的示例如下：
flow: - name: default_flow filter: - basic_auth: valid_users: medcl: passwd - http: schema: &amp;quot;http&amp;quot; #https or http #host: &amp;quot;192.168.3.98:5601&amp;quot; hosts: - &amp;quot;192.168.3.98:5601&amp;quot; - &amp;quot;192.168.3.98:5602&amp;quot; 参数说明 # 名称 类型 说明 schema string http 或是 https host string 目标主机地址，带端口，如 localhost:9200 hosts array 主机地址列表，遇到故障，依次尝试 skip_failure_host bool 是否跳过不可以的主机，默认 true max_connection_per_node int 主机的最大连接数，默认 5000 max_response_size int 支持的最大响应体大小 max_retry_times int 出错的最大重试次数，默认 0 retry_delay_in_ms int 重试的延迟，默认 1000 skip_cleanup_hop_headers bool 是否移除不兼容的 Hop-by-hop 头信息 max_conn_wait_timeout duration 建立连接的超时时间，默认 30s max_idle_conn_duration duration 空闲连接的超时时间，默认 30s max_conn_duration duration 长连接的超时时间，默认 0s timeout duration 请求的超时时间，默认 30s read_timeout duration 读请求的超时时间，默认 0s write_timeout duration 写请求的超时时间，默认 0s read_buffer_size int 读请求的缓冲区大小，默认 16384 write_buffer_size int 写请求的缓冲区大小，默认 16384 tls_insecure_skip_verify bool 是否忽略 TLS 的校验，默认 true</description></item><item><title>index_diff</title><link>/gateway/main/zh/docs/references/processors/index_diff/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/index_diff/</guid><description>index_diff # 描述 # index_diff 处理器用来对两个结果集进行差异对比。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - index_diff: diff_queue: &amp;quot;diff_result&amp;quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 参数说明 # 名称 类型 说明 source_queue string 来源数据的名称 target_queue string 目标数据的名称 diff_queue string 存放 diff 结果的队列 buffer_size int 内存 buffer 大小 keep_source bool diff 结果里面是否包含文档 source 信息 text_report bool 是否输出文本格式的结果</description></item><item><title>indexing_merge</title><link>/gateway/main/zh/docs/references/processors/indexing_merge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/indexing_merge/</guid><description>indexing_merge # 描述 # indexing_merge 处理器用来消费队列里面的纯 JSON 文档，并合并成 Bulk 请求保存到指定的队列里面，需要配合 bulk_indexing 处理器进行消费，用批量写入代替单次请求来提高写入吞吐。
配置示例 # 一个简单的示例如下：
pipeline: - name: indexing_merge auto_start: true keep_running: true processor: - indexing_merge: input_queue: &amp;quot;request_logging&amp;quot; elasticsearch: &amp;quot;logging-server&amp;quot; index_name: &amp;quot;infini_gateway_requests&amp;quot; output_queue: name: &amp;quot;gateway_requests&amp;quot; label: tag: &amp;quot;request_logging&amp;quot; worker_size: 1 bulk_size_in_mb: 10 - name: logging_requests auto_start: true keep_running: true processor: - bulk_indexing: bulk: compress: true batch_size_in_mb: 10 batch_size_in_docs: 5000 consumer: fetch_max_messages: 100 queues: type: indexing_merge when: cluster_available: [ &amp;quot;logging-server&amp;quot; ] 参数说明 # 名称 类型 说明 input_queue string 订阅的队列名称 worker_size int 并行执行消费任务的线程数，默认 1 idle_timeout_in_seconds int 消费队列的超时时间，默认 5，单位秒 bulk_size_in_kb int 批次请求的单位大小，单位 KB bulk_size_in_mb int 批次请求的单位大小，单位 MB，默认 10 elasticsearch string 保存到目标集群的名称 index_name string 保存到目标集群的索引名称 type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc output_queue.</description></item><item><title>javascript</title><link>/gateway/main/zh/docs/references/filters/javascript/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/javascript/</guid><description>javascript # 描述 # javascript 过滤器可用于通过用 javascript 编写脚本来执行您自己的处理逻辑，从而提供最大的灵活性。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - javascript: source: &amp;gt; function process(ctx) { var console = require('console'); console.log(&amp;quot;hello from javascript&amp;quot;); } 这个脚本里面的 process 是一个内置的函数，用来处理传进来的上下文信息，函数里面可以自定义业务逻辑。
如果脚本比较复杂，也支持通过文件的方式从加载：
flow: - name: test filter: - javascript: file: example.js 这里的 example.js 是文件的保存路径。
参数说明 # 名称 类型 描述 source string 要执行的 Javascript 代码。 file string 要加载的脚本文件的路径。相对路径被解释为相对于网关实例数据目录的 scripts 子目录。 params map 一个参数字典，传递给脚本的 register 方法。 上下文 API # 传递给处理方法的上下文对象具有以下 API 可以被使用。有关上下文的更多信息，请查看 Request Context。</description></item><item><title>json_indexing</title><link>/gateway/main/zh/docs/references/processors/json_indexing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/json_indexing/</guid><description>json_indexing # 描述 # json_indexing 处理器用来消费队列里面的纯 JSON 文档，并保存到指定的 Elasticsearch 服务器里面。
配置示例 # 一个简单的示例如下：
pipeline: - name: request_logging_index auto_start: true keep_running: true processor: - json_indexing: index_name: &amp;quot;gateway_requests&amp;quot; elasticsearch: &amp;quot;dev&amp;quot; input_queue: &amp;quot;request_logging&amp;quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 参数说明 # 名称 类型 说明 input_queue string 订阅的队列名称 worker_size int 并行执行消费任务的线程数，默认 1 idle_timeout_in_seconds int 消费队列的超时时间，默认 5，单位秒 bulk_size_in_kb int 批次请求的单位大小，单位 KB bulk_size_in_mb int 批次请求的单位大小，单位 MB elasticsearch string 保存到目标集群的名称 index_name string 保存到目标集群的索引名称 type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc</description></item><item><title>ldap_auth</title><link>/gateway/main/zh/docs/references/filters/ldap_auth/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/ldap_auth/</guid><description>ldap_auth # 描述 # ldap_auth 过滤器用来设置基于 LDAP 的身份认证。
配置示例 # 一个简单的示例如下：
flow: - name: ldap_auth filter: - ldap_auth: host: &amp;quot;ldap.forumsys.com&amp;quot; port: 389 bind_dn: &amp;quot;cn=read-only-admin,dc=example,dc=com&amp;quot; bind_password: &amp;quot;password&amp;quot; base_dn: &amp;quot;dc=example,dc=com&amp;quot; user_filter: &amp;quot;(uid=%s)&amp;quot; 上面的配置使用的是在线的免费 LDAP 测试服务器，测试用户 tesla，密码 password。
➜ curl http://127.0.0.1:8000/ -u tesla:password { &amp;quot;name&amp;quot; : &amp;quot;192.168.3.7&amp;quot;, &amp;quot;cluster_name&amp;quot; : &amp;quot;elasticsearch&amp;quot;, &amp;quot;cluster_uuid&amp;quot; : &amp;quot;ZGTwWtBfSLWRpsS1VKQDiQ&amp;quot;, &amp;quot;version&amp;quot; : { &amp;quot;number&amp;quot; : &amp;quot;7.8.0&amp;quot;, &amp;quot;build_flavor&amp;quot; : &amp;quot;default&amp;quot;, &amp;quot;build_type&amp;quot; : &amp;quot;tar&amp;quot;, &amp;quot;build_hash&amp;quot; : &amp;quot;757314695644ea9a1dc2fecd26d1a43856725e65&amp;quot;, &amp;quot;build_date&amp;quot; : &amp;quot;2020-06-14T19:35:50.</description></item><item><title>logging</title><link>/gateway/main/zh/docs/references/filters/logging/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/logging/</guid><description>logging # 描述 # logging 过滤器用来按请求记录下来，通过异步记录到本地磁盘的方式，尽可能降低对请求的延迟影响，对于流量很大的场景，建议配合其它请求过滤器来降低日志的总量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - logging: queue_name: request_logging 记录的请求日志样例如下：
{ &amp;quot;_index&amp;quot; : &amp;quot;gateway_requests&amp;quot;, &amp;quot;_type&amp;quot; : &amp;quot;doc&amp;quot;, &amp;quot;_id&amp;quot; : &amp;quot;EH5bG3gBsbC2s3iWFzCF&amp;quot;, &amp;quot;_score&amp;quot; : 1.0, &amp;quot;_source&amp;quot; : { &amp;quot;tls&amp;quot; : false, &amp;quot;@timestamp&amp;quot; : &amp;quot;2021-03-10T08:57:30.645Z&amp;quot;, &amp;quot;conn_time&amp;quot; : &amp;quot;2021-03-10T08:57:30.635Z&amp;quot;, &amp;quot;flow&amp;quot; : { &amp;quot;from&amp;quot; : &amp;quot;127.0.0.1&amp;quot;, &amp;quot;process&amp;quot; : [ &amp;quot;request_body_regex_replace&amp;quot;, &amp;quot;get_cache&amp;quot;, &amp;quot;date_range_precision_tuning&amp;quot;, &amp;quot;get_cache&amp;quot;, &amp;quot;elasticsearch&amp;quot;, &amp;quot;set_cache&amp;quot;, &amp;quot;||&amp;quot;, &amp;quot;request_logging&amp;quot; ], &amp;quot;relay&amp;quot; : &amp;quot;192.168.43.101-Quartz&amp;quot;, &amp;quot;to&amp;quot; : [ &amp;quot;localhost:9200&amp;quot; ] }, &amp;quot;id&amp;quot; : 3, &amp;quot;local_ip&amp;quot; : &amp;quot;127.</description></item><item><title>merge_to_bulk</title><link>/gateway/main/zh/docs/references/processors/merge_to_bulk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/merge_to_bulk/</guid><description>merge_to_bulk # 描述 # merge_to_bulk 处理器用来消费队列里面的纯 JSON 文档，并合并成 Bulk 请求保存到指定的队列里面，需要配合 consumer 处理器进行消费，用批量写入代替单次请求来提高写入吞吐。
配置示例 # 一个简单的示例如下：
pipeline: - name: messages_merge_async_bulk_results auto_start: true keep_running: true singleton: true processor: - consumer: queue_selector: keys: - bulk_result_messages consumer: group: merge_to_bulk processor: - merge_to_bulk: elasticsearch: &amp;quot;logging&amp;quot; index_name: &amp;quot;.infini_async_bulk_results&amp;quot; output_queue: name: &amp;quot;merged_async_bulk_results&amp;quot; label: tag: &amp;quot;bulk_logging&amp;quot; worker_size: 1 bulk_size_in_mb: 10 参数说明 # 名称 类型 说明 message_field string 从队列获取到的消息，存放到上下文的字段名称, 默认 messages bulk_size_in_kb int 批次请求的单位大小，单位 KB bulk_size_in_mb int 批次请求的单位大小，单位 MB，默认 10 elasticsearch string 保存到目标集群的名称 index_name string 保存到目标集群的索引名称 type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc output_queue.</description></item><item><title>queue</title><link>/gateway/main/zh/docs/references/filters/queue/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/queue/</guid><description>queue # 描述 # queue 过滤器用来保存请求到消息队列。
配置示例 # 一个简单的示例如下：
flow: - name: queue filter: - queue: #handle dirty_writes, second-commit queue_name: &amp;quot;primary_final_commit_log##$[[partition_id]]&amp;quot; labels: type: &amp;quot;primary_final_commit_log&amp;quot; partition_id: &amp;quot;$[[partition_id]]&amp;quot; message: &amp;quot;$[[_ctx.request.header.X-Replicated-ID]]#$[[_ctx.request.header.LAST_PRODUCED_MESSAGE_OFFSET]]#$[[_sys.unix_timestamp_of_now]]&amp;quot; when: equals: _ctx.request.header.X-Replicated: &amp;quot;true&amp;quot; 参数说明 # 名称 类型 说明 depth_threshold int 大于队列指定深度才能存入队列，默认为 0 type string 指定消息队列的类型，支持 kafka 和 disk queue_name string 消息队列名称 labels map 给新增的消息队列 Topic 添加自定义的标签 message string 自定义消息内容，支持变量 save_last_produced_message_offset bool 是否保留最后一次写入成功的消息的 Offset 到上下文中，可以作为变量随后使用 last_produced_message_offset_key string 自定义最后一次写入成功的消息的 Offset 保留到上下文中的变量名，默认 LAST_PRODUCED_MESSAGE_OFFSET</description></item><item><title>queue_consumer</title><link>/gateway/main/zh/docs/references/processors/queue_consumer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/queue_consumer/</guid><description>queue_consumer # 描述 # queue_consumer 处理器用来异步消费队列里面的请求到 Elasticsearch。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - queue_consumer: input_queue: &amp;quot;backup&amp;quot; elasticsearch: &amp;quot;backup&amp;quot; waiting_after: [ &amp;quot;backup_failure_requests&amp;quot;] worker_size: 20 when: cluster_available: [ &amp;quot;backup&amp;quot; ] 参数说明 # 名称 类型 说明 input_queue string 订阅的队列名称 worker_size int 并行执行消费任务的线程数，默认 1 idle_timeout_in_seconds int 消费队列的超时时间，默认 1 elasticsearch string 保存到目标集群的名称 waiting_after array 需要先等将这些指定队列消费完才能开始消费主队列里面的数据 failure_queue string 因为后端故障执行失败的请求，默认为 %input_queue%-failure invalid_queue string 状态码返回为 4xx 的请求，默认为 %input_queue%-invalid compress bool 是否压缩请求，默认 false safety_parse bool 是否启用安全解析，即不采用 buffer 的方式，占用内存更高一点，默认为 true doc_buffer_size bool 单次请求处理的最大文档 buff size，建议设置超过单个文档的最大大小，默认 256*1024</description></item><item><title>ratio</title><link>/gateway/main/zh/docs/references/filters/ratio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/ratio/</guid><description>ratio # 描述 # ratio 过滤器用来将正常的流量按照比例迁移转发到另外的一个处理流程，可以实现灰度发布、流量迁移导出，或者将部分流量切换到不同版本集群用于测试的能力。
配置示例 # 一个简单的示例如下：
flow: - name: ratio_traffic_forward filter: - ratio: ratio: 0.1 flow: hello_world continue: true 参数说明 # 名称 类型 说明 ratio float 需要迁移的流量比例 action string 当命中之后的行为，可以为 drop 或 redirect_flow，默认 redirect_flow flow string 指定新的流量处理流程 continue bool 流量迁移出去之后，是否还继续执行之前的既定流程，设置成 false 则立即返回，默认 false。</description></item><item><title>record</title><link>/gateway/main/zh/docs/references/filters/record/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/record/</guid><description>record # 描述 # record 过滤器是一个记录请求的过滤器，输出的请求可以直接复制到 Kibana 的 Console 中用于调试。
配置示例 # 一个简单的示例如下：
flow: - name: request_logging filter: - record: stdout: true filename: requests.txt record 过滤器输出的请求日志，格式示例如下：
GET /_cluster/state/version,master_node,routing_table,metadata/* GET /_alias GET /_cluster/health GET /_cluster/stats GET /_nodes/0NSvaoOGRs2VIeLv3lLpmA/stats 参数说明 # 名称 类型 说明 filename string 录制请求日志在 data 目录下保存的文件名 stdout bool 是否在终端也打印输出，默认为 false</description></item><item><title>redirect</title><link>/gateway/main/zh/docs/references/filters/redirect/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/redirect/</guid><description>redirect # 描述 # redirect 过滤器用来跳转到一个指定的 URL。
配置示例 # 一个简单的示例如下：
flow: - name: redirect filter: - redirect: uri: https://infinilabs.com 参数说明 # 名称 类型 说明 uri string 需要跳转的完整目标 URI 地址 code int 状态码设置，默认 302</description></item><item><title>redis_pubsub</title><link>/gateway/main/zh/docs/references/filters/redis_pubsub/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/redis_pubsub/</guid><description>redis_pubsub # 描述 # reids 过滤器用来将收到的请求和响应结果保存到 Redis 消息队列中。
配置示例 # 一个简单的示例如下：
flow: - name: redis_pubsub filter: - redis_pubsub: host: 127.0.0.1 port: 6379 channel: gateway response: true 参数说明 # 名称 类型 说明 host string Reids 主机名，默认 localhost port int Reids 端口号，默认为 6379 password string Redis 密码 db int Redis 默认选择的数据库，默认为 0 channel string Redis 消息队列名称，必填，没有默认值 response bool 是否包含响应结果，默认为 true</description></item><item><title>replay</title><link>/gateway/main/zh/docs/references/processors/replay/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/replay/</guid><description>replay # 描述 # replay 处理器用来重放 record 过滤器记录的请求。
配置示例 # 一个简单的示例如下：
pipeline: - name: play_requests auto_start: true keep_running: false processor: - replay: filename: requests.txt schema: &amp;quot;http&amp;quot; host: &amp;quot;localhost:8000&amp;quot; 参数说明 # 名称 类型 说明 filename string 包含重放消息的文件名称 schema string 请求协议类型，http 或 https host string 接受请求的目标服务器，格式 host:port</description></item><item><title>request_api_key_filter</title><link>/gateway/main/zh/docs/references/filters/request_api_key_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_api_key_filter/</guid><description>request_api_key_filter # 描述 # 当 Elasticsearch 是通过 API Key 方式来进行身份认证的时候，request_api_key_filter 过滤器可用来按请求的 API ID 来进行过滤。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_api_key_filter: message: &amp;quot;Request filtered!&amp;quot; exclude: - VuaCfGcBCdbkQm-e5aOx 上面的例子表示，来自 VuaCfGcBCdbkQm-e5aOx 的请求会被拒绝，如下。
➜ ~ curl localhost:8000 -H &amp;quot;Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw==&amp;quot; -v * Rebuilt URL to: localhost:8000/ * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) &amp;gt; GET / HTTP/1.1 &amp;gt; Host: localhost:8000 &amp;gt; User-Agent: curl/7.</description></item><item><title>request_api_key_limiter</title><link>/gateway/main/zh/docs/references/filters/request_api_key_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_api_key_limiter/</guid><description>request_api_key_limiter # 描述 # request_api_key_limiter 过滤器用来按照 API Key 来进行限速。
配置示例 # 配置示例如下：
flow: - name: rate_limit_flow filter: - request_api_key_limiter: id: - VuaCfGcBCdbkQm-e5aOx max_requests: 1 action: drop # retry or drop message: &amp;quot;your api_key reached our limit&amp;quot; 上面的配置中，对 VuaCfGcBCdbkQm-e5aOx 这个 API ID 进行限速，允许的最大 qps 为 1 每秒。
➜ ~ curl localhost:8000 -H &amp;quot;Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw==&amp;quot; -v * Rebuilt URL to: localhost:8000/ * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.</description></item><item><title>request_body_json_del</title><link>/gateway/main/zh/docs/references/filters/request_body_json_del/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_body_json_del/</guid><description>request_body_json_del # 描述 # request_body_json_del 过滤器用来删除 JSON 格式的请求体里面的部分字段。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_body_json_del: path: - query.bool.should.[0] - query.bool.must 参数说明 # 名称 类型 说明 path array 需要删除的 JSON PATH 键值 ignore_missing bool 如果这个 JSON Path 不存在，是否忽略处理，默认 false</description></item><item><title>request_body_json_set</title><link>/gateway/main/zh/docs/references/filters/request_body_json_set/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_body_json_set/</guid><description>request_body_json_set # 描述 # request_body_json_set 过滤器用来修改 JSON 格式的请求体。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_body_json_set: path: - aggs.total_num.terms.field -&amp;gt; &amp;quot;name&amp;quot; - aggs.total_num.terms.size -&amp;gt; 3 - size -&amp;gt; 0 参数说明 # 名称 类型 说明 path map 使用 -&amp;gt; 作为标识符的键值对， JSON PATH 和需要替换的值 ignore_missing bool 如果这个 JSON Path 不存在，是否忽略处理，默认 false</description></item><item><title>request_body_regex_replace</title><link>/gateway/main/zh/docs/references/filters/request_body_regex_replace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_body_regex_replace/</guid><description>request_body_regex_replace # 描述 # request_body_regex_replace 过滤器使用正则表达式来替换请求体正文的字符串内容。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_body_regex_replace: pattern: '&amp;quot;size&amp;quot;: 10000' to: '&amp;quot;size&amp;quot;: 100' - elasticsearch: elasticsearch: prod - dump: request: true 上面的示例将会替换发送给 Elasticsearch 请求体里面，size 设置为 10000 的部分修改为 100，可以用来动态修复错误或者不合理的查询。
测试如下：
curl -XPOST &amp;quot;http://localhost:8000/myindex/_search&amp;quot; -H 'Content-Type: application/json' -d' { &amp;quot;query&amp;quot;: { &amp;quot;match_all&amp;quot;: {} },&amp;quot;size&amp;quot;: 10000 }' 实际发生的查询：
{ &amp;quot;_index&amp;quot; : &amp;quot;gateway_requests&amp;quot;, &amp;quot;_type&amp;quot; : &amp;quot;doc&amp;quot;, &amp;quot;_id&amp;quot; : &amp;quot;EH5bG3gBsbC2s3iWFzCF&amp;quot;, &amp;quot;_score&amp;quot; : 1.</description></item><item><title>request_client_ip_filter</title><link>/gateway/main/zh/docs/references/filters/request_client_ip_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_client_ip_filter/</guid><description>request_client_ip_filter # 描述 # request_client_ip_filter 过滤器用来按请求的来源用户 IP 信息来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_client_ip_filter: exclude: - 192.168.3.67 上面的例子表示，来自 192.168.3.67 的请求不允许通过。
路由跳转的例子:
flow: - name: echo filter: - echo: message: hello stanger - name: default_flow filter: - request_client_ip_filter: action: redirect_flow flow: echo exclude: - 192.168.3.67 来自 192.168.3.67 会跳转到另外的 echo 流程。
参数说明 # 名称 类型 说明 exclude array 拒绝通过的请求 IP 数组列表 include array 允许通过的请求 IP 数组列表 action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>request_client_ip_limiter</title><link>/gateway/main/zh/docs/references/filters/request_client_ip_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_client_ip_limiter/</guid><description>request_client_ip_limiter # 描述 # request_client_ip_limiter 过滤器用来按照请求客户端 IP 来进行限速。
配置示例 # 配置示例如下：
flow: - name: rate_limit_flow filter: - request_client_ip_limiter: ip: #only limit for specify ips - 127.0.0.1 max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: &amp;quot;your ip reached our limit&amp;quot; 上面的配置中，对 127.0.0.1 这个 IP 进行限速，允许的最大 qps 为 256。
参数说明 # 名称 类型 说明 ip array 设置哪些客户端 IP 会参与限速，不设置表示所有 IP 参与 interval string 评估限速的单位时间间隔，默认为 1s max_requests int 单位间隔内最大的请求次数限额 burst_requests int 单位间隔内极限允许的请求次数 max_bytes int 单位间隔内最大的请求流量限额 burst_bytes int 单位间隔内极限允许的流量限额 action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry status string 设置达到限速条件的返回状态码，默认 429 message string 设置达到限速条件的请求的拒绝返回消息 retry_delay_in_ms int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒 max_retry_times int 限速重试的最大重试次数，默认 1000 failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息 log_warn_message bool 是否输出警告消息到日志</description></item><item><title>request_header_filter</title><link>/gateway/main/zh/docs/references/filters/request_header_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_header_filter/</guid><description>request_header_filter # 描述 # request_header_filter 过滤器用来按请求的 Header 信息来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_header_filter: include: - TRACE: true 上面的例子表示，当 Header 里面包含 TRACE: true 的请求才被允许通过。
curl 192.168.3.4:8000 -v -H 'TRACE: true' 参数说明 # 名称 类型 说明 exclude array 拒绝通过的请求 Header 信息 include array 允许通过的请求 Header 信息 action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>request_host_filter</title><link>/gateway/main/zh/docs/references/filters/request_host_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_host_filter/</guid><description>request_host_filter # 描述 # request_host_filter 过滤器主要用来按照指定的域名或者主机名来进行请求过滤，适合只有一个 IP 多个域名需要进行域名访问控制的场景。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_host_filter: include: - domain-test2.com:8000 上面的例子表示，只有访问的是这个域名 domain-test2.com:8000 的请求才被允许通过。
示例如下： # ✗ curl -k -u user:passwd http://domain-test4.com:8000/ -v * Trying 192.168.3.67... * TCP_NODELAY set * Connected to domain-test4.com (192.168.3.67) port 8000 (#0) * Server auth using Basic with user 'medcl' &amp;gt; GET / HTTP/1.1 &amp;gt; Host: domain-test4.com:8000 &amp;gt; Authorization: Basic 123= &amp;gt; User-Agent: curl/7.</description></item><item><title>request_host_limiter</title><link>/gateway/main/zh/docs/references/filters/request_host_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_host_limiter/</guid><description>request_host_limiter # 描述 # request_host_limiter 过滤器用来按照请求主机（域名）来进行限速。
配置示例 # 配置示例如下：
flow: - name: rate_limit_flow filter: - request_host_limiter: host: - api.elasticsearch.cn:8000 - logging.elasticsearch.cn:8000 max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: &amp;quot;you reached our limit&amp;quot; 上面的配置中，对 api.elasticsearch.cn 和 logging.elasticsearch.cn 这两个访问域名进行限速，允许的最大 qps 为 256 每秒。
参数说明 # 名称 类型 说明 host array 设置哪些主机域名会参与限速，不设置表示都参与，注意，如果访问的域名带端口号，这里也需包含端口号，如 localhost:8080 interval string 评估限速的单位时间间隔，默认为 1s max_requests int 单位间隔内最大的请求次数限额 burst_requests int 单位间隔内极限允许的请求次数 max_bytes int 单位间隔内最大的请求流量限额 burst_bytes int 单位间隔内极限允许的流量限额 action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry status string 设置达到限速条件的返回状态码，默认 429 message string 设置达到限速条件的请求的拒绝返回消息 retry_delay_in_ms int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒 max_retry_times int 限速重试的最大重试次数，默认 1000 failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息 log_warn_message bool 是否输出警告消息到日志</description></item><item><title>request_method_filter</title><link>/gateway/main/zh/docs/references/filters/request_method_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_method_filter/</guid><description>request_method_filter # 描述 # request_method_filter 过滤器用来按请求 Method 来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_method_filter: exclude: - PUT - POST include: - GET - HEAD - DELETE 参数说明 # 名称 类型 说明 exclude array 拒绝通过的请求 Method include array 允许通过的请求 Method action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>request_path_filter</title><link>/gateway/main/zh/docs/references/filters/request_path_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_path_filter/</guid><description>request_path_filter # 描述 # request_path_filter 过滤器用来按请求的 Path 路径来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_path_filter: must: #must match all rules to continue prefix: - /medcl contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\w]+dcl must_not: # any match will be filtered prefix: - /.kibana - /_security - /_security - /gateway_requests* - /.reporting - /_monitoring/bulk contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\w]+dcl should: prefix: - /medcl contain: - _search - _async_search suffix: - _refresh wildcard: - /*/_refresh regex: - ^/m[\w]+dcl 参数说明 # 名称 类型 说明 must.</description></item><item><title>request_path_limiter</title><link>/gateway/main/zh/docs/references/filters/request_path_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_path_limiter/</guid><description>request_path_limiter # 描述 # request_path_limiter 过滤器用来定义请求的限速规则，可以实现索引级别的限速。
配置示例 # 配置示例如下：
flow: - name: rate_limit_flow filter: - request_path_limiter: message: &amp;quot;Hey, You just reached our request limit!&amp;quot; rules: - pattern: &amp;quot;/(?P&amp;lt;index_name&amp;gt;medcl)/_search&amp;quot; max_qps: 3 group: index_name - pattern: &amp;quot;/(?P&amp;lt;index_name&amp;gt;.*?)/_search&amp;quot; max_qps: 100 group: index_name 上面的配置中，对 medcl 这个索引执行查询，允许的最大 qps 为 3，而对其它的索引执行查询的 qps 为 100。
参数说明 # 名称 类型 说明 message string 设置达到限速条件的请求的返回消息 rules array 设置限速的策略，支持多种规则，按照配置的先后顺序处理，先匹配的先执行 rules.</description></item><item><title>request_reshuffle</title><link>/gateway/main/zh/docs/references/filters/request_reshuffle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_reshuffle/</guid><description>request_reshuffle # 描述 # request_reshuffle 可以分析 Elasticsearch 的非批次请求，归档存储在队列中，通过先落地存储，业务端请求可以快速返回，从而解耦前端写入和后端 Elasticsearch 集群。request_reshuffle 需要离线管道消费任务来配合使用。
配置示例 # 一个简单的示例如下：
flow: - name: backup-flow-request-reshuffle filter: - flow: flows: - set-auth-for-backup-flow - request_reshuffle: #reshuffle none-bulk requests elasticsearch: &amp;quot;backup&amp;quot; queue_name_prefix: &amp;quot;request_reshuffle&amp;quot; partition_size: $[[env.REQUEST_RESHUFFLE_PARTITION_SIZE]] tag_on_success: [ &amp;quot;commit_message_allowed&amp;quot; ] 参数说明 # 名称 类型 说明 elasticsearch string Elasticsearch 集群实例名称 queue_name_prefix string 队列的名称前缀，默认为 async_bulk ，默认的 Label type:request_reshuffle partition_size int 在 level 的基础上，会再次基于文档 _id 进行分区，通过此参数可以设置最大的分区大小 continue_after_reshuffle bool 执行完 Reshuffle 之后是否继续后续的流程，默认 false tag_on_success array 将所有 bulk 请求处理完成之后，请求上下文打上指定标记</description></item><item><title>request_user_filter</title><link>/gateway/main/zh/docs/references/filters/request_user_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_user_filter/</guid><description>request_user_filter # 描述 # 当 Elasticsearch 是通过 Basic Auth 方式来进行身份认证的时候，request_user_filter 过滤器可用来按请求的用户名信息来进行过滤。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_user_filter: include: - &amp;quot;elastic&amp;quot; 上面的例子表示，只有来自 elastic 的请求才被允许通过。
参数说明 # 名称 类型 说明 exclude array 拒绝通过的请求的用户名列表 include array 允许通过的请求的用户名列表 action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>request_user_limiter</title><link>/gateway/main/zh/docs/references/filters/request_user_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/request_user_limiter/</guid><description>request_user_limiter # 描述 # request_user_limiter 过滤器用来按照用户名来进行限速。
配置示例 # 配置示例如下：
flow: - name: rate_limit_flow filter: - request_user_limiter: user: - elastic - medcl max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: &amp;quot;you reached our limit&amp;quot; 上面的配置中，对 medcl 和 elastic 这两个用户进行限速，允许的最大 qps 为 256 每秒。
参数说明 # 名称 类型 说明 user array 设置哪些用户会参与限速，不设置表示所有用户参与 interval string 评估限速的单位时间间隔，默认为 1s max_requests int 单位间隔内最大的请求次数限额 burst_requests int 单位间隔内极限允许的请求次数 max_bytes int 单位间隔内最大的请求流量限额 burst_bytes int 单位间隔内极限允许的流量限额 action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry status string 设置达到限速条件的返回状态码，默认 429 message string 设置达到限速条件的请求的拒绝返回消息 retry_delay_in_ms int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒 max_retry_times int 限速重试的最大重试次数，默认 1000 failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息 log_warn_message bool 是否输出警告消息到日志</description></item><item><title>response_body_regex_replace</title><link>/gateway/main/zh/docs/references/filters/response_body_regex_replace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/response_body_regex_replace/</guid><description>response_body_regex_replace # 描述 # response_body_regex_replace 过滤器使用正则表达式来替换请求响应内容的字符串。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - echo: message: &amp;quot;hello infini\n&amp;quot; - response_body_regex_replace: pattern: infini to: world 上面的结果输出为 hello world。
参数说明 # 名称 类型 说明 pattern string 用于匹配替换的正则表达式 to string 替换为目标的字符串内容</description></item><item><title>response_header_filter</title><link>/gateway/main/zh/docs/references/filters/response_header_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/response_header_filter/</guid><description>response_header_filter # 描述 # response_header_filter 过滤器用来按请求响应的 Header 信息来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: ... - response_header_filter: exclude: - INFINI-CACHE: CACHED 上面的例子表示，当 Header 信息里面出现 INFINI-CACHE: CACHED 的请求不允许通过。
参数说明 # 名称 类型 说明 exclude array 拒绝通过的响应 Header 信息 include array 允许通过的响应 Header 信息 action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>response_header_format</title><link>/gateway/main/zh/docs/references/filters/response_header_format/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/response_header_format/</guid><description>response_header_format # 描述 # response_header_format 过滤器用来将请求响应的 Header 信息里面的 Key 都转换成小写。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - response_header_format:</description></item><item><title>response_status_filter</title><link>/gateway/main/zh/docs/references/filters/response_status_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/response_status_filter/</guid><description>response_status_filter # 描述 # response_status_filter 过滤器用来按后端服务响应的状态码来进行过滤。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - response_status_filter: message: &amp;quot;Request filtered!&amp;quot; exclude: - 404 include: - 200 - 201 - 500 参数说明 # 名称 类型 说明 exclude array 拒绝通过的响应码 include array 允许通过的响应码 action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>retry_limiter</title><link>/gateway/main/zh/docs/references/filters/retry_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/retry_limiter/</guid><description>retry_limiter # 描述 # retry_limiter 过滤器用来判断一个请求是否达到最大重试次数，避免一个请求的无限重试。
配置示例 # 一个简单的示例如下：
flow: - name: retry_limiter filter: - retry_limiter: queue_name: &amp;quot;deadlock_messages&amp;quot; max_retry_times: 3 参数说明 # 名称 类型 说明 max_retry_times int 最大重试次数，默认为 3 queue_name string 达到重试最大次数后，输出消息到指定消息队列的名称 tag_on_success array 触发重试条件之后，请求上下文打上指定标记</description></item><item><title>rewrite_to_bulk</title><link>/gateway/main/zh/docs/references/filters/rewrite_to_bulk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/rewrite_to_bulk/</guid><description>rewrite_to_bulk # 描述 # rewrite_to_bulk 可以分析 Elasticsearch 的普通文档创建和修改操作并改写为 Bulk 批次请求。
配置示例 # 一个简单的示例如下：
flow: - name: replicate-primary-writes-to-backup-queue filter: - flow: flows: - set-auth-for-backup-flow - rewrite_to_bulk: #rewrite docs create/update/delete operation to bulk request - bulk_reshuffle: #handle bulk requests when: contains: _ctx.request.path: /_bulk elasticsearch: &amp;quot;backup&amp;quot; queue_name_prefix: &amp;quot;async_bulk&amp;quot; level: cluster #cluster,node,index,shard partition_size: 10 fix_null_id: true - queue: #handle none-bulk requests&amp;lt;1. send to none-bulk queue&amp;gt; queue_name: &amp;quot;backup&amp;quot; 参数说明 # 名称 类型 说明 auto_generate_doc_id bool 如果是创建操作，并且没有指定文档 ID，是否自动生成文档 ID，默认 true prefix string 给 UUID 增加一个固定前缀 type_removed bool 新版本 ES 移除了 _type 类型，这个参数用来避免在 Bulk 请求元数据添加类型参数</description></item><item><title>sample</title><link>/gateway/main/zh/docs/references/filters/sample/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/sample/</guid><description>sample # 描述 # sample 过滤器用来将正常的流量按照比例采样，对于海量查询的场景，全流量收集日志需要耗费大量的资源，可以考虑进行抽样统计，对查询日志进行采样分析。
配置示例 # 一个简单的示例如下：
flow: - name: sample filter: - sample: ratio: 0.2 参数说明 # 名称 类型 说明 ratio float 采样比例</description></item><item><title>security</title><link>/gateway/main/zh/docs/references/filters/security/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/security/</guid><description>security # 描述 # security 过滤器用来对请求的 API 进行安全过滤，结合 Console 来进行统一的身份管理，包括鉴权和授权的集中化管控，同时支持与 LDAP 的身份集成。
配置示例 # 一个简单的示例如下：
flow: - name: security_request filter: - security: elasticsearch: es-server - elasticsearch: elasticsearch: es-server elastic: elasticsearch: es-server remote_configs: true health_check: enabled: false availability_check: enabled: false orm: enabled: true init_template: false init_schema: true index_prefix: &amp;quot;.infini_&amp;quot; elasticsearch: - name: es-server enabled: true endpoints: - http://127.0.0.1:9200 security: enabled: true authc: realms: ldap: # test: #setup guide: https://github.</description></item><item><title>set_basic_auth</title><link>/gateway/main/zh/docs/references/filters/set_basic_auth/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/set_basic_auth/</guid><description>set_basic_auth # 描述 # set_basic_auth 过滤器用来设置请求的身份认证信息，可以用于重置请求的身份信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_basic_auth filter: - set_basic_auth: username: admin password: password 参数说明 # 名称 类型 说明 username string 用户名 password string 密码</description></item><item><title>set_context</title><link>/gateway/main/zh/docs/references/filters/set_context/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/set_context/</guid><description>set_context # 描述 # set_context 过滤器用来设置请求上下文的相关信息。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - set_response: body: '{&amp;quot;message&amp;quot;:&amp;quot;hello world&amp;quot;}' - set_context: context: # _ctx.request.uri: http://baidu.com # _ctx.request.path: new_request_path # _ctx.request.host: api.infinilabs.com # _ctx.request.method: DELETE # _ctx.request.body: &amp;quot;hello world&amp;quot; # _ctx.request.body_json.explain: true # _ctx.request.query_args.from: 100 # _ctx.request.header.ENV: dev # _ctx.response.content_type: &amp;quot;application/json&amp;quot; # _ctx.response.header.TIMES: 100 # _ctx.response.status: 419 # _ctx.response.body: &amp;quot;new_body&amp;quot; _ctx.response.body_json.success: true - dump: request: true 参数说明 # 名称 类型 说明 context map 请求的上下文及对应的新值 支持的上下文变量列表如下：</description></item><item><title>set_hostname</title><link>/gateway/main/zh/docs/references/filters/set_hostname/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/set_hostname/</guid><description>set_hostname # 描述 # set_hostname 过滤器用来设置请求 Header 关于要访问的主机或域名信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_hostname filter: - set_hostname: hostname: api.infini.cloud 为避免
参数说明 # 名称 类型 说明 hostname string 主机信息</description></item><item><title>set_request_header</title><link>/gateway/main/zh/docs/references/filters/set_request_header/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/set_request_header/</guid><description>set_request_header # 描述 # set_request_header 过滤器用来设置请求的 Header 头信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_request_header filter: - set_request_header: headers: - Trial -&amp;gt; true - Department -&amp;gt; Engineering 为避免
参数说明 # 名称 类型 说明 headers map 使用 -&amp;gt; 作为标识符的键值对，用于设置 Header 信息</description></item><item><title>set_request_query_args</title><link>/gateway/main/zh/docs/references/filters/set_request_query_args/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/set_request_query_args/</guid><description>set_request_query_args # 描述 # set_request_query_args 过滤器用来设置请求的 QueryString 参数信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_request_query_args filter: - set_request_query_args: args: - size -&amp;gt; 10 为避免
参数说明 # 名称 类型 说明 args map 使用 -&amp;gt; 作为标识符的键值对，用于设置 QueryString 参数信息</description></item><item><title>set_response</title><link>/gateway/main/zh/docs/references/filters/set_response/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/set_response/</guid><description>set_response # 描述 # set_response 过滤器用来设置请求响应返回信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_response filter: - set_response: status: 200 content_type: application/json body: '{&amp;quot;message&amp;quot;:&amp;quot;hello world&amp;quot;}' 参数说明 # 名称 类型 说明 status int 请求状态码，默认 200 content_type string 设置请求返回的内容类型 body string 设置请求返回的结构体</description></item><item><title>set_response_header</title><link>/gateway/main/zh/docs/references/filters/set_response_header/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/set_response_header/</guid><description>set_response_header # 描述 # set_response_header 过滤器用来设置请求响应的 Header 头信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_response_header filter: - set_response_header: headers: - Trial -&amp;gt; true - Department -&amp;gt; Engineering 参数说明 # 名称 类型 说明 headers map 使用 -&amp;gt; 作为标识符的键值对，用于设置 Header 信息</description></item><item><title>sleep</title><link>/gateway/main/zh/docs/references/filters/sleep/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/sleep/</guid><description>sleep # 描述 # sleep 过滤器用来添加一个固定的延迟到请求，可以人为降速。
配置示例 # 一个简单的示例如下：
flow: - name: slow_query_logging_test filter: - sleep: sleep_in_million_seconds: 1024 参数说明 # 名称 类型 说明 sleep_in_million_seconds int64 需要添加的延迟长度，单位为毫秒</description></item><item><title>smtp</title><link>/gateway/main/zh/docs/references/processors/smtp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/processors/smtp/</guid><description>smtp # 描述 # smtp 处理器用来发送邮件，支持普通的文本邮件和 HTML 邮件，支持模版变量，支持附件嵌入到邮件正文，邮件的消息来自上下文。
配置示例 # 一个简单的示例如下：
pipeline: - name: send_email auto_start: true keep_running: true retry_delay_in_ms: 5000 processor: - consumer: consumer: fetch_max_messages: 1 max_worker_size: 200 num_of_slices: 1 idle_timeout_in_seconds: 30 queue_selector: keys: - email_messages processor: - smtp: idle_timeout_in_seconds: 1 server: host: &amp;quot;smtp.ym.163.com&amp;quot; port: 994 tls: true auth: username: &amp;quot;notify-test@infini.ltd&amp;quot; password: &amp;quot;xxx&amp;quot; sender: &amp;quot;notify-test@infini.ltd&amp;quot; recipients: # to: [&amp;quot;Test &amp;lt;medcl@infini.ltd&amp;gt;&amp;quot;] # cc: [&amp;quot;INFINI Labs &amp;lt;hello@infini.ltd&amp;gt;&amp;quot;] variables: #default variables, can be used in templates license_code: &amp;quot;N/A&amp;quot; templates: trial_license: subject: &amp;quot;$[[name]] 您好，请查收您的免费授权信息!</description></item><item><title>switch</title><link>/gateway/main/zh/docs/references/filters/switch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/switch/</guid><description>switch # 描述 # switch 过滤器用来将流量按照请求路径转发到另外的一个处理流程，可以方便的实现跨集群操作，且 Elasticsearch 集群不需要做任何修改，且各个集群内所有的 API 都可以访问，包括索引的读写和集群操作。
配置示例 # 一个简单的示例如下：
flow: - name: es1-flow filter: - elasticsearch: elasticsearch: es1 - name: es2-flow filter: - elasticsearch: elasticsearch: es2 - name: cross_cluste_search filter: - switch: path_rules: - prefix: &amp;quot;es1:&amp;quot; flow: es1-flow - prefix: &amp;quot;es2:&amp;quot; flow: es2-flow - elasticsearch: elasticsearch: dev #elasticsearch configure reference name 上面的例子中，以 es1: 开头的索引将转发给集群 es1 集群，以 es2: 开头的索引转发给 es2 集群，不匹配的转发给 dev 集群，在一个 Kibana 里面可以直接操作不同版本的集群了，如下：</description></item><item><title>translog</title><link>/gateway/main/zh/docs/references/filters/translog/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/gateway/main/zh/docs/references/filters/translog/</guid><description>translog # 描述 # translog 过滤器用来将收到的请求保存到本地文件，并压缩存放，可记录部分或完整的请求日志，用于归档和请求重放。
配置示例 # 一个简单的示例如下：
flow: - name: translog filter: - translog: max_file_age: 7 max_file_count: 10 参数说明 # 名称 类型 说明 path string 日志存放根目录，默认为网关数据目录下的 translog 子目录 category string 区分不同日志的二级分类子目录，默认为 default filename string 设置日志的文件名，默认为 translog.log rotate.compress_after_rotate bool 文件滚动之后是否压缩归档，默认为 true rotate.max_file_age int 最多保留的归档文件天数，默认为 30 天 rotate.max_file_count int 最多保留的归档文件个数，默认为 100 个 rotate.</description></item></channel></rss>
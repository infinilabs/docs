<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>字符过滤器（Character Filters） on INFINI Easysearch</title><link>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/</link><description>Recent content in 字符过滤器（Character Filters） on INFINI Easysearch</description><generator>Hugo -- gohugo.io</generator><atom:link href="/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/index.xml" rel="self" type="application/rss+xml"/><item><title>HTML 标签字符过滤器（HTML Strip）</title><link>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/html-strip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/html-strip/</guid><description>HTML Strip 字符过滤器 # html_strip 字符过滤器会从输入文本中移除 HTML 标签（例如 &amp;lt;div&amp;gt;、&amp;lt;p&amp;gt; 和 &amp;lt;a&amp;gt; 等）并输出纯文本。该过滤器可以配置保留某些标签，或者配置把特定的 HTML 标签实体（如 &amp;amp;nbsp;）解码为空格。
相关指南（先读这些） # 文本分析基础 文本分析：识别词元 参考样例 # 以下请求展示将 html_strip 字符过滤器应用于文本：
GET /_analyze { &amp;#34;tokenizer&amp;#34;: &amp;#34;keyword&amp;#34;, &amp;#34;char_filter&amp;#34;: [ &amp;#34;html_strip&amp;#34; ], &amp;#34;text&amp;#34;: &amp;#34;&amp;lt;p&amp;gt;Commonly used calculus symbols include &amp;amp;alpha;, &amp;amp;beta; and &amp;amp;theta; &amp;lt;/p&amp;gt;&amp;#34; } 返回内容中包含的词元里，可以看到 HTML 字符已被转换为它们的解码后的值：
{ &amp;#34;tokens&amp;#34;: [ { &amp;#34;token&amp;#34;: &amp;#34;\nCommonly used calculus symbols include α, β and θ \n&amp;#34;, &amp;#34;start_offset&amp;#34;: 0, &amp;#34;end_offset&amp;#34;: 74, &amp;#34;type&amp;#34;: &amp;#34;word&amp;#34;, &amp;#34;position&amp;#34;: 0 } ] } 参数说明 # html_strip 字符过滤器可以使用以下参数进行配置。</description></item><item><title>映射字符过滤器（Mapping）</title><link>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/mapping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/mapping/</guid><description>Mapping 字符过滤器 # mapping 字符过滤器接受一个用于字符替换的键值对映射。每当该过滤器遇到与某个键匹配的字符串时，它就会用相应的值来替换这些字符。替换值可以是空字符串。
该过滤器采用贪婪匹配方式，这意味着会匹配最长的匹配结果。
在分词过程之前，需要进行特定文本替换的场景下，mapping 字符过滤器会很有帮助。
相关指南（先读这些） # 文本分析基础 文本分析：规范化 参考样例 # 以下请求配置了一个映射字符过滤器，该过滤器可将罗马数字（如 I、II 或 III）转换为对应的阿拉伯数字（1、2 和 3）：
GET /_analyze { &amp;#34;tokenizer&amp;#34;: &amp;#34;keyword&amp;#34;, &amp;#34;char_filter&amp;#34;: [ { &amp;#34;type&amp;#34;: &amp;#34;mapping&amp;#34;, &amp;#34;mappings&amp;#34;: [ &amp;#34;I =&amp;gt; 1&amp;#34;, &amp;#34;II =&amp;gt; 2&amp;#34;, &amp;#34;III =&amp;gt; 3&amp;#34;, &amp;#34;IV =&amp;gt; 4&amp;#34;, &amp;#34;V =&amp;gt; 5&amp;#34; ] } ], &amp;#34;text&amp;#34;: &amp;#34;I have III apples and IV oranges&amp;#34; } 返回内容中包含一个词元，其中罗马数字已被替换为阿拉伯数字：
{ &amp;#34;tokens&amp;#34;: [ { &amp;#34;token&amp;#34;: &amp;#34;1 have 3 apples and 4 oranges&amp;#34;, &amp;#34;start_offset&amp;#34;: 0, &amp;#34;end_offset&amp;#34;: 32, &amp;#34;type&amp;#34;: &amp;#34;word&amp;#34;, &amp;#34;position&amp;#34;: 0 } ] } 参数说明 # 你可以使用以下任意一个参数来配置键值映射。</description></item><item><title>正则替换字符过滤器（Pattern Replace）</title><link>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/pattern-replace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/pattern-replace/</guid><description>Pattern Replace 字符过滤器 # pattern_replace 字符过滤器使你能够使用正则表达式来定义文本匹配替换的模式。对于文本转换的高阶需求场景，尤其是在处理复杂的字符串模式时，它是一种灵活的工具。
这个过滤器会用替换符合匹配模式的所有匹配项，从而可以轻松地对输入文本进行替换、删除或复杂的修改。你可以在分词之前使用它对输入内容进行规范化处理。
相关指南（先读这些） # 文本分析基础 文本分析：规范化 参考样例 # 为了规范电话号码，你可以使用正则表达式 [\\s()-]+去替换号码里的特殊格式：
[]：定义一个字符类，意味着它将匹配方括号内的任意一个字符。 \\s：匹配任何空白字符，如空格、制表符或换行符。 ()：匹配字面意义上的括号（( 或 )）。 -：匹配字面意义上的连字符（-）。 +：指定该模式应匹配前面字符的一次或多次出现。 模式 [\\s()-]+ 将匹配由一个或多个空白字符、括号或连字符组成的任意序列，并将其从输入文本中移除。这确保了电话号码得到规范处理，结果将仅包含数字。
以下请求通过移除空格、连字符和括号来规范电话号码：
GET /_analyze { &amp;#34;tokenizer&amp;#34;: &amp;#34;standard&amp;#34;, &amp;#34;char_filter&amp;#34;: [ { &amp;#34;type&amp;#34;: &amp;#34;pattern_replace&amp;#34;, &amp;#34;pattern&amp;#34;: &amp;#34;[\\s()-]+&amp;#34;, &amp;#34;replacement&amp;#34;: &amp;#34;&amp;#34; } ], &amp;#34;text&amp;#34;: &amp;#34;(555) 123-4567&amp;#34; } 返回内容中包含生成的词元：
{ &amp;#34;tokens&amp;#34;: [ { &amp;#34;token&amp;#34;: &amp;#34;5551234567&amp;#34;, &amp;#34;start_offset&amp;#34;: 1, &amp;#34;end_offset&amp;#34;: 14, &amp;#34;type&amp;#34;: &amp;#34;&amp;lt;NUM&amp;gt;&amp;#34;, &amp;#34;position&amp;#34;: 0 } ] } 参数说明 # pattern_replace 字符过滤器必须使用以下参数进行配置。</description></item><item><title>ICU 归一化字符过滤器（ICU Normalizer）</title><link>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/icu-normalizer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/icu-normalizer/</guid><description>ICU Normalizer 字符过滤器 # icu_normalizer 字符过滤器使用 ICU 库在分词之前对原始文本进行 Unicode 归一化。它可以将字符的多种编码形式统一为标准形式，确保相同的&amp;quot;视觉字符&amp;quot;在搜索时能够匹配。
需要插件：此过滤器由 analysis-icu 插件提供，Easysearch 默认已集成。
与词元过滤器版本的区别 # ICU 插件同时提供了字符过滤器和词元过滤器两个版本：
版本 类型名 处理阶段 适用场景 字符过滤器 icu_normalizer 分词前 需要在分词前统一字符形式 词元过滤器 icu_normalizer 分词后 只需对词元进行归一化 建议：大多数场景使用字符过滤器版本效果更好，因为归一化发生在分词之前，可以避免因字符形式不同导致的分词差异。
参数说明 # 参数 类型 默认值 说明 name String nfkc_cf Unicode 归一化方式，见下方选项 mode String compose 归一化模式：compose（合成）或 decompose（分解） unicode_set_filter String — 可选，ICU UnicodeSet 过滤条件，仅对匹配字符进行归一化 name 可选值 # 值 说明 nfc NFC 标准归一化（合成优先） nfkc NFKC 兼容归一化（合成优先） nfkc_cf 默认值。NFKC 归一化 + Case Folding（大小写折叠） 使用示例 # 基本用法（默认 nfkc_cf） # PUT /my-icu-index { &amp;#34;settings&amp;#34;: { &amp;#34;analysis&amp;#34;: { &amp;#34;analyzer&amp;#34;: { &amp;#34;my_icu_analyzer&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;custom&amp;#34;, &amp;#34;tokenizer&amp;#34;: &amp;#34;standard&amp;#34;, &amp;#34;char_filter&amp;#34;: [&amp;#34;icu_normalizer&amp;#34;] } } } } } 自定义归一化方式 # PUT /my-icu-index { &amp;#34;settings&amp;#34;: { &amp;#34;analysis&amp;#34;: { &amp;#34;char_filter&amp;#34;: { &amp;#34;my_icu_normalizer&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;icu_normalizer&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;nfc&amp;#34;, &amp;#34;mode&amp;#34;: &amp;#34;compose&amp;#34; } }, &amp;#34;analyzer&amp;#34;: { &amp;#34;my_analyzer&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;custom&amp;#34;, &amp;#34;tokenizer&amp;#34;: &amp;#34;standard&amp;#34;, &amp;#34;char_filter&amp;#34;: [&amp;#34;my_icu_normalizer&amp;#34;] } } } } } 测试效果 # GET /_analyze { &amp;#34;tokenizer&amp;#34;: &amp;#34;keyword&amp;#34;, &amp;#34;char_filter&amp;#34;: [&amp;#34;icu_normalizer&amp;#34;], &amp;#34;text&amp;#34;: &amp;#34;Ⅲ ﬁ ℃&amp;#34; } 归一化结果：ⅲ→iii、ﬁ→fi、℃→°c（NFKC 兼容分解 + case folding）。</description></item><item><title>简繁转换字符过滤器（ST Convert）</title><link>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/stconvert/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/features/mapping-and-analysis/text-analysis/character-filters/stconvert/</guid><description>ST Convert 字符过滤器 # stconvert 字符过滤器在分词之前对中文文本进行简体与繁体之间的转换，使简繁体内容在搜索时可以互相匹配。
需要插件：此过滤器由 analysis-stconvert 插件提供，Easysearch 默认已集成。
转换方向 # convert_type 说明 s2t 默认值。简体 → 繁体 t2s 繁体 → 简体 使用示例 # 简体转繁体（默认） # PUT /my-chinese-index { &amp;#34;settings&amp;#34;: { &amp;#34;analysis&amp;#34;: { &amp;#34;analyzer&amp;#34;: { &amp;#34;s2t_analyzer&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;custom&amp;#34;, &amp;#34;tokenizer&amp;#34;: &amp;#34;standard&amp;#34;, &amp;#34;char_filter&amp;#34;: [&amp;#34;stconvert&amp;#34;] } } } } } 繁体转简体 # PUT /my-chinese-index { &amp;#34;settings&amp;#34;: { &amp;#34;analysis&amp;#34;: { &amp;#34;char_filter&amp;#34;: { &amp;#34;t2s_filter&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;stconvert&amp;#34;, &amp;#34;convert_type&amp;#34;: &amp;#34;t2s&amp;#34; } }, &amp;#34;analyzer&amp;#34;: { &amp;#34;t2s_analyzer&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;custom&amp;#34;, &amp;#34;tokenizer&amp;#34;: &amp;#34;standard&amp;#34;, &amp;#34;char_filter&amp;#34;: [&amp;#34;t2s_filter&amp;#34;] } } } } } 测试效果 # GET /_analyze { &amp;#34;tokenizer&amp;#34;: &amp;#34;keyword&amp;#34;, &amp;#34;char_filter&amp;#34;: [ { &amp;#34;type&amp;#34;: &amp;#34;stconvert&amp;#34;, &amp;#34;convert_type&amp;#34;: &amp;#34;t2s&amp;#34; } ], &amp;#34;text&amp;#34;: &amp;#34;國際化標準&amp;#34; } 结果：國際化標準 → 国际化标准</description></item></channel></rss>
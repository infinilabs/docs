<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>基础理论 on INFINI Easysearch (main)</title><link>/easysearch/main/docs/fundamentals/</link><description>Recent content in 基础理论 on INFINI Easysearch (main)</description><generator>Hugo -- gohugo.io</generator><atom:link href="/easysearch/main/docs/fundamentals/index.xml" rel="self" type="application/rss+xml"/><item><title>核心概念</title><link>/easysearch/main/docs/fundamentals/concepts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/concepts/</guid><description>Easysearch 是一个分布式搜索分析引擎，建立在 Apache Lucene 基础之上。本页介绍 Easysearch 的核心概念，帮助你快速建立正确的心智模型。
什么是 Easysearch # Easysearch 是一个高性能的分布式搜索引擎，建立在全文搜索引擎库 Apache Lucene 基础之上。Lucene 可以说是当下最先进、高性能、全功能的搜索引擎库。
但 Lucene 仅仅只是一个库。为了充分发挥其功能，你需要使用 Java 并将 Lucene 直接集成到应用程序中。Easysearch 在此基础上提供了一套简单一致的 RESTful API，使全文检索变得简单。
Easysearch 不仅仅是全文搜索引擎，它可以被准确地形容为：
一个分布式的实时文档存储，每个字段可以被索引与搜索 一个分布式实时分析搜索引擎 能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或非结构化数据 面向文档 # Easysearch 是面向文档（Document-Oriented）的：它存储整个对象或文档，并索引每个文档的内容使之可以被检索。在 Easysearch 中，我们对文档进行索引、检索、排序和过滤——而不是对行列数据。
JSON # Easysearch 使用 JSON 作为文档的序列化格式：
{ &amp;#34;email&amp;#34;: &amp;#34;john@smith.com&amp;#34;, &amp;#34;first_name&amp;#34;: &amp;#34;John&amp;#34;, &amp;#34;last_name&amp;#34;: &amp;#34;Smith&amp;#34;, &amp;#34;info&amp;#34;: { &amp;#34;bio&amp;#34;: &amp;#34;Eco-warrior and defender of the weak&amp;#34;, &amp;#34;age&amp;#34;: 25, &amp;#34;interests&amp;#34;: [ &amp;#34;dolphins&amp;#34;, &amp;#34;whales&amp;#34; ] }, &amp;#34;join_date&amp;#34;: &amp;#34;2014/05/01&amp;#34; } 在 Easysearch 中将对象转化为 JSON 后构建索引，要比在扁平的表结构中简单得多。</description></item><item><title>Lucene 底层原理</title><link>/easysearch/main/docs/fundamentals/lucene-internals/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/lucene-internals/</guid><description>Easysearch 的搜索能力建立在 Apache Lucene 之上。理解 Lucene 的核心概念，有助于更好地使用 Easysearch 和进行性能调优。
Lucene 与 Easysearch 的关系 # 用户请求 → Easysearch (分布式协调、REST API、集群管理) ↓ 每个分片 = 一个 Lucene Index ↓ Lucene (倒排索引、评分、段合并) Easysearch 负责：分布式路由、副本复制、集群管理、REST API、安全 Lucene 负责：文本分析、倒排索引构建、查询执行、评分计算 每个 Easysearch 分片（shard） 对应一个完整的 Lucene Index。
术语对齐：Lucene 的&amp;quot;索引&amp;quot;在 Easysearch 里更接近&amp;quot;分片&amp;quot;；而 Easysearch 的&amp;quot;索引&amp;quot;是多个分片的集合。
倒排索引：全文检索的核心 # 要理解 Easysearch 的搜索行为，必须先回答一个基础问题：文本是怎么变成&amp;quot;可搜索&amp;quot;的？
关系型数据库通常把一个字段当作一个整体来索引；而全文检索需要把一个字段里的每个&amp;quot;词&amp;quot;都变成可检索的索引项。这就需要倒排索引（Inverted Index）——一个天然支持&amp;quot;一个字段对应很多词项&amp;quot;的数据结构。
正排 vs 倒排 # 正排索引（文档 → 词项）：
文档 ID 内容 1 &amp;ldquo;搜索引擎 技术&amp;rdquo; 2 &amp;ldquo;分布式 搜索引擎&amp;rdquo; 倒排索引（词项 → 文档）：</description></item><item><title>分布式基础</title><link>/easysearch/main/docs/fundamentals/distributed/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/distributed/</guid><description>Easysearch 的主旨是随时可用和按需扩容。真正的扩容能力来自于水平扩容——为集群添加更多的节点，并且将负载压力和稳定性分散到这些节点中。Easysearch 天生就是分布式的，它知道如何通过管理多节点来提高扩容性和可用性。
本页通过从 1 节点到 3 节点的演进，直观展示分片分配、故障转移和水平扩容的过程。
空集群 # 启动一个单独的节点，里面不包含任何数据和索引——这就是一个空集群。
此时这个节点既是唯一的数据节点，也是主节点。作为用户，我们可以将请求发送到集群中的任何节点（包括主节点），每个节点都知道任意文档所处的位置，并能将请求直接转发到正确的节点。
集群健康 # Easysearch 的集群监控信息中最重要的一项是集群健康，status 字段展示为 green、yellow 或 red：
GET /_cluster/health 颜色 含义 green 所有的主分片和副本分片都正常运行 yellow 所有的主分片都正常运行，但不是所有的副本分片都正常运行 red 有主分片没能正常运行 添加索引 # 索引是指向一个或者多个物理分片的逻辑命名空间。一个分片是一个底层的工作单元，它本身就是一个完整的搜索引擎（一个 Lucene 实例）。
Easysearch 利用分片将数据分发到集群内各处。当集群规模扩大或缩小时，Easysearch 会自动在各节点间迁移分片，使数据均匀分布。
让我们创建一个名为 blogs 的索引，分配 3 个主分片和 1 份副本：
PUT /blogs { &amp;#34;settings&amp;#34; : { &amp;#34;number_of_shards&amp;#34; : 3, &amp;#34;number_of_replicas&amp;#34; : 1 } } 此时只有一个节点，3 个主分片都分配在该节点上。集群健康状态为 yellow——主分片正常，但 3 个副本分片无处分配（在同一节点上保存原始数据和副本没有意义）。</description></item><item><title>分布式读取写入过程</title><link>/easysearch/main/docs/fundamentals/distributed-write/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/distributed-write/</guid><description>分布式读取写入过程 # Easysearch 隐藏了分布式系统的大部分底层细节，让你可以专注在业务开发上。但线上出问题时你真正需要的是：这条请求在集群里到底走了哪几步。本页把分布式 CRUD 的关键流程串起来，读完你会更容易理解：
为什么同一条数据总能&amp;quot;找到回家的路&amp;quot;（routing） 为什么写入一定要先到主分片（primary） 为什么副本不吃&amp;quot;补丁&amp;quot;，只吃&amp;quot;整份文档&amp;quot;（复制语义） 为什么 bulk 要用看起来奇怪的 NDJSON（性能与内存） 术语提示：你可以把请求发到集群中的任意节点。接收请求并负责&amp;quot;拆分、转发、汇总&amp;quot;的那个节点，称为协调节点（coordinating node）。为了均衡负载，更好的做法是轮询集群中所有节点发送请求。
路由：文档如何找到分片 # 当索引一个文档时，Easysearch 需要确定它属于哪个主分片。这个过程是确定性的，基于以下公式：
shard = hash(routing) % number_of_primary_shards routing 是一个可变值，默认是文档的 _id，也可以设置成一个自定义的值 routing 通过 Murmur3 x86 32-bit 哈希算法（种子为 0）生成一个数字，然后除以主分片数量取余 余数就是文档所在分片的编号（范围 0 到 number_of_primary_shards - 1） 这就解释了为什么主分片数量在索引创建后不能改变：分片数变了，取模结果就变了，所有之前路由的值都会无效，老文档的&amp;quot;地址&amp;quot;全得重算。工程上一般通过新索引 + 重建索引 + 别名切换来实现扩容（见 别名）。
所有的文档 API（get、index、delete、bulk、update、mget）都接受一个 routing 参数。自定义路由常用于&amp;quot;把相关数据放在一起&amp;quot;——例如把同一租户/同一用户的数据路由到同一分片，减少查询时的 fan-out（参见 多租户建模）。
写入流程：新建、索引和删除 # 新建、索引和删除请求都是写操作，必须在主分片上完成之后才能被复制到副本分片。
执行步骤：
客户端向 Node 1（协调节点）发送写入请求 Node 1 使用文档的 _id（或自定义 routing）计算出文档属于分片 0，请求被转发到分片 0 的主分片所在节点（例如 Node 3） Node 3 在主分片上执行请求。成功后，将新版本的完整文档（或删除标记）并行转发到所有副本分片节点 一旦所有副本分片都报告成功，Node 3 向协调节点报告成功，协调节点再向客户端返回成功 在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成。</description></item><item><title>分布式搜索执行过程</title><link>/easysearch/main/docs/fundamentals/distributed-search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/distributed-search/</guid><description>分布式搜索执行过程 # 当你向 Easysearch 发起一个 /_search 请求时，集群内部会发生一系列分布式协作。理解这个过程能帮助你解释很多“看起来奇怪”的现象：为什么分页越深越慢、为什么结果顺序会抖动、为什么加副本能提高吞吐、为什么有时相关性会“不一致”。
在一个典型的搜索执行中，Easysearch 会经历两个阶段：
Query phase（查询阶段）：找出每个分片上的 top-n 候选，并在协调节点合并成全局 top-n Fetch phase（取回阶段）：只取回最终需要返回的那一页文档内容，并做必要的“丰富” Query phase：每个分片产出本地 top-n # 查询阶段会把请求广播到目标索引涉及的每个分片拷贝（主分片或副本分片）。每个分片本地执行查询，并构建一个 优先队列（priority queue），保存本分片的 top-n 匹配结果。
优先队列的大小取决于分页参数：
GET /_search { &amp;#34;from&amp;#34;: 90, &amp;#34;size&amp;#34;: 10 } 这个请求意味着需要找出“第 91～100 条”结果，所以每个分片需要构建长度为 from + size = 100 的优先队列，才有可能保证全局合并后不漏掉候选。
查询阶段（概念流程）：
客户端把 search 请求发给某个节点，该节点成为协调节点 协调节点将请求转发到所有相关分片（主或副本） 每个分片本地执行查询，返回： 文档 ID 排序所需的值（例如 _score，或排序字段的值） 协调节点把所有分片返回的候选合并到全局优先队列，得到“全局有序的 top-(from+size)” 为什么副本能提高吞吐：搜索请求可以由主分片或副本分片处理，副本越多、硬件越多，可并行处理的搜索请求也越多。
Fetch phase：只取回最终需要返回的那一页 # 查询阶段只确定“哪些文档应该在结果里”，但并没有把文档内容取回。取回阶段会：</description></item><item><title>写入与存储机制</title><link>/easysearch/main/docs/fundamentals/write-and-storage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/write-and-storage/</guid><description>当你向 Easysearch 索引一个文档时，数据要经历多个阶段才能最终安全地持久化到磁盘。理解这个过程，有助于你在性能调优和故障恢复时做出正确决策。
写入的全景图 # 一个文档从写入请求到可被搜索再到持久化落盘，大致经历以下阶段：
客户端请求 ↓ 协调节点路由到主分片 ↓ 主分片写入： 1. 追加到 translog（事务日志） 2. 写入内存索引缓冲区（in-memory buffer） ↓ refresh（默认每秒）: - 缓冲区内容写入新的段（segment）到文件系统缓存 - 新段可被搜索（近实时） - 缓冲区清空，translog 保留 ↓ flush（translog 超过 512MB 阈值时触发）: - 段从文件系统缓存 fsync 到磁盘 - 写入提交点（commit point） - translog 清空 ↓ 段合并（后台持续）: - 小段合并为大段 - 清理已删除文档 - 减少段数量，提升搜索性能 下面按阶段逐一展开。
近实时搜索：为什么不是&amp;quot;实时&amp;quot; # Easysearch 被称为 近实时（Near Real-Time, NRT） 搜索引擎——文档写入后并非立刻可搜索，但通常在一秒内就能被检索到。
背后的原因在于：磁盘 I/O 是瓶颈。提交（commit）一个新的段到磁盘需要 fsync，开销非常大。如果每索引一个文档就执行一次 fsync，性能将无法接受。
Easysearch 的做法是：将新段先写入文件系统缓存（OS page cache）——这一步代价很低；稍后再 fsync 到磁盘。只要新段进入了文件系统缓存，就可以像其他文件一样被打开和读取，从而对搜索可见。</description></item><item><title>文档建模</title><link>/easysearch/main/docs/fundamentals/document-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/document-model/</guid><description>这一页回答两个问题：应该把什么放进一个文档？字段怎么设计才适合搜索？ 这里只讲单个文档层面的建模，跨文档关系放在“数据建模”章节。
什么是文档 # 在 Easysearch 中，一个 文档（Document） 是被序列化为 JSON 的最顶层对象，指定了唯一 ID 并存储到 Easysearch 中。例如：
{ &amp;#34;name&amp;#34;: &amp;#34;John Smith&amp;#34;, &amp;#34;age&amp;#34;: 42, &amp;#34;confirmed&amp;#34;: true, &amp;#34;join_date&amp;#34;: &amp;#34;2014-06-01&amp;#34;, &amp;#34;home&amp;#34;: { &amp;#34;lat&amp;#34;: 51.5, &amp;#34;lon&amp;#34;: 0.1 }, &amp;#34;accounts&amp;#34;: [ { &amp;#34;type&amp;#34;: &amp;#34;facebook&amp;#34;, &amp;#34;id&amp;#34;: &amp;#34;johnsmith&amp;#34; }, { &amp;#34;type&amp;#34;: &amp;#34;twitter&amp;#34;, &amp;#34;id&amp;#34;: &amp;#34;johnsmith&amp;#34; } ] } 文档可以包含字符串、数字、布尔、日期、嵌套对象、数组等多种类型。
文档元数据 # 每个文档都有三个核心元数据：
元数据 说明 _index 文档存放的索引，是逻辑命名空间 _id 文档的唯一标识符，可自定义或自动生成 _source 文档的原始 JSON 内容 此外，每个文档还有 _version 字段——每次对文档修改（包括删除）时版本号递增，用于并发控制。</description></item><item><title>并发控制与版本</title><link>/easysearch/main/docs/fundamentals/concurrency-and-versioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/concurrency-and-versioning/</guid><description>当有多个客户端同时写入同一份文档时，如果不做任何并发控制，很容易出现&amp;quot;旧值覆盖新值&amp;quot;的问题。本页介绍如何用版本与乐观锁避免这类隐性数据错误。
为什么需要并发控制？ # 考虑这样一个场景：
客户端 A 读取文档，准备把字段 count 从 1 改到 2 客户端 B 也读取了同一文档，把 count 从 1 改到 3 如果没有并发控制：
A 先写入，文档变成 count=2 B 后写入，文档被覆盖为 count=3（A 的更新&amp;quot;丢了&amp;quot;） 很多时候这种问题不会立刻暴露，但会在数据对账或业务逻辑中造成难以解释的异常。
乐观并发控制（Optimistic Concurrency Control） # Easysearch 使用 _seq_no（序列号） 和 _primary_term（主分片任期） 实现乐观并发控制：
_seq_no：每次对分片的写操作递增，全局唯一标识该分片上的操作顺序 _primary_term：当主分片发生切换（故障转移）时递增，用于区分不同&amp;quot;任期&amp;quot;的写入 每次读取文档时，响应中都会包含这两个值：
GET /products/_doc/1 // 响应 { &amp;#34;_index&amp;#34;: &amp;#34;products&amp;#34;, &amp;#34;_type&amp;#34;: &amp;#34;_doc&amp;#34;, &amp;#34;_id&amp;#34;: &amp;#34;1&amp;#34;, &amp;#34;_version&amp;#34;: 3, &amp;#34;_seq_no&amp;#34;: 5, &amp;#34;_primary_term&amp;#34;: 1, &amp;#34;found&amp;#34;: true, &amp;#34;_source&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;iPhone&amp;#34;, &amp;#34;count&amp;#34;: 10, &amp;#34;price&amp;#34;: 5999 } } 安全更新：if_seq_no + if_primary_term # 使用 if_seq_no 和 if_primary_term 参数，只有当前版本与预期一致时才允许更新：</description></item><item><title>_source 与字段存储</title><link>/easysearch/main/docs/fundamentals/source-and-stored-fields/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/source-and-stored-fields/</guid><description>_source 是文档写入时的原始 JSON，而字段的存储和检索有多种方式。本页讨论如何在&amp;quot;读取灵活性、存储成本与性能&amp;quot;之间做权衡。
_source：默认的真相来源 # _source 保存了写入时的完整 JSON 文档。在 _source 开启的情况下：
GET 请求可以直接返回原始文档 update 操作可以在服务端基于 _source 进行部分更新 需要重建索引时，可以直接从 _source 读取数据（参见 重建索引） 大多数场景下，建议保持 _source 开启，除非有非常严格的存储或合规要求。
_source 字段过滤 # 在查询时，可以通过 _source_includes 和 _source_excludes 只返回需要的字段，减少网络传输：
// GET 请求中过滤 _source GET /my-index/_doc/1?_source_includes=title,date // Search 请求中过滤 _source POST /my-index/_search { &amp;#34;_source&amp;#34;: { &amp;#34;includes&amp;#34;: [&amp;#34;title&amp;#34;, &amp;#34;date&amp;#34;], &amp;#34;excludes&amp;#34;: [&amp;#34;description&amp;#34;] }, &amp;#34;query&amp;#34;: { &amp;#34;match_all&amp;#34;: {} } } // 完全不返回 _source GET /my-index/_doc/1?_source=false 这是接口级别的&amp;quot;投影&amp;quot;，不影响存储——_source 中仍然保存完整文档。</description></item><item><title>Mapping 与文本分析</title><link>/easysearch/main/docs/fundamentals/mapping-analysis-intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/mapping-analysis-intro/</guid><description>Easysearch 中不同字段类型的索引和搜索行为截然不同。理解映射（Mapping）和分析（Analysis）是用好全文搜索的关键。
精确值 VS 全文 # Easysearch 中的数据可以概括为两类：
精确值（Exact Values）
例如日期 2024-09-15、用户 ID user_123、状态码 published Foo 和 foo 是不同的，2024 和 2024-09-15 也是不同的 查询是二进制的：要么匹配，要么不匹配 全文（Full Text）
例如文章内容、商品描述、邮件正文 查询不是&amp;quot;是否匹配&amp;quot;，而是&amp;quot;匹配程度有多大&amp;quot; 期望搜索 jump 能匹配 jumped、jumps、jumping 期望搜索 UK 能返回包含 United Kingdom 的文档 为了支持全文搜索，Easysearch 在索引之前会先对文本进行分析，生成标准化的词条后写入倒排索引。
分析器：三步处理 # 分析（Analysis） 是将文本转换为适合倒排索引的词条的过程。一个分析器由三个部分组成：
组件 作用 示例 字符过滤器 在分词前整理字符串 去掉 HTML 标签、&amp;amp; → and 分词器 将字符串拆分为单独的词条 按空格/标点拆分 Token 过滤器 对词条做变换 小写化、词干提取、同义词扩展、停用词删除 内置分析器对比 # 以文本 &amp;quot;Set the shape to semi-transparent by calling set_trans(5)&amp;quot; 为例：</description></item><item><title>RESTful 与 Query DSL</title><link>/easysearch/main/docs/fundamentals/restful-query-dsl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/restful-query-dsl/</guid><description>RESTful 与 Query DSL # Easysearch 通过 RESTful API 提供所有功能，使用 JSON 格式的 Query DSL 描述查询逻辑。理解这两个基础概念，是使用 Easysearch 的第一步。
RESTful API 约定 # Easysearch 的所有操作都通过 HTTP 请求完成，遵循 RESTful 风格：
HTTP 方法 含义 示例 GET 读取 GET /my-index/_search PUT 创建或全量更新 PUT /my-index POST 创建或部分更新 POST /my-index/_doc DELETE 删除 DELETE /my-index 请求结构 # 一个典型的 Easysearch 请求由三部分组成：</description></item><item><title>相关性与排序</title><link>/easysearch/main/docs/fundamentals/relevance-and-sorting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/relevance-and-sorting/</guid><description>在 Easysearch 中，搜索结果默认按**相关性（relevance）**降序排列。理解相关性如何计算、如何自定义排序，是用好全文搜索的关键。
什么是相关性？ # 每个文档都有一个 _score 字段，表示它与查询的匹配程度。评分越高，相关性越高。
_score 的计算基于 BM25 算法（Okapi BM25），它是经典 TF/IDF 的改进版本。BM25 使用三个核心因素来衡量相关性：
词频（Term Frequency, TF） # 检索词在文档字段中出现的频率。出现 5 次比出现 1 次的权重更高。BM25 对词频做了饱和处理——频率增长到一定程度后增益递减，不像经典 TF/IDF 会无限增长：
$$tf_{BM25} = \frac{freq \cdot (k_1 + 1)}{freq + k_1 \cdot (1 - b + b \cdot \frac{dl}{avgdl})}$$
逆向文档频率（Inverse Document Frequency, IDF） # 检索词在所有文档中出现的频率。越常见的词（如&amp;quot;的&amp;quot;&amp;ldquo;和&amp;rdquo;），权重越低；越罕见的词权重越高。
$$idf(t) = \ln\left(1 + \frac{N - df + 0.5}{df + 0.5}\right)$$
其中 $N$ 是文档总数，$df$ 是包含该词的文档数。
字段长度归一化（Field-length Norm） # 字段越短，权重越高。检索词出现在 title（短字段）比出现在 content（长字段）更有意义。在 BM25 中通过参数 $b$ 控制长度归一化的影响程度。</description></item><item><title>NLP 自然语言处理</title><link>/easysearch/main/docs/fundamentals/nlp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/nlp/</guid><description>NLP 自然语言处理 # 搜索引擎的核心挑战是理解人类语言。本文介绍 NLP（Natural Language Processing）在 Easysearch 中的应用，从基础的分词到高级的向量语义搜索。
NLP 在搜索中的角色 # 用户输入: &amp;#34;我想买一台便宜的笔记本电脑&amp;#34; ↓ NLP 处理层（分词、去停用词、同义词、向量化） ↓ Easysearch 查询执行 ↓ 返回相关结果（包括 &amp;#34;laptop&amp;#34;、&amp;#34;notebook&amp;#34;、&amp;#34;手提电脑&amp;#34; 等） Easysearch 中 NLP 的应用可以分为三个层次：
层次 技术 实现方式 词级处理 分词、词干提取、停用词 内置分析器 语言规则 同义词、拼音、模糊匹配 分析器插件 语义理解 向量检索、文本嵌入 AI 集成 / kNN 第一层：分词与文本分析 # 分词是 NLP 的基础——将连续文本切分为独立的词项（Token）。
中文分词 # 中文没有空格分隔，需要专用分词器：
PUT /my-index { &amp;#34;settings&amp;#34;: { &amp;#34;analysis&amp;#34;: { &amp;#34;analyzer&amp;#34;: { &amp;#34;ik_smart_analyzer&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;custom&amp;#34;, &amp;#34;tokenizer&amp;#34;: &amp;#34;ik_smart&amp;#34; } } } } } 测试分词效果：</description></item><item><title>聚合与数据分析</title><link>/easysearch/main/docs/fundamentals/aggregations-data-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/fundamentals/aggregations-data-analysis/</guid><description>聚合（Aggregations）是 Easysearch 用于做统计与分析的核心能力，可以在一次请求中同时完成&amp;quot;搜索 + 统计&amp;quot;。本页介绍聚合的概念、类型与用法。
聚合可以解决什么问题？ # 典型场景：
统计：总数、平均值、最大/最小值、百分位数 分布：按字段分桶（如按状态、地区、时间段统计数量） 下钻分析：先按大维度分组，再在组内做更细粒度分析 和传统数据库的类比：
可以粗略类比为 GROUP BY + 聚合函数，但聚合可以与全文搜索、过滤等能力组合，且天然适应分布式环境。 聚合请求的基本结构 # 一个最小的&amp;quot;搜索 + 聚合&amp;quot;请求大致长这样：
{ &amp;#34;query&amp;#34;: { &amp;#34;term&amp;#34;: { &amp;#34;status&amp;#34;: &amp;#34;success&amp;#34; } }, &amp;#34;aggs&amp;#34;: { &amp;#34;by_host&amp;#34;: { &amp;#34;terms&amp;#34;: { &amp;#34;field&amp;#34;: &amp;#34;host&amp;#34; } } } } 结构说明：
query：决定哪些文档参与统计（可为空，表示全量） aggs：定义一个或多个聚合，每个聚合都有一个名字（如 by_host） 聚合的结果会出现在响应体的 aggregations 区域，与 hits（命中的文档）并列。
桶（Bucket）与指标（Metric） # 大多数聚合可以拆成两类：
桶聚合（Bucket Aggregations）：把文档分到不同&amp;quot;桶&amp;quot;里
例如：按字段值分桶（terms）、按数值区间分桶（range）、按时间间隔分桶（date_histogram）等。 指标聚合（Metric Aggregations）：对某个字段在桶内做统计
例如：avg、sum、min、max、percentiles 等。 通常会把两者组合使用：</description></item></channel></rss>
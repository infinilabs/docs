<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>索引管理 on INFINI Easysearch</title><link>/easysearch/main/docs/operations/data-management/</link><description>Recent content in 索引管理 on INFINI Easysearch</description><generator>Hugo -- gohugo.io</generator><atom:link href="/easysearch/main/docs/operations/data-management/index.xml" rel="self" type="application/rss+xml"/><item><title>索引压缩</title><link>/easysearch/main/docs/operations/data-management/index-compression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/index-compression/</guid><description>索引压缩 # 索引编码 # 索引编码决定索引的存储字段如何被压缩和存储在磁盘上。索引编码由静态的 index.codec 设置来控制，该设置指定压缩算法。这个设置会影响索引分片的大小和索引操作的性能。
Easysearch 提供了多种基于索引编码的压缩方案，以降低索引的存储成本。
default – 该编码使用LZ4算法和预设字典，优先考虑性能而非压缩比。与best_compression相比，它提供更快的索引和搜索操作，但可能导致更大的索引/分片大小。如果在索引设置中未提供编码，则默认使用LZ4作为压缩算法。
best_compression – 该编码底层使用zlib算法进行压缩。它能实现高压缩比，从而减小索引大小。然而，这可能会增加索引操作期间的额外CPU使用，并可能随后导致较高的索引和搜索延迟。
从 Easysearch 1.1 开始，增加了基于 Zstandard 压缩算法的新编码方式。这种算法在压缩比和速度之间提供了良好的平衡。
ZSTD 与默认编解码器相比，该编解码器提供了与best_compression编解码器相当的压缩比，CPU使用合理，索引和搜索性能也有所提高。
source 复用 # source_reuse： 启用 source_reuse 配置项能够去除 _source 字段中与 doc_values 或倒排索引重复的部分，从而有效减小索引总体大小，这个功能对日志类索引效果尤其明显。
source_reuse 支持对以下数据类型进行压缩：keyword，integer，long，short，boolean，float，half_float，double，geo_point，ip， 如果是 text 类型，需要默认启用 keyword 类型的 multi-field 映射。 以上类型必须启用 doc_values 映射（默认启用）才能压缩。
使用限制 # 当索引里包含 nested 类型映射，或插件额外提供的数据类型时，不能启用 source_reuse，例如 knn 索引。
使用 source_reuse 压缩时，keyword 类型的字段最好不要设置 ignore_above 属性，设置过短的值可能会导致字段内容无法展示。
压缩效果对比 # Easysearch 压缩效果对比如下</description></item><item><title>索引模板</title><link>/easysearch/main/docs/operations/data-management/index-templates/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/index-templates/</guid><description>索引模板 # 日志、指标、审计事件这类数据，常见模式是&amp;quot;按天/按月一个新索引&amp;quot;。如果每次新索引都要手动 PUT /index 配 settings + mappings，很快就会变成运维噩梦。
索引模板（Index Template） 就是为了解决这个问题：当新索引（手动或自动）被创建时，只要名字命中规则，就自动套用一组预配置——索引设置、映射和别名。
先了解： 索引管理：创建、删除与重建索引 | 时间序列建模
Easysearch 支持三类模板：
类型 API 路径 说明 可组合索引模板 _index_template 推荐使用，支持组件模板组合 组件模板 _component_template 可复用的模板构建块，被可组合模板引用 遗留索引模板 _template 旧版 API，建议迁移到可组合模板 注意：可组合索引模板（_index_template）优先级高于遗留模板（_template）。如果同时存在匹配的可组合模板和遗留模板，将使用可组合模板。
可组合索引模板 # 可组合索引模板是推荐的模板方式，支持通过 composed_of 引用组件模板，实现模板的模块化组合。
创建模板 # PUT _index_template/daily_logs { &amp;#34;index_patterns&amp;#34;: [&amp;#34;logs-2024-01-*&amp;#34;], &amp;#34;priority&amp;#34;: 100, &amp;#34;template&amp;#34;: { &amp;#34;aliases&amp;#34;: { &amp;#34;my_logs&amp;#34;: {} }, &amp;#34;settings&amp;#34;: { &amp;#34;number_of_shards&amp;#34;: 2, &amp;#34;number_of_replicas&amp;#34;: 1 }, &amp;#34;mappings&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;timestamp&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;date&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&amp;#34; }, &amp;#34;value&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;double&amp;#34; } } } } } 请求参数 # 参数 类型 描述 默认值 create boolean 为 true 时，仅在模板不存在时创建，不会覆盖已有模板 false cause string 创建/更新模板的原因（记录到日志） — master_timeout time 连接主节点的超时时间 30s 请求体参数 # 参数 类型 描述 必填 index_patterns array 索引名称匹配模式列表 是 template object 包含 aliases、settings、mappings 的模板定义 否 composed_of array 引用的组件模板名称列表，按顺序合并 否 priority number 模板优先级，值越大优先级越高 0 version number 模板版本号（用户自定义，仅供管理使用） — _meta object 模板的元数据信息 — data_stream object 设置后匹配的索引将作为数据流创建 — 查看模板 # # 获取指定模板 GET _index_template/daily_logs # 获取所有可组合模板 GET _index_template # 通配符匹配 GET _index_template/daily* 查询参数 # 参数 类型 描述 默认值 flat_settings boolean 以扁平格式返回 Settings false local boolean 从本地节点返回信息，不查询主节点 false master_timeout time 连接主节点的超时时间 30s 检查模板是否存在 # HEAD _index_template/daily_logs 返回 200 表示存在，404 表示不存在。</description></item><item><title>索引的增删改查</title><link>/easysearch/main/docs/operations/data-management/index-management/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/index-management/</guid><description>索引（Index）是 Easysearch 的&amp;quot;逻辑命名空间&amp;quot;，但它背后是不可变段（segment）与固定主分片数等一系列硬约束。结果就是：很多你以为&amp;quot;改一下就行&amp;quot;的变更，最后都会走到&amp;quot;建新索引 + 迁移数据&amp;quot;的路上。
本页涵盖索引的完整生命周期操作：创建、查看、修改设置/映射、删除，以及重建索引的常见套路。
创建索引：把关键设置提前定好 # 你当然可以“先写一条文档让索引自动出现”，但在生产环境，更推荐显式创建索引，把关键设置、映射、分析器在写入前一次性确定：
PUT /my_index { &amp;#34;settings&amp;#34;: { &amp;#34;number_of_shards&amp;#34;: 3, &amp;#34;number_of_replicas&amp;#34;: 1 }, &amp;#34;mappings&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;title&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;text&amp;#34; }, &amp;#34;tags&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;keyword&amp;#34; } } } } 你需要提前考虑的常见项：
分片与副本：见 索引设置 映射与字段类型：见 Mapping 基础 分析器：见 Mapping 与文本分析 索引命名限制 # Easysearch 索引命名规则：
所有字母必须小写 索引名称不能以 _（下划线）或 -（连字符）开头 索引名称不能包含空格、逗号或以下字符：: &amp;quot; * + / \ | ? # &amp;gt; &amp;lt; 是否允许“自动创建索引”？ # 对日志类场景，“按天/按月写到新索引”很常见，此时自动创建索引会很省事；但对强管控业务，自动创建索引可能变成“拼写错误导致创建一堆垃圾索引”的事故源头。</description></item><item><title>索引设置（Index Settings）</title><link>/easysearch/main/docs/operations/data-management/index-settings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/index-settings/</guid><description>索引级别的设置直接影响写入、查询性能以及资源利用率。本页按功能分类列出关键设置及其默认值，帮助你在建索引或调优时有一个清单。
查看与修改索引设置 # // 查看索引的所有设置 GET /my-index/_settings // 查看特定设置 GET /my-index/_settings/index.refresh_interval // 动态修改设置（仅限 Dynamic 类型的设置） PUT /my-index/_settings { &amp;#34;index.refresh_interval&amp;#34;: &amp;#34;30s&amp;#34; } Static vs Dynamic：Static 设置只能在索引创建时指定或在关闭索引后修改；Dynamic 设置可以在运行时通过 _settings API 随时修改。
分片与副本 # 设置 默认值 类型 说明 index.number_of_shards 1 Static 主分片数量。创建后不可更改（上限由 es.index.max_number_of_shards 控制，默认 1024） index.number_of_replicas 1 Dynamic 每个主分片的副本数量。最小值 0 index.number_of_routing_shards 等于主分片数 Static 用于 _split 操作的路由分片数，必须 ≥ number_of_shards index.</description></item><item><title>开关索引与索引限制</title><link>/easysearch/main/docs/operations/data-management/open-close-index/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/open-close-index/</guid><description>开关索引与索引限制 # 关闭索引 # 关闭的索引不消耗集群资源（CPU、内存、文件句柄），但索引数据仍保留在磁盘上。关闭后索引不能读写，但可以随时重新打开。
典型场景：
历史索引暂时不需要查询，但不想删除 修改 Static 类型的索引设置（必须先关闭索引） 降低集群负载 POST /my-index/_close 响应：
{ &amp;#34;acknowledged&amp;#34;: true, &amp;#34;shards_acknowledged&amp;#34;: true, &amp;#34;indices&amp;#34;: { &amp;#34;my-index&amp;#34;: { &amp;#34;closed&amp;#34;: true } } } 批量关闭：
POST /logs-2024-01,logs-2024-02/_close POST /logs-2024-*/_close 查询参数 # 参数 类型 默认值 说明 timeout Time 30s 操作超时时间 master_timeout Time 30s 连接主节点的超时时间 wait_for_active_shards String — 等待的活跃分片数（数字、all 或 index-setting） expand_wildcards String open 通配符展开策略：open、closed、hidden、none、all ignore_unavailable Boolean false 是否忽略不存在的索引 allow_no_indices Boolean true 通配符未匹配到索引时是否报错 打开索引 # POST /my-index/_open 打开后索引会进入恢复流程（重建分片、分配副本），需要等待分片就绪后才能正常读写。</description></item><item><title>克隆、缩小与拆分索引</title><link>/easysearch/main/docs/operations/data-management/clone-shrink-split/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/clone-shrink-split/</guid><description>克隆、缩小与拆分索引 # 这三个操作都是&amp;quot;把一个现有索引复制到一个新索引&amp;quot;，区别在于目标索引的主分片数：
操作 API 目标主分片数 典型场景 Clone _clone 与源索引相同 复制索引用于测试/实验 Shrink _shrink 源分片数的因子（如 6→3、6→2、6→1） 合并小分片、降低开销 Split _split 源分片数的倍数（如 2→4、2→6） 扩展分片以提高写入并发 前置条件：源索引必须是只读状态。所有操作都会创建一个全新的索引，源索引保持不变。
公共前置步骤 # 在执行 Clone / Shrink / Split 之前，源索引必须标记为只读：
PUT /source-index/_settings { &amp;#34;index.blocks.write&amp;#34;: true } 对于 Shrink 操作，还需要将所有分片的副本迁移到同一个节点：
PUT /source-index/_settings { &amp;#34;index.routing.allocation.require._name&amp;#34;: &amp;#34;node-1&amp;#34;, &amp;#34;index.blocks.write&amp;#34;: true } 等待所有分片完成迁移：
GET _cat/shards/source-index?v 确认所有分片都在目标节点上后再执行 Shrink。</description></item><item><title>索引滚动（Rollover）</title><link>/easysearch/main/docs/operations/data-management/index-rollover/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/index-rollover/</guid><description>索引滚动（Rollover） # Rollover API 用于在满足特定条件时，将一个别名或数据流（Data Stream）滚动到一个新的索引。这是管理时间序列数据的核心操作——让你的索引保持合理大小，避免单个索引无限膨胀。
基本用法 # 前置条件 # Rollover 只能在以下两种目标上执行：
写入别名（Write Alias）：别名必须标记了 is_write_index: true 数据流（Data Stream）：天然支持 Rollover 对别名执行 Rollover # 先创建索引和写入别名：
PUT /logs-000001 { &amp;#34;aliases&amp;#34;: { &amp;#34;logs-write&amp;#34;: { &amp;#34;is_write_index&amp;#34;: true } } } 当条件满足时执行 Rollover：
POST /logs-write/_rollover { &amp;#34;conditions&amp;#34;: { &amp;#34;max_age&amp;#34;: &amp;#34;7d&amp;#34;, &amp;#34;max_docs&amp;#34;: 10000000, &amp;#34;max_size&amp;#34;: &amp;#34;50gb&amp;#34;, &amp;#34;max_primary_shard_size&amp;#34;: &amp;#34;25gb&amp;#34; } } 响应：
{ &amp;#34;acknowledged&amp;#34;: true, &amp;#34;shards_acknowledged&amp;#34;: true, &amp;#34;old_index&amp;#34;: &amp;#34;logs-000001&amp;#34;, &amp;#34;new_index&amp;#34;: &amp;#34;logs-000002&amp;#34;, &amp;#34;rolled_over&amp;#34;: true, &amp;#34;dry_run&amp;#34;: false, &amp;#34;conditions&amp;#34;: { &amp;#34;[max_age: 7d]&amp;#34;: false, &amp;#34;[max_docs: 10000000]&amp;#34;: true, &amp;#34;[max_size: 50gb]&amp;#34;: false, &amp;#34;[max_primary_shard_size: 25gb]&amp;#34;: false } } 任一条件满足即触发滚动。响应中会列出每个条件的评估结果。</description></item><item><title>Refresh、Flush 与 Force Merge</title><link>/easysearch/main/docs/operations/data-management/refresh-flush-forcemerge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/refresh-flush-forcemerge/</guid><description>Refresh、Flush 与 Force Merge # 这些是索引的日常维护操作，用于控制数据可见性、持久性和段文件结构。
Refresh：让新写入的文档可搜索 # 写入的文档不会立刻出现在搜索结果中——需要经过一次 refresh 操作，在内存中创建新的 Lucene 段（segment），文档才能被 _search 检索到。
详见 写入与存储机制 了解 refresh 的工作原理。
默认情况下，Easysearch 每 1 秒 自动执行一次 refresh（由 index.refresh_interval 控制）。但你也可以手动触发：
// 刷新特定索引 POST /my-index/_refresh // 刷新多个索引 POST /index-1,index-2/_refresh // 刷新所有索引 POST /_refresh 响应：
{ &amp;#34;_shards&amp;#34;: { &amp;#34;total&amp;#34;: 10, &amp;#34;successful&amp;#34;: 5, &amp;#34;failed&amp;#34;: 0 } } 查询参数 # 参数 类型 默认值 说明 expand_wildcards String open 通配符展开策略 ignore_unavailable Boolean false 忽略不存在的索引 allow_no_indices Boolean true 通配符未匹配时是否报错 常见场景 # 批量写入后立即搜索：导入数据后手动 refresh 确保数据可见 测试/CI 环境：写入后立即 refresh 以验证结果 生产环境注意：频繁手动 refresh 会增加小段数量，影响搜索性能。大批量写入时建议临时关闭自动 refresh（设为 &amp;quot;-1&amp;quot;），导入完成后再恢复。</description></item><item><title>数据流</title><link>/easysearch/main/docs/operations/data-management/data-streams/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/data-streams/</guid><description>数据流（Data streams） # 如果你正在将连续生成的时间序列数据（如日志、事件和指标）摄入 Easysearch，那么你很可能处于这样一种场景：文档数量快速增长，且你无需更新旧文档。
管理时间序列数据的典型工作流程包含多个步骤，例如创建滚动索引别名、定义写入索引，以及为底层索引定义通用的映射和设置。
数据流简化了这一过程，并强制采用最适合时间序列数据的配置方式，例如主要为仅追加（append-only）数据设计，并确保每个文档都包含一个时间戳字段。
数据流在内部由多个底层索引组成。搜索请求会被路由到所有底层索引，而写入请求则被路由到最新的写入索引。通过 索引生命周期管理（ILM） 策略，你可以自动处理索引滚动（rollover）或删除操作。
数据流使用说明 # 步骤 1：创建索引模板 # 要创建数据流，首先需要创建一个索引模板，用于将一组索引配置为数据流。data_stream 对象表明这是一个数据流，而非普通索引模板。索引模式需与数据流的名称匹配：
PUT _index_template/logs-template-nginx { &amp;#34;index_patterns&amp;#34;: &amp;#34;logs-nginx&amp;#34;, &amp;#34;data_stream&amp;#34;: { }, &amp;#34;priority&amp;#34;: 200, &amp;#34;template&amp;#34;: { &amp;#34;settings&amp;#34;: { &amp;#34;number_of_shards&amp;#34;: 1, &amp;#34;number_of_replicas&amp;#34;: 0 } } } 在此情况下，每个摄入的文档都必须包含一个 @timestamp 字段。
你也可以在 data_stream 对象中自定义时间戳字段名称。此外，你还可以在此处定义索引映射和其他设置，就像为普通索引模板所做的那样。
PUT _index_template/logs-template-nginx { &amp;#34;index_patterns&amp;#34;: &amp;#34;logs-nginx&amp;#34;, &amp;#34;data_stream&amp;#34;: { &amp;#34;timestamp_field&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;request_time&amp;#34; } }, &amp;#34;priority&amp;#34;: 200, &amp;#34;template&amp;#34;: { &amp;#34;settings&amp;#34;: { &amp;#34;number_of_shards&amp;#34;: 1, &amp;#34;number_of_replicas&amp;#34;: 0 } } } 在此示例中，logs-nginx 索引会匹配 logs-template-nginx 模板。当存在多个匹配时，Easysearch 会选择优先级更高的模板。</description></item><item><title>重建索引</title><link>/easysearch/main/docs/operations/data-management/reindex/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/reindex/</guid><description>重新索引数据 # 相关指南 # 索引管理：创建、删除与重建索引 别名（Aliases） 创建索引后，如果您需要进行广泛的更改，例如为每个文档添加一个新字段或合并多个索引以形成一个新的索引，而不是删除索引，使更改脱机，然后重新索引数据，则可以使用 reindex 操作。
使用 reindex 操作，可以将通过查询选择的所有文档或文档子集复制到另一个索引。重新索引是一个 POST 操作。在最基本的形式中，指定源索引和目标索引。
重新编制索引可能是一项昂贵的操作，具体取决于源索引的大小。我们建议您通过将 number_of_replicas 设置为 0 来禁用目标索引中的副本，并在重新索引过程完成后重新启用它们。
重新索引所有文档 # 您可以将所有文档从一个索引复制到另一个索引。
首先需要使用所需的字段映射和设置创建目标索引，或者可以从源索引中复制这些映射和设置：
PUT destination { &amp;#34;mappings&amp;#34;:{ &amp;#34;Add in your desired mappings&amp;#34; }, &amp;#34;settings&amp;#34;:{ &amp;#34;Add in your desired settings&amp;#34; } } reindex 命令将所有文档从源索引复制到目标索引：
POST _reindex { &amp;#34;source&amp;#34;:{ &amp;#34;index&amp;#34;:&amp;#34;source&amp;#34; }, &amp;#34;dest&amp;#34;:{ &amp;#34;index&amp;#34;:&amp;#34;destination&amp;#34; } } 如果尚未创建目标索引，则 reindex 操作将使用默认配置创建新的目标索引。
从远程群集 reindex # 您可以从远程集群中的索引复制文档。使用 remote 选项指定远程主机名和所需的登录凭据。</description></item><item><title>索引统计与监控</title><link>/easysearch/main/docs/operations/data-management/index-stats/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/index-stats/</guid><description>索引统计与监控 # Easysearch 提供了一组 API，用于查看索引的运行状态、性能指标和存储详情。这些信息是性能调优和故障排查的基础。
索引统计（Index Stats） # 获取索引级别的统计信息，包括文档数、存储大小、写入/查询/合并等操作的计数和耗时。
// 获取特定索引的所有统计 GET /my-index/_stats // 获取所有索引的统计 GET /_stats // 只获取特定指标 GET /my-index/_stats/docs,store // 多索引 GET /index-1,index-2/_stats/indexing,search 可用指标 # 指标 说明 docs 文档数和已删除文档数 store 索引存储大小 indexing 写入操作统计（总数、耗时、当前进行中等） get Get 操作统计 search 搜索操作统计（query、fetch 阶段） merge 段合并统计（次数、耗时、大小） refresh Refresh 统计 flush Flush 统计 query_cache 查询缓存命中率和大小 fielddata Fielddata 内存使用 completion Completion Suggester 内存使用 segments 段数量、内存占用 translog Translog 大小和操作数 request_cache 请求缓存命中率 recovery 恢复操作统计 warmer Warmer 统计 _all 所有指标（默认） 查询参数 # 参数 类型 默认值 说明 level String indices 聚合级别：cluster、indices、shards fields String — 逗号分隔的字段名（用于 completion 和 fielddata 指标） completion_fields String — Completion 字段名 fielddata_fields String — Fielddata 字段名 include_segment_file_sizes Boolean false 在 segments 指标中包含文件大小详情 include_unloaded_segments Boolean false 包含未加载的段信息 forbid_closed_indices Boolean true 禁止查询已关闭索引的统计 expand_wildcards String open 通配符展开策略 ignore_unavailable Boolean false 忽略不存在的索引 响应示例（节选） # { &amp;#34;_all&amp;#34;: { &amp;#34;primaries&amp;#34;: { &amp;#34;docs&amp;#34;: { &amp;#34;count&amp;#34;: 1500000, &amp;#34;deleted&amp;#34;: 2500 }, &amp;#34;store&amp;#34;: { &amp;#34;size_in_bytes&amp;#34;: 1073741824 }, &amp;#34;indexing&amp;#34;: { &amp;#34;index_total&amp;#34;: 1500000, &amp;#34;index_time_in_millis&amp;#34;: 45000, &amp;#34;index_current&amp;#34;: 0 }, &amp;#34;search&amp;#34;: { &amp;#34;query_total&amp;#34;: 350000, &amp;#34;query_time_in_millis&amp;#34;: 12000, &amp;#34;query_current&amp;#34;: 2 }, &amp;#34;segments&amp;#34;: { &amp;#34;count&amp;#34;: 42, &amp;#34;memory_in_bytes&amp;#34;: 52428800 } } } } 常见用法 # // 查看段数量（判断是否需要 force merge） GET /my-index/_stats/segments // 查看写入速率 GET /my-index/_stats/indexing // 查看查询缓存命中率 GET /my-index/_stats/query_cache,request_cache // 按分片级别查看统计 GET /my-index/_stats?</description></item><item><title>别名（Aliases）</title><link>/easysearch/main/docs/operations/data-management/aliases/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/aliases/</guid><description>别名（Alias）是指向一个或多个索引的&amp;quot;虚拟名称&amp;quot;，常用于实现无感迁移、蓝绿切换、按条件路由等功能。合理使用别名，可以让上游客户端几乎不感知底层索引的重建与演进。
最常用的场景：无感重建索引 # 典型需求：你想调整 mapping/设置，只能重建一个新索引，但又不希望业务代码改来改去。
做法示意：
当前索引为 logs_v1，别名为 logs，所有读写都通过 logs 创建新索引 logs_v2，并将数据迁移过去 将别名 logs 从 logs_v1 原子性切换到 logs_v2 业务只需始终访问 logs，不关心具体版本 好处：
切换时可以做到&amp;quot;近乎无停机&amp;quot; 可以在后台验证新索引的可用性与正确性，再切换别名 多索引聚合访问 # 别名还可以指向多个索引，例如：
别名 logs_all → 指向 logs_2024_01、logs_2024_02、logs_2024_03 等 查询 logs_all 即可同时访问多个时间分片索引 这种方式对时间序列/多分片索引的统一查询非常有用。
按条件路由的读写别名 # 别名还可以带有过滤条件或路由信息，例如：
为某个租户创建只读别名，只能看见自己的数据 为某些写入创建&amp;quot;写别名&amp;quot;，将写入路由到特定索引/分片 这类高级用法可以在多租户、数据分层等场景中减少上游逻辑复杂度，但也需要更严格的管理与规范。
API 操作 # 创建索引别名 # 使用 actions 方法指定要执行的操作列表：
POST _aliases { &amp;#34;actions&amp;#34;: [ { &amp;#34;add&amp;#34;: { &amp;#34;index&amp;#34;: &amp;#34;index-1&amp;#34;, &amp;#34;alias&amp;#34;: &amp;#34;alias1&amp;#34; } } ] } 响应：</description></item><item><title>悬挂索引</title><link>/easysearch/main/docs/operations/data-management/dangling-indices/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/operations/data-management/dangling-indices/</guid><description>悬挂索引（Dangling Indices） # 什么是悬挂索引 # 悬挂索引是指存在于节点本地磁盘上，但不属于当前集群状态的索引。这种情况通常发生在：
节点离线期间，集群中其他节点删除了某个索引 节点从一个集群迁移到另一个集群 快照恢复失败或中断 集群状态丢失后重建 当节点重新加入集群时，它本地存储的这些&amp;quot;孤立&amp;quot;索引分片就成为悬挂索引。
自动导入 # 可以通过集群设置控制是否自动导入悬挂索引：
# easysearch.yml gateway.auto_import_dangling_indices: false # 默认值：false 注意：自动导入默认关闭。在生产环境中，建议保持关闭，手动检查并决定是否导入，以避免意外引入过期或不需要的数据。
API 操作 # 列出悬挂索引 # GET /_dangling 响应示例：
{ &amp;#34;dangling_indices&amp;#34;: [ { &amp;#34;index_name&amp;#34;: &amp;#34;my_old_index&amp;#34;, &amp;#34;index_uuid&amp;#34;: &amp;#34;r1eSJ3MoTheHQ2CvFoVrOg&amp;#34;, &amp;#34;creation_date_millis&amp;#34;: 1609459200000, &amp;#34;node_ids&amp;#34;: [&amp;#34;node-1&amp;#34;] } ] } 导入悬挂索引 # 使用索引 UUID 将悬挂索引导入到集群中：
POST /_dangling/r1eSJ3MoTheHQ2CvFoVrOg?accept_data_loss=true accept_data_loss=true 参数是必须的，表示您已了解导入可能存在数据不一致的风险。
删除悬挂索引 # 不需要的悬挂索引可以直接删除：
DELETE /_dangling/r1eSJ3MoTheHQ2CvFoVrOg?accept_data_loss=true 操作建议 # 场景 建议操作 节点短暂离线后重新加入 检查索引内容后决定是否导入 集群迁移残留数据 确认数据已在新集群中恢复后删除 集群状态丢失重建 列出所有悬挂索引，逐一导入恢复 来源不明的悬挂索引 谨慎处理，建议先备份再决定 注意事项 # 导入悬挂索引不会自动恢复副本分片，需要等待集群自行分配 如果集群中已存在同名索引（但 UUID 不同），导入会失败 悬挂索引的映射和设置保持离线前的状态，可能与当前集群配置不兼容 建议在导入前通过 _dangling API 检查索引的创建时间，确认是否是期望的数据</description></item></channel></rss>
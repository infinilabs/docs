<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>数据接入 on INFINI Easysearch (main)</title><link>/easysearch/main/docs/integrations/ingest/</link><description>Recent content in 数据接入 on INFINI Easysearch (main)</description><generator>Hugo -- gohugo.io</generator><atom:link href="/easysearch/main/docs/integrations/ingest/index.xml" rel="self" type="application/rss+xml"/><item><title>使用 Logstash 接入数据</title><link>/easysearch/main/docs/integrations/ingest/logstash/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/integrations/ingest/logstash/</guid><description>Logstash 适合做“重量级管道”：支持丰富的输入源、过滤器和输出插件。
这一页只解决几个核心问题：
最小可用的 Logstash → Easysearch pipeline 长什么样？ 和 Easysearch 的索引与 mapping 怎么配合，避免“写进去一团糊”？ 在生产环境里，批量大小、重试、幂等这些常见坑怎么规避？ 1. 最小可用 Pipeline 示例 # 下面是一个从文件读取日志、简单解析后写入 Easysearch 的最小示例（概念结构）：
input { file { path =&amp;gt; &amp;#34;/var/log/app/app.log&amp;#34; start_position =&amp;gt; &amp;#34;beginning&amp;#34; sincedb_path =&amp;gt; &amp;#34;/var/lib/logstash/.sincedb_app&amp;#34; } } filter { # 示例：按 JSON 日志解析 json { source =&amp;gt; &amp;#34;message&amp;#34; } # 示例：统一时间字段名称 if [timestamp] { mutate { rename =&amp;gt; { &amp;#34;timestamp&amp;#34; =&amp;gt; &amp;#34;@timestamp&amp;#34; } } } } output { elasticsearch { hosts =&amp;gt; [&amp;#34;http://easysearch:9200&amp;#34;] index =&amp;gt; &amp;#34;app-logs-%{+YYYY.</description></item><item><title>轻量 Agent 接入：Filebeat / Fluent Bit</title><link>/easysearch/main/docs/integrations/ingest/filebeat-fluentbit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/integrations/ingest/filebeat-fluentbit/</guid><description>轻量 Agent 接入：Filebeat / Fluent Bit # Filebeat 和 Fluent Bit 是两款常用的轻量级日志采集 Agent，均可将日志数据直接发送到 Easysearch。
相关指南（先读这些） # Logstash 接入 摄取管道 Agent 对比 # 特性 Filebeat Fluent Bit 语言 Go C 内存占用 ~30-50 MB ~5-10 MB 配置方式 YAML INI / YAML 输出到 ES ✅ 原生支持 ✅ 原生支持（es output） Ingest Pipeline ✅ 支持指定 ✅ 支持指定 多行日志 ✅ multiline 模块 ✅ multiline parser 生态模块 丰富（modules for nginx等） 较少，但灵活的 parser 体系 适用场景 通用日志采集 边缘设备、资源受限环境 Filebeat 配置示例 # 基础配置 # # filebeat.</description></item><item><title>从数据库同步数据（JDBC / ETL）</title><link>/easysearch/main/docs/integrations/ingest/jdbc-etl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/main/docs/integrations/ingest/jdbc-etl/</guid><description>从数据库同步数据（JDBC / ETL） # 将关系型数据库（MySQL、PostgreSQL 等）中的数据同步到 Easysearch 是一个常见需求。本文介绍全量导入和增量同步的主要方案和实践。
相关指南（先读这些） # Logstash 接入 SeaTunnel 集成 Bulk API 同步方案概览 # 方案 全量 增量 实时性 复杂度 说明 Logstash JDBC Input ✅ ✅ 分钟级 低 定时轮询数据库，适合中小规模 SeaTunnel ✅ ✅ 分钟级 中 分布式 ETL，适合大数据量 Canal / Debezium (CDC) ❌ ✅ 秒级 高 基于 binlog，实时捕获变更 自研同步程序 ✅ ✅ 灵活 高 完全自定义，适合特殊需求 Logstash JDBC Input（推荐入门） # 基本配置 # # logstash-jdbc.</description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>文本分词 on INFINI Easysearch</title><link>/easysearch/v1.15.5/docs/references/text-analysis/</link><description>Recent content in 文本分词 on INFINI Easysearch</description><generator>Hugo -- gohugo.io</generator><atom:link href="/easysearch/v1.15.5/docs/references/text-analysis/index.xml" rel="self" type="application/rss+xml"/><item><title>规范化</title><link>/easysearch/v1.15.5/docs/references/text-analysis/normalizers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/text-analysis/normalizers/</guid><description>规范化 # 规范化的功能与分词器类似，但它仅输出单个词元。它不包含分词器，并且只能包含特定类型的字符过滤器和词元过滤器。这些过滤器只能执行字符级别的操作，例如字符或模式替换，而不能对整个词元进行操作。这意味着不支持用同义词替换词元或进行词干提取。
规范化在关键字搜索（即基于词项的查询）中很有用，因为它允许你对任何给定的输入运行词元过滤器和字符过滤器。例如，它使得能够将传入的查询 “Naïve” 与索引词项 “naive” 进行匹配。
考虑以下示例：
创建一个带有自定义规范化的新索引：
PUT /sample-index { &amp;quot;settings&amp;quot;: { &amp;quot;analysis&amp;quot;: { &amp;quot;normalizer&amp;quot;: { &amp;quot;normalized_keyword&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;custom&amp;quot;, &amp;quot;char_filter&amp;quot;: [], &amp;quot;filter&amp;quot;: [ &amp;quot;asciifolding&amp;quot;, &amp;quot;lowercase&amp;quot; ] } } } }, &amp;quot;mappings&amp;quot;: { &amp;quot;properties&amp;quot;: { &amp;quot;approach&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;, &amp;quot;normalizer&amp;quot;: &amp;quot;normalized_keyword&amp;quot; } } } } 索引一个文档
POST /sample-index/_doc/ { &amp;quot;approach&amp;quot;: &amp;quot;naive&amp;quot; } 以下查询与该文档匹配。这是预期的结果：
GET /sample-index/_search { &amp;quot;query&amp;quot;: { &amp;quot;term&amp;quot;: { &amp;quot;approach&amp;quot;: &amp;quot;naive&amp;quot; } } } 但这个查询同样也与该文档匹配：</description></item><item><title>词干提取</title><link>/easysearch/v1.15.5/docs/references/text-analysis/stemming/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/text-analysis/stemming/</guid><description>词干提取 # 词干提取是将单词还原为其词根或基本形式（即词干）的过程。这项技术可确保在搜索操作中，单词的不同变体都能匹配到相应结果。例如，单词 “running”（跑步，现在分词形式）、“runner”（跑步者，名词形式）和 “ran”（跑步，过去式）都可以还原为词干 “run”（跑步，原形），这样一来，搜索这些词中的任何一个都能返回相关结果。
在自然语言中，由于动词变位、名词复数变化或词的派生等原因，单词常常以各种形式出现。词干提取在以下方面提升了搜索操作的效果：
提高搜索召回率：通过将不同的单词形式匹配到同一个词干，词干提取增加了检索到的相关文档的数量。 减小索引大小：仅存储单词的词干形式可以减少搜索索引的总体大小。 词干提取是通过在分词器中使用词元过滤器来配置的。一个分词器包含以下组件：
字符过滤器：在分词之前修改字符流。 词元生成器：将文本拆分为词元（通常是单词）。 词元过滤器：在分词之后修改词元，例如，应用词干提取操作。 使用内置词元过滤器进行词干提取的示例 # 要实现词干提取，你可以配置一个内置的词元过滤器，比如 porter_stem 或 kstem 过滤器。
波特词干提取算法（ Porter stemming algorithm）是一种常用于英语的词干提取算法。
创建带有自定义分词器的索引 # 以下示例请求创建了一个名为 my_stemming_index 的新索引，并配置了一个使用 porter_stem 词元过滤器的分词器：
PUT /my_stemming_index { &amp;quot;settings&amp;quot;: { &amp;quot;analysis&amp;quot;: { &amp;quot;analyzer&amp;quot;: { &amp;quot;my_stemmer_analyzer&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;custom&amp;quot;, &amp;quot;tokenizer&amp;quot;: &amp;quot;standard&amp;quot;, &amp;quot;filter&amp;quot;: [ &amp;quot;lowercase&amp;quot;, &amp;quot;porter_stem&amp;quot; ] } } } } } 此配置包含以下内容：
标准分词器：根据单词边界将文本拆分为词项。 小写字母过滤器：将所有词元转换为小写形式。 波特词干过滤器（porter_stem 过滤器）：将单词还原为它们的词根形式。 测试分词器 # 为了检验词干提取的效果，使用之前配置好的自定义分词器来分析一段示例文本：</description></item></channel></rss>
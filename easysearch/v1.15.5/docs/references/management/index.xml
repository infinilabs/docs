<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>管理模块 on INFINI Easysearch</title><link>/easysearch/v1.15.5/docs/references/management/</link><description>Recent content in 管理模块 on INFINI Easysearch</description><generator>Hugo -- gohugo.io</generator><atom:link href="/easysearch/v1.15.5/docs/references/management/index.xml" rel="self" type="application/rss+xml"/><item><title>搭建集群</title><link>/easysearch/v1.15.5/docs/references/management/cluster/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/cluster/</guid><description>搭建集群 # 在深入研究 Easysearch 以及搜索和聚合数据之前，你首先需要创建一个 Easysearch 集群。
Easysearch 可以作为一个单节点或多节点集群运行。一般来说，配置两者的步骤是非常相似的。本页演示了如何创建和配置一个多节点集群，但只需做一些小的调整，你可以按照同样的步骤创建一个单节点集群。
要根据你的要求创建和部署一个 Easysearch 集群，重要的是要了解节点发现和集群形成是如何工作的，以及哪些设置对它们有影响。
有许多方法可以设计一个集群。下面的插图显示了一个基本架构。
这是一个四节点的集群，有一个专用的主节点，一个专用的协调节点，还有两个数据节点，这两个节点是主节点，也是用来摄取数据的。
下表提供了节点类型的简要描述。
节点类型 描述 最佳实践 Master 管理集群的整体运作并跟踪集群的状态。这包括创建和删除索引，跟踪加入和离开集群的节点，检查集群中每个节点的健康状况（通过运行 ping 请求），并将分片分配给节点。 在三个不同区域的三个专用主节点是几乎所有生产用例的正确方法。这可以确保你的集群永远不会失去法定人数。两个节点在大部分时间都是空闲的，除非一个节点宕机或需要一些维护。 Data 存储和搜索数据。在本地分片上执行所有与数据有关的操作（索引、搜索、聚合）。这些是你的集群的工作节点，需要比其他任何节点类型更多的磁盘空间。 当你添加数据节点时，保持它们在各区之间的平衡。例如，如果你有三个区，以三的倍数添加数据节点，每个区一个。我们建议使用存储和内存重的节点。 默认情况下，每个节点是一个主节点和数据节点。决定节点的数量，分配节点类型，并为每个节点类型选择硬件，取决于你的使用情况。你必须考虑到一些因素，如你想保留数据的时间，你的文件的平均大小，你的典型工作负载（索引、搜索、聚合），你的预期性价比，你的风险容忍度，等等。
在你评估所有这些要求之后，我们建议你使用一个管理工具。要开始使用 INFINI Console，请参阅 INFINI Console 文档。
本页演示了如何处理不同的节点类型。它假设你有一个类似于前面插图的四节点集群。
前提条件 # 在你开始之前，你必须在你的所有节点上安装和配置 Easysearch。有关可用选项的信息，请参见 安装和配置。
完成后，使用 SSH 连接到每个节点，然后打开 config/easysearch.yml 文件。
你可以在这个文件中为你的集群设置所有的配置。
Step 1: 命名集群 # 为集群指定一个唯一的名字。如果你不指定集群名称，它将被默认设置为 easysearch。设置一个描述性的集群名称很重要，特别是如果你想在一个网络内运行多个集群。
要指定集群名称，请修改下面一行。
#cluster.name: my-application to</description></item><item><title>CAT API</title><link>/easysearch/v1.15.5/docs/references/management/catapis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/catapis/</guid><description>cat API # 您可以使用紧凑且对齐的文本 （CAT） API 以易于理解的表格格式获取有关集群的基本统计信息。cat API 是一个人类可读的接口，它返回纯文本而不是传统的 JSON。
使用 cat API，您可以回答诸如哪个节点是选定的主节点、集群处于什么状态、每个索引中有多少文档等问题。
要查看 cat API 中的可用操作，请使用以下命令：
GET _cat 还可以在查询中使用以下字符串参数。
参数 描述 ?v 通过向列添加标题使输出更详细。它还添加了一些格式，以帮助将每列对齐在一起。此页面上的所有示例都包含 v 参数。 ?help 列出给定操作的默认标头和其他可用标头。 ?h 将输出限制为特定标头。 ?format 以 JSON、YAML 或 CBOR 格式输出结果。 ?sort 按指定列对输出进行排序。 要查看每列表示的内容，请使用 ?v 参数：
GET _cat/&amp;lt;operation_name&amp;gt;?v 要查看所有可用的标头，请使用 ?help 参数：
GET _cat/&amp;lt;operation_name&amp;gt;?help 要将输出限制为标头的子集，请使用 ?h 参数：</description></item><item><title>系统日志</title><link>/easysearch/v1.15.5/docs/references/management/logs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/logs/</guid><description>系统日志 # Easysearch 日志包含监控群集操作和故障排除问题的重要信息。日志的位置因安装类型而异：
在 Docker 上，Easysearch 将大多数日志写入控制台，并将其余日志存储在 Easysearch/logs/ 中。 tarball 安装也使用 easysearch/logs/ 。 在 RPM 和 Debian 安装上， Easysearch 将日志写入 /var/log/Easysearch/ 。 日志可作为 .log （纯文本）和 .json 文件使用。
应用程序日志 # 对于其应用程序日志，Easysearch 使用 Apache Log4j 2 其内置日志级别（从最低到最高）为 TRACE 、 DEBUG 、 INFO 、 WARN 、 ERROR 和 FATAL 。默认 Easysearch 日志级别为 INFO 。
您可以更改各个 Easysearch 模块的日志级别，而不是更改默认日志级别（ logger.level ）：
PUT /_cluster/settings { &amp;#34;persistent&amp;#34; : { &amp;#34;logger.org.easysearch.index.reindex&amp;#34; : &amp;#34;DEBUG&amp;#34; } } 此示例更改后，Easysearch 在重新索引操作期间会发出更详细的日志：</description></item><item><title>索引模板</title><link>/easysearch/v1.15.5/docs/references/management/index-templates/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/index-templates/</guid><description>索引模板 # 索引模板允许您使用预定义的映射和设置初始化新索引。例如，如果连续索引日志数据，可以定义一个索引模板，以便所有这些索引都具有相同数量的碎片和副本。
创建模板 # 要创建索引模板，请使用 POST 请求：
POST _index_template 此命令创建一个名为 daily_logs 的模板，并将其应用于名称与正则表达式 logs-2023-01-* 匹配的任何新索引，还将其添加到 my_log 别名中：
PUT _index_template/daily_logs { &amp;#34;index_patterns&amp;#34;: [ &amp;#34;logs-2023-01-*&amp;#34; ], &amp;#34;template&amp;#34;: { &amp;#34;aliases&amp;#34;: { &amp;#34;my_logs&amp;#34;: {} }, &amp;#34;settings&amp;#34;: { &amp;#34;number_of_shards&amp;#34;: 2, &amp;#34;number_of_replicas&amp;#34;: 1 }, &amp;#34;mappings&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;timestamp&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;date&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&amp;#34; }, &amp;#34;value&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;double&amp;#34; } } } } } 您应该看到以下响应：
{ &amp;#34;acknowledged&amp;#34;: true } 如果创建名为 logs-2023-01-01 的索引，可以看到它具有模板中的映射和设置：
PUT logs-2023-01-01 GET logs-2023-01-01 { &amp;#34;logs-2023-01-01&amp;#34;: { &amp;#34;aliases&amp;#34;: { &amp;#34;my_logs&amp;#34;: {} }, &amp;#34;mappings&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;timestamp&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;date&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&amp;#34; }, &amp;#34;value&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;double&amp;#34; } } }, &amp;#34;settings&amp;#34;: { &amp;#34;index&amp;#34;: { &amp;#34;creation_date&amp;#34;: &amp;#34;1673588860779&amp;#34;, &amp;#34;number_of_shards&amp;#34;: &amp;#34;2&amp;#34;, &amp;#34;number_of_replicas&amp;#34;: &amp;#34;1&amp;#34;, &amp;#34;uuid&amp;#34;: &amp;#34;S1vMSMDHSAuS2IzPcOHpOA&amp;#34;, &amp;#34;version&amp;#34;: { &amp;#34;created&amp;#34;: &amp;#34;7110199&amp;#34; }, &amp;#34;provided_name&amp;#34;: &amp;#34;logs-2023-01-01&amp;#34; } } } } 与此模式匹配的任何其他索引&amp;mdash; logs-2023-01-02 、 logs-2033-01-03等&amp;mdash; 都将继承相同的映射和设置。</description></item><item><title>重建数据</title><link>/easysearch/v1.15.5/docs/references/management/reindex-data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/reindex-data/</guid><description>重新索引数据 # 创建索引后，如果您需要进行广泛的更改，例如为每个文档添加一个新字段或合并多个索引以形成一个新的索引，而不是删除索引，使更改脱机，然后重新索引数据，则可以使用 reindex 操作。
使用 reindex 操作，可以将通过查询选择的所有文档或文档子集复制到另一个索引。重新索引是一个 POST 操作。在最基本的形式中，指定源索引和目标索引。
重新编制索引可能是一项昂贵的操作，具体取决于源索引的大小。我们建议您通过将 number_of_replicas 设置为 0 来禁用目标索引中的副本，并在重新索引过程完成后重新启用它们。
重新索引所有文档 # 您可以将所有文档从一个索引复制到另一个索引。
首先需要使用所需的字段映射和设置创建目标索引，或者可以从源索引中复制这些映射和设置：
PUT destination { &amp;#34;mappings&amp;#34;:{ &amp;#34;Add in your desired mappings&amp;#34; }, &amp;#34;settings&amp;#34;:{ &amp;#34;Add in your desired settings&amp;#34; } } reindex 命令将所有文档从源索引复制到目标索引：
POST _reindex { &amp;#34;source&amp;#34;:{ &amp;#34;index&amp;#34;:&amp;#34;source&amp;#34; }, &amp;#34;dest&amp;#34;:{ &amp;#34;index&amp;#34;:&amp;#34;destination&amp;#34; } } 如果尚未创建目标索引，则 reindex 操作将使用默认配置创建新的目标索引。
从远程群集 reindex # 您可以从远程集群中的索引复制文档。使用 remote 选项指定远程主机名和所需的登录凭据。
此命令会到达远程集群，使用用户名和密码登录，并将所有文档从该远程集群中的源索引复制到本地集群中的目标索引：
POST _reindex { &amp;#34;source&amp;#34;:{ &amp;#34;remote&amp;#34;:{ &amp;#34;host&amp;#34;:&amp;#34;https://&amp;lt;REST_endpoint_of_remote_cluster&amp;gt;:9200&amp;#34;, &amp;#34;username&amp;#34;:&amp;#34;YOUR_USERNAME&amp;#34;, &amp;#34;password&amp;#34;:&amp;#34;YOUR_PASSWORD&amp;#34; } }, &amp;#34;dest&amp;#34;:{ &amp;#34;index&amp;#34;:&amp;#34;destination&amp;#34; } } 您可以指定以下选项：</description></item><item><title>任务管理</title><link>/easysearch/v1.15.5/docs/references/management/tasksapis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/tasksapis/</guid><description>任务管理 # 任务是在集群中运行的任何操作。例如，搜索图书数据集以查找标题或作者姓名是一项任务。将自动创建任务以监视集群的运行状况和性能。有关集群中当前执行的所有任务的详细信息，可以使用 tasks API 操作。
以下请求返回有关所有任务的信息：
GET _tasks 通过包含任务 ID，您可以获得特定任务的信息。请注意，任务 ID 由节点的标识字符串和任务的数字 ID 组成。例如，如果节点的标识串是 nodestring ，任务的数字标识是 1234 ，则任务 ID 是 nodestring:1234 。您可以通过运行 tasks 操作来查找此信息。
GET _tasks/&amp;lt;task_id&amp;gt; 请注意，如果任务完成运行，它将不会作为请求的一部分返回。对于一个需要稍长时间才能完成的任务的示例，可以在较大的文档上运行 _reindex API 操作，然后运行 tasks 。
Sample Response
{ &amp;#34;nodes&amp;#34;: { &amp;#34;Mgqdm0f9SEGClWxp_RdnaQ&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;easy-node1&amp;#34;, &amp;#34;transport_address&amp;#34;: &amp;#34;30.18.0.3:9300&amp;#34;, &amp;#34;host&amp;#34;: &amp;#34;30.18.0.3&amp;#34;, &amp;#34;ip&amp;#34;: &amp;#34;30.18.0.3:9300&amp;#34;, &amp;#34;roles&amp;#34;: [&amp;#34;data&amp;#34;, &amp;#34;ingest&amp;#34;, &amp;#34;master&amp;#34;, &amp;#34;remote_cluster_client&amp;#34;], &amp;#34;tasks&amp;#34;: { &amp;#34;Mgqdm0f9SEGClWxp_RdnaQ:17416&amp;#34;: { &amp;#34;node&amp;#34;: &amp;#34;Mgqdm0f9SEGClWxp_RdnaQ&amp;#34;, &amp;#34;id&amp;#34;: 17416, &amp;#34;type&amp;#34;: &amp;#34;transport&amp;#34;, &amp;#34;action&amp;#34;: &amp;#34;cluster:monitor/tasks/lists&amp;#34;, &amp;#34;start_time_in_millis&amp;#34;: 1613599752458, &amp;#34;running_time_in_nanos&amp;#34;: 994000, &amp;#34;cancellable&amp;#34;: false, &amp;#34;headers&amp;#34;: {} }, &amp;#34;Mgqdm0f9SEGClWxp_RdnaQ:17413&amp;#34;: { &amp;#34;node&amp;#34;: &amp;#34;Mgqdm0f9SEGClWxp_RdnaQ&amp;#34;, &amp;#34;id&amp;#34;: 17413, &amp;#34;type&amp;#34;: &amp;#34;transport&amp;#34;, &amp;#34;action&amp;#34;: &amp;#34;indices:data/write/bulk&amp;#34;, &amp;#34;start_time_in_millis&amp;#34;: 1613599752286, &amp;#34;running_time_in_nanos&amp;#34;: 30846500, &amp;#34;cancellable&amp;#34;: false, &amp;#34;parent_task_id&amp;#34;: &amp;#34;Mgqdm0f9SEGClWxp_RdnaQ:17366&amp;#34;, &amp;#34;headers&amp;#34;: {} }, &amp;#34;Mgqdm0f9SEGClWxp_RdnaQ:17366&amp;#34;: { &amp;#34;node&amp;#34;: &amp;#34;Mgqdm0f9SEGClWxp_RdnaQ&amp;#34;, &amp;#34;id&amp;#34;: 17366, &amp;#34;type&amp;#34;: &amp;#34;transport&amp;#34;, &amp;#34;action&amp;#34;: &amp;#34;indices:data/write/reindex&amp;#34;, &amp;#34;start_time_in_millis&amp;#34;: 1613599750929, &amp;#34;running_time_in_nanos&amp;#34;: 1529733100, &amp;#34;cancellable&amp;#34;: true, &amp;#34;headers&amp;#34;: {} } } } } } 您还可以在查询中使用以下参数。</description></item><item><title>快照生命周期管理</title><link>/easysearch/v1.15.5/docs/references/management/slm_api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/slm_api/</guid><description>快照生命周期管理 # 使用快照管理（SLM）API 自动创建快照。
创建快照策略 # 请求示例 # 每天上午 8 点自动创建一份快照,快照名称格式为 yyyy-MM-dd-HH:mm ，存储在 my_backup 快照仓库 每天凌晨 1 点自动删除最早 7 天前创建的快照、超过 21 个的快照以及保留至少 7 个快照 快照创建和删除的时间限制均为 1 小时 curl -XPOST -uadmin:admin -H 'Content-Type: application/json' 'https://localhost:9200/_slm/policies/daily-policy' -d ' { &amp;quot;description&amp;quot;: &amp;quot;每日快照策略&amp;quot;, &amp;quot;creation&amp;quot;: { &amp;quot;schedule&amp;quot;: { &amp;quot;cron&amp;quot;: { &amp;quot;expression&amp;quot;: &amp;quot;0 8 * * *&amp;quot;, &amp;quot;timezone&amp;quot;: &amp;quot;Asia/Shanghai&amp;quot; } }, &amp;quot;time_limit&amp;quot;: &amp;quot;1h&amp;quot; }, &amp;quot;deletion&amp;quot;: { &amp;quot;schedule&amp;quot;: { &amp;quot;cron&amp;quot;: { &amp;quot;expression&amp;quot;: &amp;quot;0 1 * * *&amp;quot;, &amp;quot;timezone&amp;quot;: &amp;quot;Asia/Shanghai&amp;quot; } }, &amp;quot;condition&amp;quot;: { &amp;quot;max_age&amp;quot;: &amp;quot;7d&amp;quot;, &amp;quot;max_count&amp;quot;: 21, &amp;quot;min_count&amp;quot;: 7 }, &amp;quot;time_limit&amp;quot;: &amp;quot;1h&amp;quot; }, &amp;quot;snapshot_config&amp;quot;: { &amp;quot;date_format&amp;quot;: &amp;quot;yyyy-MM-dd-HH:mm&amp;quot;, &amp;quot;date_format_timezone&amp;quot;: &amp;quot;Asia/Shanghai&amp;quot;, &amp;quot;indices&amp;quot;: &amp;quot;*&amp;quot;, &amp;quot;repository&amp;quot;: &amp;quot;my_backup&amp;quot;, &amp;quot;ignore_unavailable&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;include_global_state&amp;quot;: &amp;quot;false&amp;quot;, &amp;quot;partial&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;metadata&amp;quot;: { &amp;quot;any_key&amp;quot;: &amp;quot;any_value&amp;quot; } } }' 示例响应 # { &amp;quot;_id&amp;quot;: &amp;quot;daily-policy-sm-policy&amp;quot;, &amp;quot;_version&amp;quot;: 1, &amp;quot;_seq_no&amp;quot;: 0, &amp;quot;_primary_term&amp;quot;: 1, &amp;quot;sm_policy&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;daily-policy&amp;quot;, &amp;quot;description&amp;quot;: &amp;quot;每日快照策略&amp;quot;, &amp;quot;schema_version&amp;quot;: 17, &amp;quot;creation&amp;quot;: { &amp;quot;schedule&amp;quot;: { &amp;quot;cron&amp;quot;: { &amp;quot;expression&amp;quot;: &amp;quot;0 8 * * *&amp;quot;, &amp;quot;timezone&amp;quot;: &amp;quot;Asia/Shanghai&amp;quot; } }, &amp;quot;time_limit&amp;quot;: &amp;quot;1h&amp;quot; }, &amp;quot;deletion&amp;quot;: { &amp;quot;schedule&amp;quot;: { &amp;quot;cron&amp;quot;: { &amp;quot;expression&amp;quot;: &amp;quot;0 1 * * *&amp;quot;, &amp;quot;timezone&amp;quot;: &amp;quot;Asia/Shanghai&amp;quot; } }, &amp;quot;condition&amp;quot;: { &amp;quot;max_age&amp;quot;: &amp;quot;7d&amp;quot;, &amp;quot;min_count&amp;quot;: 7, &amp;quot;max_count&amp;quot;: 21 }, &amp;quot;time_limit&amp;quot;: &amp;quot;1h&amp;quot; }, &amp;quot;snapshot_config&amp;quot;: { &amp;quot;indices&amp;quot;: &amp;quot;*&amp;quot;, &amp;quot;metadata&amp;quot;: { &amp;quot;any_key&amp;quot;: &amp;quot;any_value&amp;quot; }, &amp;quot;ignore_unavailable&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;date_format_timezone&amp;quot;: &amp;quot;Asia/Shanghai&amp;quot;, &amp;quot;include_global_state&amp;quot;: &amp;quot;false&amp;quot;, &amp;quot;date_format&amp;quot;: &amp;quot;yyyy-MM-dd-HH:mm&amp;quot;, &amp;quot;repository&amp;quot;: &amp;quot;my_backup&amp;quot;, &amp;quot;partial&amp;quot;: &amp;quot;true&amp;quot; }, &amp;quot;schedule&amp;quot;: { &amp;quot;interval&amp;quot;: { &amp;quot;start_time&amp;quot;: 1685348095913, &amp;quot;period&amp;quot;: 1, &amp;quot;unit&amp;quot;: &amp;quot;Minutes&amp;quot; } }, &amp;quot;enabled&amp;quot;: true, &amp;quot;last_updated_time&amp;quot;: 1685348095938, &amp;quot;enabled_time&amp;quot;: 1685348095909 } } 获取策略 # 获取所有 SLM 策略</description></item><item><title>索引生命周期管理</title><link>/easysearch/v1.15.5/docs/references/management/ilm_api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/ilm_api/</guid><description>索引生命周期管理 # 索引生命周期管理（Index Lifecycle Management, ILM）为您提供了一种集成化、自动化的方式来高效管理时序数据。 通过配置 ILM 策略，您可以根据性能、可用性与数据保留需求，自动执行索引的滚动、归档和清理等操作。
典型应用场景 # 自动滚动生成新索引：当现有索引达到指定大小或文档数量时，自动创建新索引； 周期性轮换索引：按天、周或月创建新索引，并将历史索引归档； 强制数据保留策略：自动删除过期索引，确保合规与存储成本可控。 从 1.15.2 版本开始，index-management 已经成为 modules 的一部分，不需要单独安装插件。
创建策略 # 引入版本 1.0
创建一个策略。
请求示例 # PUT _ilm/policy/ilm_test { &amp;quot;policy&amp;quot;: { &amp;quot;phases&amp;quot;: { &amp;quot;hot&amp;quot;: { &amp;quot;min_age&amp;quot;: &amp;quot;0ms&amp;quot;, &amp;quot;actions&amp;quot;: { &amp;quot;rollover&amp;quot;: { &amp;quot;max_age&amp;quot;: &amp;quot;10m&amp;quot;, &amp;quot;max_size&amp;quot;: &amp;quot;1mb&amp;quot;, &amp;quot;max_docs&amp;quot;: 100 }, &amp;quot;set_priority&amp;quot;: { &amp;quot;priority&amp;quot;: 100 } } }, &amp;quot;delete&amp;quot;: { &amp;quot;min_age&amp;quot;: &amp;quot;15m&amp;quot;, &amp;quot;actions&amp;quot;: { &amp;quot;delete&amp;quot;: { } } } } } } 示例响应 # { &amp;quot;acknowledged&amp;quot;: true } 应用生命周期策略到索引模板 要让策略生效，需要在索引模板中指定策略名称和滚动索引的别名。</description></item><item><title>跨集群复制</title><link>/easysearch/v1.15.5/docs/references/management/ccr_api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/ccr_api/</guid><description>跨集群复制 # 使用跨集群复制 API 管理跨集群复制。
在跨集群复制中，可以将数据索引到一个领导者索引，然后 Easysearch 将这些数据复制到一个或多个只读的跟随者索引。所有在领导者上进行的后续操作都会在跟随者上复制，例如创建、更新或删除文档。
先决条件 # 1.11.1 版本之前，leader 和 follower 集群都必须安装 cross-cluster-replication 插件和 index-management 插件，1.11.1 版本开始，已经内置了 cross-cluster-replication 模块。 从1.15.2版本开始，cross-cluster-replication 和 index-management 都已经内置到 modules，不再需要安装。 如果 follower 集群的 easysearch.yml 文件中覆盖了 node.roles，确保它也包括 remote_cluster_client 角色，默认启用。 node.roles: [&amp;lt;other_roles&amp;gt;, remote_cluster_client] 权限 # 确保安全功能在两个集群上都启用或都禁用。如果启用了安全功能，确保非管理员用户被映射到适当的权限，以便他们可以执行复制操作。 部署示例集群 # 在本地起 2 个单节点的 easysearch 测试集群，分别是 follower-application (9201 端口) 和 leader-application (9200 端口) 在 easysearch.yml 添加 discovery.type: single-node 如果启用 security 功能，确保 2 个集群的证书互信，测试环境可以直接合并 2 个节点的 ca 证书： 例如 cat ca.</description></item><item><title>备份还原</title><link>/easysearch/v1.15.5/docs/references/management/snapshot-restore/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/snapshot-restore/</guid><description>备份还原 # 快照是集群索引和状态的备份。状态包括集群设置、节点信息、索引设置和分片的信息。
快照有两个主要用途：
从故障中恢复
例如，如果集群运行状况变为红色，则可以从快照恢复红色索引。
从一个群集迁移到另一个群集
例如，如果您要从概念验证迁移到生产集群，您可以拍摄前者的快照并在后者上进行恢复。
关于快照(snapshots) # 快照不是即时的。它们需要时间来完成，并不代表集群的完美时间点视图。当快照正在进行时，您仍然可以为文档编制索引并向集群发出其他请求，但快照中通常不包括新文档和对现有文档的更新。快照包括 Easysearch 启动快照时存在的主碎片。根据快照线程池的大小，快照中可能会在稍微不同的时间包含不同的碎片。
Easysearch 快照是增量的，这意味着它们只存储自上次成功快照以来已更改的数据。频繁快照和不频繁快照之间的磁盘使用率差异通常很小。
换句话说，一周内每小时拍摄一次快照（总共拍摄 168 个快照）可能不会比周末拍摄一个快照占用更多的磁盘空间。此外，拍摄快照的频率越高，完成快照所需的时间越短。一些 Easysearch 用户每半小时拍摄一次快照。
如果需要删除快照，请确保使用 Easysearch API，而不是导航到存储位置并清除文件。集群中的增量快照通常共享大量相同的数据；使用 API 时， Easysearch 仅删除其他快照未使用的数据。 {: .tip }
注册快照存储库 # 在拍摄快照之前，必须“注册”快照存储库。快照存储库只是一个存储位置：共享文件系统、 Amazon S3 、 Hadoop 分布式文件系统（HDFS）、 Azure 存储等。
Shared file system # 要将共享文件系统用作快照存储库，请将其添加到 easysearch.yml： path.repo: [&amp;#34;/mnt/snapshots&amp;#34;] 在 RPM 和 Debian 安装中，您可以安装文件系统。如果您使用 Docker 安装，请在启动集群之前，将文件系统添加到 docker-compose.yml 中的每个节点：
volumes: - /Users/jdoe/snapshots:/mnt/snapshots T1.</description></item><item><title>写入限流</title><link>/easysearch/v1.15.5/docs/references/management/throttling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/throttling/</guid><description>写入限流 # Easysearch 支持节点级别和分片级别的写入限流功能，可以将 bulk 操作对集群的压力，限制在可接受的范围。
最低版本 # 1.8.0
限流参数设置 # 以下是 Easysearch 集群级别的限流设置，并且是动态的，您可以更改此功能的默认行为，而无需重新启动集群。
限流参数说明
名称 类型 说明 默认值 cluster.throttle.node.write boolean 是否启用节点级别限流 false cluster.throttle.node.write.max_requests int 限定时间范围内单个节点允许的最大写入请求次数 0 cluster.throttle.node.write.max_bytes 字符串 限定时间范围内单个节点允许的最大写入请求字节数（kb, mb, gb 等） 0mb cluster.throttle.node.write.action 字符串 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 drop drop cluster.throttle.node.write.interval int 节点级别评估限速的单位时间间隔，默认为 1s 1 cluster.throttle.shard.write boolean 是否启用分片级别限流 false cluster.</description></item><item><title>可搜索快照</title><link>/easysearch/v1.15.5/docs/references/management/searchable_snapshot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/searchable_snapshot/</guid><description>可搜索快照 # 可搜索快照索引在实时搜索时从快照存储库中按需读取数据，而不是在恢复时将所有索引数据下载到集群存储中。由于索引数据仍然保持在快照格式中存储在存储库中，因此可搜索快照索引本质上是只读的。 任何尝试写入可搜索快照索引的操作都会导致错误。
可搜索快照功能采用了诸如在集群节点中缓存频繁使用的数据段以及删除集群节点中最不常使用的数据段等技术，以便为频繁使用的数据段腾出空间。从快照下载的数据段存储在块存储中，与集群节点的通用索引并存。 因此，集群节点的计算能力在索引、本地搜索和存储在低成本对象存储，例如 Amazon Simple Storage Service（Amazon S3）上的快照数据段之间共享。 尽管集群节点的资源利用效率要高得多，但大量的任务将导致快照搜索变得较慢且持续时间较长。节点的本地存储也用于缓存快照数据。
将节点配置为使用可搜索快照 # 只有角色为 search 的节点才能进行快照搜索，要启用可搜索快照功能，请在您的 easysearch.yml 文件中创建一个节点，并将节点角色定义为 &amp;ldquo;search&amp;rdquo;：
node.name: snapshots-node node.roles: [search] 如果您正在运行 Docker，可以通过在您的 docker-compose.yml 文件中添加以下行来创建一个具有搜索节点角色的节点：
- node.roles: [search] 创建可搜索的快照索引 # 可搜索的快照索引是通过使用 _restore API 并指定 remote_snapshot 存储类型来创建的。
storage_type:
local 表示所有快照的元数据和索引数据都将下载到本地存储。 remote_snapshot 表示快照的元数据将下载到集群，但远程存储库将保持索引数据的权威存储。数据将根据需要下载和缓存以提供查询服务。为了使用 remote_snapshot 类型还原快照，集群中至少必须配置一个节点具有 search 节点角色。 使用示例 # 下面我们以 MinIO 作为快照存储仓库，Minio 是专为云应用程序开发人员和 DevOps 构建的对象存储服务器，与 Amazon S3 对象存储兼容。
使用 _snapshot API 注册 MinIO 存储库</description></item><item><title>使用时间范围合并策略优化时序索引</title><link>/easysearch/v1.15.5/docs/references/management/time-series-Index-optimization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/time-series-Index-optimization/</guid><description>使用时间范围合并策略优化时序索引 # 在处理时序数据（如日志、监控指标、事件流）时，数据通常具有明显的时间先后顺序。Easysearch 底层的 Lucene Segment 合并是保证搜索性能和资源效率的关键操作。 然而，默认的合并策略（如 TieredMergePolicy）主要基于 Segment 的大小和删除文档比例来决定合并哪些 Segment，它并不感知数据的时间属性。
对于时序场景，这种默认策略可能导致：
冷热数据混合合并：较旧的（冷）数据 Segment 可能与较新的（热）数据 Segment 合并，导致不必要的 I/O 和 CPU 开销，因为冷数据通常访问频率低，合并它们带来的收益有限。
查询性能影响：跨时间范围的大 Segment 可能降低某些按时间范围过滤的查询效率。
为了解决这些问题，Easysearch 从 1.12.1 版本开始引入了基于时间范围的合并策略 (TimeRangeMergePolicy)，专门为时序索引优化 Segment 合并行为。
最低版本 # 1.12.1
核心概念：TimeRangeMergePolicy # TimeRangeMergePolicy 是一种特殊的合并策略，它在选择要合并的 Segment 时，除了考虑大小、删除比例等因素外，优先考虑 Segment 所覆盖的时间范围。
其核心思想是：
时间优先：倾向于合并时间上相邻的 Segment。
保留时间分区：尽量避免将时间跨度很大的 Segment 合并在一起，保持数据的“时间局部性”。
优先合并新数据：通常，新写入的数据变化更频繁（包括更新、删除），优先合并较新的 Segment 有助于更快地回收空间和优化最新数据的查询性能。
如何启用 # 要为你的时序索引启用时间范围合并策略，你需要更新索引的设置，指定用于时间排序的字段名。
步骤： # 确认时间字段：确保你的索引 Mapping 中有一个合适的日期或时间戳类型的字段（如 @timestamp、event_time 等），并且该字段准确反映了数据的时间属性。 更新索引设置：使用 Index Settings API 来设置 index.</description></item><item><title>数据汇总</title><link>/easysearch/v1.15.5/docs/references/management/rollup_api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/rollup_api/</guid><description>数据汇总 # 数据汇总或上卷（Rollup），对于时序场景类的数据，往往会有大量的非常详细的聚合指标，随着时间的图推移，存储将持续增长。汇总功能可以将旧的、细粒度的数据汇总为粗粒度格式以进行长期存储。通过将数据汇总到一个单一的文档中，可以大大降低历史数据的存储成本。 Easysearch 的 rollup 具备一些独特的优势，可以自动对 rollup 索引进行滚动而不用依赖其他 API 去单独设置，并且在进行聚合查询时支持直接搜索原始索引，做到了对业务端的搜索代码完全兼容，从而对用户无感知。
支持的聚合类型 # 对数值类型字段支持的聚合
avg sum max min value_count percentiles 对 keyword 类型字段提供 terms 聚合。
对 date 类型字段 除了 date_histogram 聚合，还支持 date_range 聚合。(v1.10.0)
查询 rollup 数据时，增加支持 Filter aggregation，某些场景可以用来替代 query 过滤数据。(v1.10.1)
增加针对个别字段自定义 special_metrics 指标的配置项。 (v1.10.1)
增加支持 Bucket sort aggregation。 (v1.10.1)
混合查询原始索引和 rollup 索引时，返回的 response 里增加了 origin 参数，表示包含 rollup 数据。(v1.10.1)
Rollup 查询 API 提供了 debug 参数，显示 Easysearch 内部执行的查询语句。(v1.10.1)</description></item><item><title>其它常用 API</title><link>/easysearch/v1.15.5/docs/references/management/popular-api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/popular-api/</guid><description>其它常用 API # 此页面包含 Easysearch 常用 API 的示例请求。
使用非默认设置创建索引 # PUT my-logs { &amp;#34;settings&amp;#34;: { &amp;#34;number_of_shards&amp;#34;: 4, &amp;#34;number_of_replicas&amp;#34;: 2 }, &amp;#34;mappings&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;title&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;text&amp;#34; }, &amp;#34;year&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;integer&amp;#34; } } } } 索引单个文档并自动生成随机 ID # POST my-logs/_doc { &amp;#34;title&amp;#34;: &amp;#34;Your Name&amp;#34;, &amp;#34;year&amp;#34;: &amp;#34;2016&amp;#34; } 索引单个文档并指定 ID # PUT my-logs/_doc/1 { &amp;#34;title&amp;#34;: &amp;#34;Weathering with You&amp;#34;, &amp;#34;year&amp;#34;: &amp;#34;2019&amp;#34; } 一次索引多个文档 # 请求正文末尾的空白行是必填的。如果省略 _id 字段， Easysearch 将生成一个随机 id 。</description></item><item><title>数据流</title><link>/easysearch/v1.15.5/docs/references/management/data-streams/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/easysearch/v1.15.5/docs/references/management/data-streams/</guid><description>数据流（Data streams） # 如果你正在将连续生成的时间序列数据（如日志、事件和指标）摄入 Easysearch，那么你很可能处于这样一种场景：文档数量快速增长，且你无需更新旧文档。
管理时间序列数据的典型工作流程包含多个步骤，例如创建滚动索引别名、定义写入索引，以及为底层索引定义通用的映射和设置。
数据流简化了这一过程，并强制采用最适合时间序列数据的配置方式，例如主要为仅追加（append-only）数据设计，并确保每个文档都包含一个时间戳字段。
数据流在内部由多个底层索引组成。搜索请求会被路由到所有底层索引，而写入请求则被路由到最新的写入索引。通过 索引生命周期管理（ILM） 策略，你可以自动处理索引滚动（rollover）或删除操作。
数据流使用说明 # 步骤 1：创建索引模板 # 要创建数据流，首先需要创建一个索引模板，用于将一组索引配置为数据流。data_stream 对象表明这是一个数据流，而非普通索引模板。索引模式需与数据流的名称匹配：
PUT _index_template/logs-template-nginx { &amp;quot;index_patterns&amp;quot;: &amp;quot;logs-nginx&amp;quot;, &amp;quot;data_stream&amp;quot;: { }, &amp;quot;priority&amp;quot;: 200, &amp;quot;template&amp;quot;: { &amp;quot;settings&amp;quot;: { &amp;quot;number_of_shards&amp;quot;: 1, &amp;quot;number_of_replicas&amp;quot;: 0 } } } 在此情况下，每个摄入的文档都必须包含一个 @timestamp 字段。
你也可以在 data_stream 对象中自定义时间戳字段名称。此外，你还可以在此处定义索引映射和其他设置，就像为普通索引模板所做的那样。
PUT _index_template/logs-template-nginx { &amp;quot;index_patterns&amp;quot;: &amp;quot;logs-nginx&amp;quot;, &amp;quot;data_stream&amp;quot;: { &amp;quot;timestamp_field&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;request_time&amp;quot; } }, &amp;quot;priority&amp;quot;: 200, &amp;quot;template&amp;quot;: { &amp;quot;settings&amp;quot;: { &amp;quot;number_of_shards&amp;quot;: 1, &amp;quot;number_of_replicas&amp;quot;: 0 } } } 在此示例中，logs-nginx 索引会匹配 logs-template-nginx 模板。当存在多个匹配时，Easysearch 会选择优先级更高的模板。</description></item></channel></rss>